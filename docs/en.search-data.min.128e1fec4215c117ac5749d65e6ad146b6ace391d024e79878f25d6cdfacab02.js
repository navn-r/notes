'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/notes/CSCB09/Week-1/','title':"Week 1",'section':"CSCB09",'content':"Week 1 #  Processes #   What happens when you run a program.\n   Has Input and Output ends:\n stdin: Standard Input - eg. Keyboard input goes through stdin stdout: Standard Output - eg. Terminal output (printing to screen)  eg.\nNavinns-MacBook-Pro:~ home$ sort # OS connects keyboard to stdin Watermelon Apple Strawberry Mango ^D # \u0026#39;exit\u0026#39; keybind, OS connects screen to stdout Apple Mango Strawberry Watermelon   Pipelining and Redirection #   Routing outputs of one program to the input of another, and outputting to a file instead of the screen.\n eg.\nNavinns-MacBook-Pro:Desktop home$ cat myfile # screen is connected to stdout # starting text This this is is a file haha haha Navinns-MacBook-Pro:Desktop home$ cat myfile | sort | uniq \u0026gt; myNewFile \u0026amp;\u0026amp; cat myNewFile # myfile -\u0026gt; stdin of cat =\u0026gt; stdout -\u0026gt; stdin of sort =\u0026gt; stdout -\u0026gt; stdin of uniq =\u0026gt; stdout -\u0026gt; myNewFile This a file haha is this Scripting #   Combining shell commands, instead of being redundant.\n eg.\n  Redundant commands:\nNavinns-MacBook-Pro:Desktop home$ cat mywords | sort | uniq \u0026gt; mywords-unique Navinns-MacBook-Pro:Desktop home$ cat yourwords | sort | uniq \u0026gt; yourwords -unique Navinns-MacBook-Pro:Desktop home$ cat badwords | sort | uniq \u0026gt; badwords -unique   Simple For-Loop script:\nfor w in mywords yourwords badwords; do cat $w | sort | uniq \u0026gt; $w-unique done   Devices and Services #   Presented as files in Unix.\n  Unix kernal creates file names and emulates file operations, known as \u0026lsquo;Special Files\u0026rsquo;  eg.\n/dev/sda # Hard disk as a special file, restricted /dev/zero # Endless stream of 0\u0026#39;s as bytes # To wipe a hard disk clean: Navinns-MacBook-Pro:~ home$ dd bs=4K if=/dev/zero of=/dev/sda Terminology #    Kernel: Decides which processes may run, and what it can access\n  OS Processes: More services, features, and background monitoring not in the kernal\n  Shell: Command-line user interface\n  User Processes: Your processes\n  The Unix Philosophy #    Consisting of small programs, that do one thing really well\n  Scripting + Pipelining versus rewriting bigger programs for complex tasks\n  Recursive file-like structure\n  Short and Simple program names - eg. cp: copies files\n  "});index.add({'id':1,'href':'/notes/CSCA48/','title':"CSCA48",'section':"Home",'content':"CSCA48 - Intro to Computer Science II #  Semester Taken: Winter 2020\nProgramming Language: C\nCourse Description:\n  Abstract data types and data structures for implementing them Linked data structures Object Oriented Programming  Encapsulation and information-hiding Testing Specifications   Analyzing the efficiency of programs Recursion   Course Page\n"});index.add({'id':2,'href':'/notes/CSCC24/Week-1/','title':"Week 1",'section':"CSCC24",'content':"Week 1 #  Translation #   The process of converting high-level source code into machine code.\n A Programming Language (PL) is neither compiled or interpreted, it\u0026rsquo;s implementation can be.\nTypes of Translation #    Compilation: translated before execution\n[Source Code] -\u0026gt; {Compiler} -\u0026gt; (Target Code)   Target code optimises for speed and security verification (potential memory leaks) for the specific machine\n \u0026lsquo;Heavy\u0026rsquo; information (i.e. variable types) only needed during compilation    Can expose potential errors/bugs before run-time\n  C, Rust are complied languages\n    Interpretation: translated line by line\n[Source Code] -\u0026gt; (Interpreter)   Useful for prototyping, scripting\n  Easier to debug; stack trace uses the source code rather than binaries\n  More portable; only requires an interpreter\n  Python, JavaScript, Shell are interpreted languages\n    Pseudo-Compilation: hybrid of compilation and interpretation\n[Source Code] -\u0026gt; {Compiler} -\u0026gt; [(Intermediate Code)] -\u0026gt; (Interpreter)   Compiler translate all of the source code before execution but into Intermediate Code\n  Interpreter executes the Intermediate Code line by line\n  Intermediate Code can be executed on any machine with the interpreter\n  Java is a hybrid language, it\u0026rsquo;s intermediate code is bytecode\n    The Process of Translation #    Lexical Analysis:\n Creates a sequence of tokens; the smallest meaningful element (language specific)    Syntactic Analysis\n  Structures tokens into an Initial Parse Tree\n internal nodes are syntax rules, leaves are tokens Rules are determined by a Precedence Table    Where syntax errors are discovered\n    Symantic Analysis\n Annotates parse tree with semantic actions    Code Generation\n Produces machine code    "});index.add({'id':3,'href':'/notes/CSCB09/','title':"CSCB09",'section':"Home",'content':"CSCB09 - Software Tools and Systems Programming #  Semester Taken: Summer 2020\nProgramming Languages: Bash shell, C\nCourse Description:\n Software techniques in a Unix-style environment, using scripting languages and a machine-oriented programming language (typically C). What goes on in the system when programs are executed.\nCore topics:\n Creating and using software tools, pipes and filters File processing, shell programming, processes, system calls, signals, basic network programming.   Course Page\n"});index.add({'id':4,'href':'/notes/CSCB09/Week-2/','title':"Week 2",'section':"CSCB09",'content':"Week 2 #  File Management #   How we survived without File Explorer\n Directory Tree #  / ├── Applications ├── Library ├── System ├── *Users* ├── Volumes ├── bin ├── cores ├── *dev* ├── etc -\u0026gt; private/etc ├── *home* -\u0026gt; /System/Volumes/Data/home ├── opt ├── private ├── sbin ├── tmp -\u0026gt; private/tmp ├── *usr* └── var -\u0026gt; private/var Paths #    Absolute Path: from root dir\n eg. /Users/home/projects/course-notes/index.html    Relative Path: from current dir\n eg. course-notes/index.html (if current dir is /Users/home/projects/)    Parent Directory: ..\n  Directory Itself: .\n Some commands require the dir name, . simplifies this task    Commands #    pwd: print working directory\n  cd: change directory\n  ls: list\n -a || -A: include dotfiles (. for -a, .. \u0026amp;\u0026amp; . for -A) -l: include more information (size, modification time, etc.) -d: include only directories -t: sort by modification time -r: reverse order -R: recursive list, whole subtree    mkdir: make directory\n  cp: copy\n -R: recursive copy, can possibly overwrite    mv: move\n Can possibly replace existing files    rmdir: remove dir\n Precondition: the current dir is empty    rm: remove/delete file(s)\n -r: recursive delete, used for non-empty directories No \u0026ldquo;Recycle Bin\u0026rdquo;/Trash    Core Utilities #    cat: concatenation\n Copy files and/or stdin to stdout eg. $ cat file1 file2 ... # dumps file1 ... # dumps file2 $ cat file1 - file2 ... # dumps file1 ... # user input as stdin, use ctrl+D to exit and continue ... # dumps file2 $ sort myFile | uniq | cat file1 - file2 ... # dumps file1 ... # dumps myFile after sorting and uniq ... # dumps file2     head and tail:\n head starts from start of file, tail starts from last eg. $ head -3 # output first 3 lines $ head -n -3 # output all except last 3 lines $ tail -3 # output last 3 lines $ tail -n +3 # output starting from and including line 3     wc: word count\n Can count by words (-w), bytes (-c), lines (-l), characters (-m) eg. $ wc file1 2 6 27 file1 # 2 lines, 6 words, 27 bytes     sort:\n Sort, check if sorted, merge sorted Default sort by whole-line eg. # sample input Navinn CS 420 UofT Expensive 69 GiveJobPls iNeedJob 180 $ sort -b -k 3,3n # sort by key=3rd field, parse 3rd field as number UofT Expensive 69 # lowest number GiveJobPls iNeedJob 180 Navinn CS 420 # greatest number     tr: translate\n  Similar to a String.replace() method\n  eg.\n$ tr 12 ab # replace \u0026#39;1\u0026#39; with \u0026#39;a\u0026#39;, \u0026#39;2\u0026#39; with \u0026#39;b\u0026#39; $ tr 1234 \u0026#39;[a*]\u0026#39; # replace \u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39; with \u0026#39;a\u0026#39; $ tr A-Z a-z # replace Uppercase with lowercase   -c: compliment\n eg. $ tr -c 1234 \u0026#39;[a*]\u0026#39; # replace everything except \u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39; with \u0026#39;a\u0026#39;     -s: squeeze\n Replace consecutive occurences by a single occurrence eg. $ tr -s 12 # can convert \u0026#39;11122abc211\u0026#39; to \u0026#39;12abc21\u0026#39; $ tr -s 12 abc # replaces then squeezes $ tr -cs 0-9a-z ’[\\n*]’ # replace everything except digits and letters with line breaks # then squeezes multiple line breaks -\u0026gt; \u0026#39;one word per line\u0026#39;     -d: delete\n Remove occurence eg. $ tr -d 12 # removes \u0026#39;1\u0026#39; and 2\u0026#39; $ tr -ds 12 3 # deletes \u0026#39;1\u0026#39;,\u0026#39;2\u0026#39; then squeezes \u0026#39;3\u0026#39;       tee: T\n Branching out, extra pipe (T-shaped) Copy stdin to stdout, and also copy to file (extra branch) eg. sort | tee sortedfile | uniq # similar to sort | uniq  # but stdout from sort is now copied to sorted file before pipelining into uniq stdin     yes:\n Unending lines of y Use case: if a program requires [y/N] a lot [expletive]: outputs expletive instead of y    "});index.add({'id':5,'href':'/notes/CSCC24/Week-2/','title':"Week 2",'section':"CSCC24",'content':"Week 2 #   Programming Languages define syntax formally.\n   Lexical Rules: specify the form of the \u0026lsquo;building blocks\u0026rsquo; of a PL\n i.e. Comment Syntax, Tokens (keywords, literals, operators, etc.) and delimiters, White space    Syntax: specifies how the \u0026lsquo;building blocks\u0026rsquo; are put together\n  Regular Expressions #  Notation #    Kleene Star (*): 0 or more repetitions\n  Alternation (+ or |): denotes choice\n  Grouping: marked by parentheses ()\n  Empty/Null String: denoted by epsilon: $\\epsilon$\n  Empty Language: language with no strings, denoted by $\\empty$\n  Examples:\n(0+1)*\t0 or more of (\u0026quot;0\u0026quot; OR \u0026quot;1\u0026quot;) 1*(:+;)*\t0+ of \u0026quot;1\u0026quot;, 0+ of (\u0026quot;:\u0026quot; OR \u0026quot;;\u0026quot;) (a+b)*aa(a+b)* 0+ of (\u0026quot;a\u0026quot; OR \u0026quot;b\u0026quot;), \u0026quot;aa\u0026quot;, 0+ of (\u0026quot;a\u0026quot; OR \u0026quot;b\u0026quot;) Formal Definition #  Let $\\Sigma$ denote a finite alphabet. A given string is a Regular Expression (RE) iff it can be formed from primitive REs $$ [\\empty, \\epsilon, \\textrm{ any } a | a \\in \\Sigma ] $$\nRules of Applications of Regular Expressions #   $a$ and $b$ are regular expressions\n   $a + b$: Union\n  $ab$ : Concatenation\n  $a^\\star$: Kleene Closure\n  $(a)$: Grouping\n  $\\Sigma^\\star$: the set of all finite strings over the alphabet $\\Sigma$\n  Definition of a Regular Language #   Languages that can be expressed by Regular Expressions.\n Given a RE $r$ over an alphabet $\\Sigma$, $L(r)$, a language associated with $r$ is defined by:\n  $L(\\empty)$: language that contains no strings\n  $L(\\epsilon)$: language that only contains ${\\epsilon}$\n  For $a \\in \\Sigma$, $L(a)$: language that only contains ${a}$\n  Rules of Regular Languages #   $a$ and $b$ are regular expressions\n   $L(a + b) = L(a) \\cup L(b)$\n  $L(ab) = L(a)L(b)$\n  $L((a)) = L(a)$\n  $L(a^\\star) = (L(a))^\\star$\n $S^\\star$ is the smallest superset of $S$ containing $\\epsilon$ and is closed under concatenation     Grammars #   Informal Grammar: just rules to follow  i.e. \u0026ldquo;Don\u0026rsquo;t end a sentence with a preposition\u0026rdquo;   Formal Grammar   Language: set of strings\n  Grammar: specifies which strings are in the language\n    Types of Formal Grammar #   Chomsky\u0026rsquo;s Hierarchy: ordered by ascending expressiveness.\n  Regular Grammars Context-Free Grammars Context-Sensitive Grammars Phase-Structure Grammars  Context-Free Grammars #   More powerful than REs.\n Parts of a Context Free Grammar #    Terminals: atomic symbols of the language\n  Non-Terminals: \u0026ldquo;variables\u0026rdquo; used in the grammar\n  Start Symbol: special non-terminal chosen as the top-level construct of the language\n The first non-terminal listed is chosen as the start symbol by convention    Productions: set of rules that specify legal ways that a non-terminal can be rewritten as a sequence of terminals and non-terminals\n  Formal Definition of CFGs #  A Context-Free Grammar $G$ is a tuple ${\\Sigma, V, S, P}$ where\n  $\\Sigma$: set of terminals\n  $V$: set of non-terminals\n  $S$: Start Symbol where $S \\in V$\n  $P$: set of productions\n Rule Form: $X \\Longrightarrow w$, where $X \\in V, w \\in (\\Sigma \\cup V)^\\star$    Note: $\\Sigma \\cap V = \\empty$\n  A Production Rule $X \\Longrightarrow w$ can be applied to a string in the form of $sXt$ where $s,t \\in (\\Sigma \\cup V)^\\star$ to produce a string $swt$\n  A grammar $G$ generates string $s$ if $\\exists$ a finite sequence of applications of productions, such that the first rule is applied to the start symbol, and the last rule produces $s$, $s \\in \\Sigma^\\star$. Written as $G \\Rightarrow^\\star s$.\n  Definition of a Context-Free Language #   Languages that can be expressed by Context-Free Grammars.\n The language generated by a grammar $G$ is $L(G) = {s \\mid G \\Rightarrow^\\star s}$\nRegular Grammars #   More restricted than CFGs.\n Productions in a Regular Grammar #    Left Recursive: 0 or 1 non-terminal, appears as the left-most symbol on the RHS of the rule\n\u0026lt;S\u0026gt; ::= \u0026lt;T\u0026gt; a b\t\u0026lt;T\u0026gt; ::= a | \u0026lt;T\u0026gt; b   Right Recursive: 0 or 1 non-terminal, appears as the right-most symbol on the RHS of rule\n\u0026lt;S\u0026gt; ::= a \u0026lt;T\u0026gt; \u0026lt;T\u0026gt; ::= b \u0026lt;T\u0026gt; | a \u0026lt;T\u0026gt;   Backus-Naur Form (BNF) #   The notation typically used to describe Context-Free Grammars.\n  Non-Terminals: \u0026lt;NonTerminal\u0026gt; OR: | Productions: LHS ::= RHS or LHS ==\u0026gt; RHS  Extended Backus-Naur Form (EBNF) #   Extensions to BNF to make it more concise, but not more powerful\n   Repetitions: { x } - 0 or more repetitions of x\n $x^+$: one or more repetitions $x^n$: maximum of $n$ repetitions    Optional: [ x ] - 0 or 1 occurrences of x\n  Grouping: ()\n  Derivations #   The sequence of applications of productions to generate a string.\n  A string is in the language generated by a grammar iff there is a derivation for it  Example, Write 3.14 using the following CFG:\n\u0026lt;r\u0026gt; ==\u0026gt; \u0026lt;p\u0026gt; . \u0026lt;p\u0026gt; \u0026lt;p\u0026gt; ==\u0026gt; \u0026lt;d\u0026gt; | \u0026lt;d\u0026gt; \u0026lt;p\u0026gt; \u0026lt;d\u0026gt; ==\u0026gt; 0 | ... | 9\t# ... just means 1 through 8 Solution:\n\u0026lt;r\u0026gt; ==\u0026gt; \u0026lt;p\u0026gt; . \u0026lt;p\u0026gt; ==\u0026gt; \u0026lt;d\u0026gt; . \u0026lt;d\u0026gt; \u0026lt;p\u0026gt; ==\u0026gt; 3 . 1 \u0026lt;d\u0026gt; ==\u0026gt; 3 . 1 4 Parse Trees #   Shows the structure within a string of the language.\n   Parsing is the process of producing a parse tree.\n  A string is in the language generated by a grammar iff there is a parse tree for the string.\n  Structure of a Parse Tree #    Root: start symbol\n  Leaf: terminal\n  Internal Node: non-terminal\n Children correspond in-order, to the RHS of one of its products in the grammar    Syntactic Ambiguity #    A grammar is ambiguous iff it generates a string for where there are two or more Parse Trees\n  A string is ambiguous w/r/t a grammar iff that grammar generates two or more Parse Trees\n  Note: Two or more derivations does not mean a string is ambiguous.\nDealing with Ambiguity #    Include Delimiters\n i.e. Curly Brackets, fi, etc.    Impose Associativity and Precedence\n  i.e. Multiplication gets higher precedence than Addition\n  Introduce a non-terminal for each precedence level\n  For the same precedence level, operators can be\n  Left Associative: recursive term before non-recursive\n  Right Associative: recursive term after non-recursive\n      "});index.add({'id':6,'href':'/notes/CSCB09/Week-3/','title':"Week 3",'section':"CSCB09",'content':"Week 3 #  Introduction to Shell #   More features available from man sh\n Simple Commands #  4 general cases of commands\n Built in commands: cd, ls etc. User defined functions Aliases eg. alias pls=\u0026quot;sudo\u0026quot; Commands that refer to the program name  eg. tr command runs the tr program    Sequential List #  Multi-line commands in a single line\n$ cd projects ; sort file1 | uniq # runs cd then runs sort with pipe # equivalent to $ cd projects projects$ sort file1 | uniq  Grouping:  Explicit: {grep foo file1 ; ls ; } \u0026gt; file2    Exit Codes #  0 for success, non-0 for failure\n$ sort file1 # assume this works $ echo $? # prints `?` command 0 $ cd asdgkj -bash: cd: asdgkj: No such file or directory $ echo $? 127 # non-zero -\u0026gt; fail Logical AND OR NOT #  $ mkdir foo \u0026amp;\u0026amp; cd foo # sequential unless one fails $ mkdir foo1 || mkdir foo2 || exit # runs sequential command if first one fails $ ! mkdir foo # trivial (true to false, v.v) Operator Precedence:\n | highest ! \u0026amp;\u0026amp; || - same precedence ; lowest  Boolean Conditions #   String comparisons: [ s1 = s2 ] # `!=`, `\u0026lt;`, `\u0026gt;` also work  Number comparisons: [ num1 -eq num2 ] # `-ne`,`-gt`,`-ge`,`-lt`,`-le` also work  Logical connectives  -a: and -o: or -e: not    Conditionals and Iteratives #   if statement: if list1 ; then list2 elif list 3 ; then list4 else list5 fi # end statement  while loop: while list1 ; do list2 done # end statement  for loop: for var in word1 word2 word3 ; do echo $var mkdir $var done # end statement   Filename Patters #   *: any string ?: matches one character [nav]: matches \u0026lsquo;n\u0026rsquo;, \u0026lsquo;a\u0026rsquo;, \u0026lsquo;v\u0026rsquo; [0-9]: matches digit [!0-9]: matches non-digit  eg.\nfor i in *.sh ; do # for all files in dir with ext .sh echo $i # echo its name done Escaping and Quoting #   \\: backslash '': single quotes \u0026quot;\u0026quot;: double quotes  Use Cases:\n Spaced files: cd \u0026quot;Onedrive - University of Toronto\u0026quot; Regex for grep: grep ’\u0026lt;[a-z]*\u0026gt;’ *.html Operators in test commands: [ ! ’(’ aaa ’\u0026lt;’ abc -o aaa ’\u0026gt;’ abc ’)’ ]  Variables #   Declaration: var=69 # no spaces # if uninit, `echo $var` returns empty string (`echo ${var}` also works) # uninitialized var is not neccessarily an empty string by default  Double Quotes $ f=`Stupid Example.js` $ ls $f # equiv to `ls Stupid ; ls Example.js` $ ls \u0026#34;$f\u0026#34; # equiv to `ls \u0026#34;Stupid Example.js\u0026#34;` # double quotes and variables($) are \u0026#39;special\u0026#39;   String Testing #   Non-Empty String: [ -n string ] Empty String: [ -z string ] Tricky: # suppose {V} is an empty string [ -n $V ] # doesnt work (interpreted as `[ -n ]`) [ -n \u0026#34;$V\u0026#34; ] # works!   Case Matching #  eg.\ncase \u0026#34;$var\u0026#34; in *.py) # Case python  rm \u0026#34;$var\u0026#34; ;; *.c | *.sh | myscript) # Case C, Shell, myscript echo w00t \u0026#34;$var\u0026#34; ;; *) # else echo meh \u0026#34;$var\u0026#34; esac # end statement "});index.add({'id':7,'href':'/notes/CSCC01/','title':"CSCC01",'section':"Home",'content':"CSCC01 - Intro to Software Engineering #  Semester Taken: Fall 2020\nProgramming Languages: N/A\nCourse Description:\n Introduction to software development methodologies with an emphasis on agile development methods appropriate for rapidly-moving projects.\nCore Topics:\n Basic software development infrastructure Requirements elicitation and tracking Prototyping; basic project management Basic UML Introduction to software architecture Design patterns Testing.   Course Page\n"});index.add({'id':8,'href':'/notes/CSCC24/Week-3/','title':"Week 3",'section':"CSCC24",'content':"Week 3 #  Higher-Order Procedures #   Procedures as returned values.\n All modern functional PLs manipulates functions as values.\n; f, g are functions and (f (g)) is well-defined (define (compose f g) (lambda x (f (g x)))) ; returns the composed function map #  Usage:\n(map proc l1 l2 ... ln)   proc: n-ary procedure (expects n arguments)\n  l1, ..., ln: lists of length m\n  Returns (e1 ... em) where ei = proc(l1[i], l2[i], ... ln[i])\n  Example:\n(map (lambda (x y) (+ x y)) \u0026#39;(1 2 3) \u0026#39;(6 5 4)) ; ==\u0026gt; \u0026#39;(7 7 7) fold #  Usage:\n(foldr op id lst) (foldl op id lst)   op: binary procedure\n  lst: list of arguments\n  id: identity element; always used\n  Returns result of applying op to elements in lst\n foldr: right-associatively foldl: left-associatively    Examples:\n(foldr op id \u0026#39;(e1 ... en)) ;\t==\u0026gt; (op e1 (op e2 (op ... (op en id)))) ; where (op en id) = id (foldr + 0 \u0026#39;(1 2 3)) (+ 1 (foldr + 0 \u0026#39;(2 3))) (+ 1 (+ 2 (foldr + 0 \u0026#39;(3)))) (+ 1 (+ 2 (+ 3 (foldr + 0 \u0026#39;())))) (+ 1 (+ 2 (+ 3 0))) (+ 1 (+ 2 3)) (+ 1 5) 6 ; (append xs ys) (define (fappend xs ys) (foldr cons ys xs)) ; (map f xs) (define (fmap f xs) (foldr (lambda (x r) (cons (f x) r)) \u0026#39;() xs)) "});index.add({'id':9,'href':'/notes/CSCB09/Week-4/','title':"Week 4",'section':"CSCB09",'content':"Week 4 #  Shell Scripting #  Running Scripts #  $ sh myscript Alternatively, in your myscript.sh file, do the following\n#! /bin/sh chmod u+x myscript # sets \u0026#39;executable\u0026#39; flag on the file and run it with\u0026hellip;\n$ ./myscript Positional Parameters #  $ ./myscript foo bar baz # come after filename, spaced  $#: Number of arguments (3) $n: Parameter name (n is the number)  eg. $1 = \u0026quot;foo\u0026quot;   $*: One string with all parameter names  \u0026quot;foo bar baz\u0026quot;   $@: Comma seperated strings for each parameter name  \u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;baz\u0026quot;   shift: Shifts Positional Parameters by 1 $# = 2 $1 = \u0026#34;bar\u0026#34; $2 = \u0026#34;baz\u0026#34; $* = \u0026#34;bar baz\u0026#34; # good for looping over parameters   Example Script #  #! /bin/sh chmod u+x pydelete # sets exec flag on pydelete.sh dryrun= verbose= while [ $# -gt 0 ]; do # while the number of params \u0026gt; 0 case \u0026#34;$1\u0026#34; in # takes the first parameter/argument -n) # if the argument is -n dryrun=y # sets the program as a dryrun \u0026#34;doesnt actually delete files\u0026#34; ;; -v) verbose=y # sets the program as verbose \u0026#34;deletes verbosely\u0026#34; ;; *) # as soon as there is another different parameter, the while loop breaks break esac # end of case shift # basically $# -= 1 done # end of while for f in \u0026#34;$@\u0026#34; ; do # for each parameter (after remove the arguments) case \u0026#34;$f\u0026#34; in # begins case *.py) # if the file is .py extension [ -n \u0026#34;$verbose\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;deleting $f\u0026#34; # if user used `-v` [ -z \u0026#34;$dryrun\u0026#34; ] \u0026amp;\u0026amp; rm \u0026#34;$f\u0026#34; # if user did not use `-n`, then it will delete ;; *) # any other file extension [ -n \u0026#34;$verbose\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;not deleting $f\u0026#34; # if the user set verbose esac # end of case done # end of for exit #   Terminates script and/or shell process Useful for:  Early exit Non-zero exit codes: exit 1    Functions #   Example definition myfunc() { echo \u0026#34;Hot diggity dog\u0026#34; }  Example function call myfunc foo bar baz # positional parameters are now function arguments  Returning return # early return return 1 # with exit code  Variable Scopes  Local variables myfunc() { local x y z x=69 y=351 z=$(expr $x + $y) echo $z }  Dynamic Scoping $ cat myscript x=0 printnum() { local x echo $x } func1() { local x x=1 printnum } func2() { local x x=2 printnum } func1 ; func2 $ sh myscript 1 # from func1 2 # from func2     Feeding multi-line text into stdin #  $ cat \u0026lt;\u0026lt; EOF # could be any string ﹥Hi I\u0026#39;m Navinn ﹥Variables also work \\$x=$x ﹥EOF # tells shell its the end of file Hi I\u0026#39;m Navinn Variables also work $x=42069  if end-marker is declared in quotes, $ is no longer special.  Command Substitution #   Run a command and take its stdout in-place for i in $(cat myfile) ; do # if wrapped in double-quotes, `cat myfile` is just one string instead of multiple echo \u0026#34;$i\u0026#34; done   Environment Variables #   Every process has a collection of environment variables  eg. PATH, CLASSPATH, USER, PWD, PS1 etc. Convention is all caps Same syntax: eg. $PATH, PATH=...   printenv: prints current env. vars. $ printenv HOME=/Users/home PWD=/Users/home/desktop PATH=/usr/local/cms/jdk1.8.0_31/bin:/usr/bin:/bin # colon-seperated list of directories ANDROID_HOME=/Users/home/Library/Android/sdk SHELL=/bin/bash ...  Creating a new env. var. is different LOGNAME=navn # same init export LOGNAME # different export LOGNAME=navinn # alt   File Attributes #  General Attributes #   Size Type Last modified time Last access time Last change time Owning user Owning group \u0026hellip;  Unix Account Organization #  Two main accounts: user, groups\n user: the user (home, navinn etc.) groups: A user can be in multiple groups  groups command displays which groups the current user is in  $ groups staff everyone localaccounts _appserverusr admin # ...   Permission Flags #    Each file is assigned one owning user and one owning group. Default is the user who created it and their default group\n Permissions: take the form rwxrwxrwx  r: read w: write x: execute   File permission notation $ ls -l rwxr-x--x 1 home staff 73966 1 Jun 23:07 myscript.sh # perms. user group bytes date_created name # rwxr-x--x: user gets `rwx`, users in group get `x`, other users get `x`      For directories:\n r: list files in the dir ls w: add, delete, modify files in the dir x: cd into dir., use paths mentioning dir    To Check Perms on a file/dir:\n[ -r path ] # exists and readable by current user [ -w path ] # exists and writable [ -x path ] # exists and executable   Changing Ownership/Permission\n  chown user path1 path2 # changes the owning user for both paths chown user:group path1 path2 # changes owning user and owning group chown :group path1 path2 # changes group chmod u=rw,g=r,o= path1 path2 # changes specific perms (u=user, g=group, o=other) find #  Literally finds a path and operates on selected files with automatic recursion\n$ find path ...expression For each given path, recurse down and pick out a file based on the expression\neg. Find python files, print their path, then delete\n$ find . -name ’*.py’ -exec rm ’{}’ ’;’ -print "});index.add({'id':10,'href':'/notes/CSCC24/','title':"CSCC24",'section':"Home",'content':"CSCC24 - Principles of Programming Languages #  Semester Taken: Winter 2021\nProgramming Languages: TBA\nCourse Description:\n Major topics in the design, definition, analysis, and implementation of modern programming languages.\nStudy of programming paradigms:\n Procedural (C, Java, Python) Functional (Scheme, ML, Haskell) Logic programming (Prolog, Mercury)   Course Page\n"});index.add({'id':11,'href':'/notes/CSCC24/Week-4/','title':"Week 4",'section':"CSCC24",'content':"Week 4 #  Local Bindings #   Creating variables with a local scope, and bind them to the result of expressions\n  Scope: Visibility of variables  let #  Usage:\n(let ([var1 expr1] ... [varn exprn]) body)   expr1, ..., exprn are evaluated in an undefined order, has the appearance of running in parallel\n  The scope of var1, ..., varn is body\n  Note: vari is not in the scope of [varj, exprj] when i != j, due to the parallel nature\n  Example:\n(define double-triple (x) (let ([double (* 2 x)] [triple (* 3 x)]) (list double triple))) let* #    Same usage as let\n  expr1, ..., exprn are evaluated sequentially left to right\n  The scope of vari is everything to the right of vari\n  Example:\n(define double-triple (x) (let* ([double (* 2 x)] [triple (+ x double)]) (list double triple))) letrec #    Same usage and order of evaluation as let\n  The scope of vari is the entire letrec\n  Example:\n;; Tail Recursion - allows var to be called in expr (define len-of-list (lst) (letrec ([length-tail (lambda (lst len) (if (empty? lst) len (length-tail (rest lst) (+ len 1))))]) (length-tail lst 0))) ;; another recursive example (letrec  ([my-even? (lambda (x) (if (eq? x 0) #t (my-odd? (- x 1))))] [my-odd? (lambda (x) (if (eq? x 0) #f (my-even? (- x 1))))]) ; allows my-even? to be in scope when called in my-odd? ; and vice versa (if (my-even? 4) 1 0)) "});index.add({'id':12,'href':'/notes/CSCB09/Week-5/','title':"Week 5",'section':"CSCB09",'content':"Week 5 #  Programming in C #  Memory Model #   Array of bytes, \u0026ldquo;Addresses\u0026rdquo; are indexes Variables may occupy several consecutive bytes, its address refers to the first occupied byte \u0026ldquo;Pointer\u0026rdquo;: Variable/parameter that stores an address  int i = 69; // Suppose i was occupying bytes 45 to 74 int *p = \u0026amp;i // 45 Memory Regions #   Text:  Stores code Pointers pointing to functions point here   Global:  Stores global variables   Stack:  Used for function calls Stores local variables Auto allocation and deallocation   Heap:  Manual allocation (malloc(), calloc()) and deallocation (free()) Used for dynamic data outside of functions    Global Variables #   Two types of varaibles int pubVar = 10; // top-level public global variable int f() { static int privVar = 1010; // function private global variable  pubVar++; privVar++; ... }   Integer Types #   All possible combinations: {signed, unsigned $\\times$ char, short, int, long, long long} Byte size depends on platform  eg. x86-64    Type Size (bytes)     char (default signed) 1   short 2   int 4   long 8   long long 8        Integer Literal Notation #     Literal Type     3 int   c char   3U unsigned int   3L long   3UL unsigned long   3LL long long   3ULL unsigned long long    printf(\u0026#34;%lu\\n\u0026#34;, 3UL) // Good usage printf(\u0026#34;%lu\\n\u0026#34;, 3) // Bad since 3 is `int` Type Casting with Numbers #   Larger size type to smaller:  Automatic conversion Lose some information in a natural way (double to int removes decimal place) Better to explicitly typecast: double d = 420.69; int i = (int)d;    Smaller size type to larger:  Automatic conversion Completely lossless    Implicit Number Promotion #   The smaller operand type gets promoted to the larger operand type  Note: char and short are always promoted to int   eg. // Suppose the following double d = 65.0; int i = 65; char c = \u0026#39;A\u0026#39;; /** i / c -\u0026gt; promotes c to `int` and preforms integer division d / j -\u0026gt; promotes j to `double` and preforms floating-point division **/   Enumeration Types #   New \u0026ldquo;types\u0026rdquo; and integer constant names enum rps { ROCK, // ROCK = 0  PAPER, // PAPER = 1  SCISSORS // SCISSORS = 2 }; enum coin { HEAD, // HEAD = 0  TAIL // TAIL = 1 }; enum rps a = PAPER; // a = 1 enum coin c = HEAD; // c = 0  \u0026ldquo;Types\u0026rdquo; are simply int, are mixable and not checked Practically useful for meaningful names only  Union Types #   Overlapping \u0026ldquo;fields\u0026rdquo; that share the same space union myUnion { // sizeof(myUnion) = \u0026#34;largest field size\u0026#34; = 4 (for this example)  unsigned short s; unsigned int i; unsigned char b[4]; }; union myUnion u; // can use u.s, u.i, u.b[j] etc.  Use Cases:  High-level: Data has multiple mutually exclusive cases Low-level:  Store an int in i Read b[0] to b[3] to discover how i splits      Tagged Union Idiom #   Example: Suppose you wanted an array that holds both int and double Idiom: Make an outer struct struct int_or_double { enum { INT, DOUBLE } tag; // remembers which case you are in  union { // shares the same space in memory regardless of int or double  int i; // case value is an int  double d; // case value is a double  } data; }; struct int_or_double a[10]; // as wanted   Type Alias with typedef #   Very general, i.e can use with struct, enum, int, double etc. typedef struct node { int i; struct node *next; } nodetype; // use `nodetype` instead of `struct node`  Cannot use the same typedef name for more than one thing typedef coin { HEAD, TAIL } coin; typedef int coin; // illegal since `typedef coin` is already defined   "});index.add({'id':13,'href':'/notes/CSCC24/Week-5/','title':"Week 5",'section':"CSCC24",'content':"Week 5 #  Tail Recursion #  Consider the following function\n(define (len xs) (if (empty? xs) 0 (+ 1 (len (rest xs))))) ; trace (len \u0026#39;(1 2)) (+ 1 (len \u0026#39;(2))) (+ 1 (+ 1 (len \u0026#39;()))) (+ 1 (+ 1 0)) (+ 1 1) 2 The space complexity for this is precisely $O(n)$, where $n$ is the length of xs.\nFor a small enough stack space, and large enough list, this function can result in a Stack Overflow. To fix this issue, we must implement this function using tail recursion.\n(define (len xs) (local [(define (len* xs l) ; accumulator (if (empty? xs) l (len* (rest xs) (+ 1 l))))] (len* xs 0))) ; trace (len \u0026#39;(1 2)) (len* \u0026#39;(1 2) 0) (len* \u0026#39;(2) 1) (len* \u0026#39;() 2) 2 Tail-Call Optimization #    A language can implement Tail-Call Optimization, where no stack is required\n  Some languages (Scheme) require tail-recursion to be implemented, some don\u0026rsquo;t (Python)\n  Types of Recursion #    Linear Recursion: At most one recursive call occuring in the body of the function\n  Tail Recursion: Recusive call is the last evaluated step in the body of the function\n  Flat Recursion: Only recurse on the top level of the list\n  Deep (or Tree) Recursion: Recurses on all items in the list (sublists)\n  Mutual Recursion: Pair of functions, that call each other, not themselves\n  Continuation-Passing Style (CPS) #   Every well-formed subexpression has a continuation; what needs to be done to complete the expression\n Consider the following expression\n(* 2 (+ 4 5))   The continuation of (+ 4 5) would be (+ 2 []) or in Scheme\n(lambda (v) (+ 2 v))   Every well-formed sub-expression in the evaluation corresponds to a point in the evaluation of the program, and v.v\n  Rewriting the above len function using CPS\n(define (len xs) (local [define (len* xs k) ; k -\u0026gt; continuation function (if (empty? xs) (k 0) (len* (rest xs) (lambda (v) (k (+ 1 v)))))] (len* xs identity))) ; trace (len \u0026#39;(1 2)) (len* \u0026#39;(1 2) identity) ; identity = (lambda (v) v) (len* \u0026#39;(2) (lambda (v1) (identity (+ 1 v1)))) (len* \u0026#39;() (lambda (v2) ((lambda (v1) (identity (+ 1 v1))) (+ 1 v2)))) 2 ; computed all in one-step ((lambda (v2) ((lambda (v1) (identity (+ 1 v1))) (+ 1 v2))) 0) ; v2 = 0 ((lambda (v1) (identity (+ 1 v1))) 1) ; v1 = 1 (identity 2) 2 "});index.add({'id':14,'href':'/notes/CSCB09/Week-6/','title':"Week 6",'section':"CSCB09",'content':"Week 6 #  Programming in C (cont.) #  File I/O in C #   Content can be accessed as a steam (seq. read/write) File functions work with FILE *  FILE: Type rep. stream state, definition varies by platform, most likely a struct    Open #  FILE *fopen(const char *filename, const char *mode)  Modes: \u0026quot;r\u0026quot;, \u0026quot;w\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;r+\u0026quot;, \u0026quot;w+\u0026quot;, \u0026quot;a+\u0026quot;  Read, Write, Append, Read \u0026amp; Write, Write \u0026amp; Read, Append \u0026amp; Read Appending and Writing to a file will create a new one if the file does not exist Reading to a non-existent file will cause an error (returns NULL)    Close #  int fclose(FILE *stream)  Close stream when finished with the file Returns 0 if success, EOF if error Why should you close the file as soon as you\u0026rsquo;re finished:  There is a limit on how many streams are open per process Writing may be buffered until closing No two process can open the same file (Windows only)    Formatted I/O #  // printf and scanf but for a given stream int fprintf(FILE *stream, const char *format, ...) int fscanf(FILE *stream, const char *format, ...)  printf is just fprintf but stdout is specified scanf(format, args) == fscanf(stdin, format, args) //same for scanf  You do not need to manually close stdin, stdout, stderr streams  Character and String I/O #   One single character: returns EOF if error or not found int putchar(int c) /* stdout */ int putc(int c, FILE *stream) int getchar(void) /* stdin */ int getc(FILE *stream)  String: int fputs(const char *string, FILE *stream) // does not put a newline at the end char *fgets(char *dest, int n, FILE *stream) // Reads at most (n-1) chars or until (and including) newline   Arbitrary Data I/O #  size_t fread(void *dest, size_t s, size_t n, FILE *stream) size_t fwrite(const void *data, size_t s, size_t n,FILE *stream)  Reads/Writes n items, each of s bytes Returns how many items have been read/written Potential Use Cases:  A whole array struct Raw bytes (array of unsigned char)    Error versus End-of-Stream Disambiguation #   getc, scanf return EOF on error fgets returns NULL fread returns \u0026lt; n  int feof(FILE *stream) // returns true if end-of-stream int ferror(FILE *stream) // returns true if error void clearerr(FILE *stream) // clears end-of-stream and error status Error Information #  #include \u0026lt;errno.h\u0026gt; Global variable stores error reason of most recent error int errno;  Many possible values: ENOENT // File does not exist EACCESS // No permission EDOM // sqrt(-3.0)  Usually, we just use perror to print the error message to stderr: void perror(const char *prefix)   Buffering #   C delays file writing  Accumulates data in a buffer until it is large, then requests the kernel to write that chunk   Also hastens reading  Requests kernel to read a large chunk into the buffer, then serves read requests from said buffer    Buffer Operations #  int fflush(FILE *stream) // Returns 0 if success, EOF if error  Writes the buffer for the output stream Clears the buffer for the input stream  int setvbuf(FILE *stream, char *buf, int mode, size_t n)    mode meaning     _IOFBF full buffering   _IOLBF line buffering   _IONBF no buffering    Default Buffering of stdin, stdout, stderr #    If Terminal:\n stdin: line buffer stdout: no buffer stderr: complicated    If in a file or pipelined:\n stdin: full buffer stdout: no buffer stderr: full buffer    Seeking #   Ask current position: long int ftell(FILE *stream) // returns -1L if error  Seek: int fseek(FILE *stream, long i, int origin) // non-zero return if error    origin go to i bytes from     SEEK_SET beginning   SEEK_END end   SEEK_CUR current position      "});index.add({'id':15,'href':'/notes/CSCC24/Week-6/','title':"Week 6",'section':"CSCC24",'content':"Week 6 #  Pure Functional Languages #   Programs: collections of functions Execution: view as evaluation  Referential Transparency #   The value of applying a function is independent of its context\n Consider the program\n# Top part of program f(a, b, c) # well-formed expression # Bottom part of program A program exhibits Referential Transparency, if it behaves the exact same, when the expression f(a, b, c) is replaced with its value.\nThe expression does not depend on the global state of computation. i.e. only on f, a, b, and c.\nNo Assignment Statements #   Variables retain their acquired value until the end of the evaluation\n In an imperative language\u0026hellip;\nint x = 42; x = x + 1; // goes to the locker that stores x // increments the value // and overwrites the locker In a functional language\u0026hellip;\n(define x 42) (define x (+ x 1)) ; just an association ; points to a different locker No Side Effects #   Functions do not change things outside of its own scope\n lst = [1, 2, 3] # no side effects def good-sum(lst, x): return sum(lst) + x # value of lst outside of bad-sun\u0026#39;s scope is changed def bad-sum(lst, x): lst.append(x) return sum(lst) # lst is now [1, 2, 3, x] Closures #   A combination of a function, and the lexical environment within which the function was declared\n Consider this closure from a functional PL\nconst addThree = (x, y) =\u0026gt; x + y + z // 1. get values x, y from the lexical scope (parameters) // 2. get z from the global scope // 3. return the sum of x, y, z   Lexical Environment: reference to its surrounding state\n  Lexical Scope: uses the location of where the variable has been declared in the source code, in order to evaluate it\n i.e. x and y are declared when calling addThree    Functions have access to variables declared in their outer scope\n i.e. the outer scope of addThree is the global scope, which is where it will find z    Only upon evaluation time, will the value of z be determined, meaning addThree basically is a recipe of steps to follow every time it is called.\n"});index.add({'id':16,'href':'/notes/CSCB09/Week-7/','title':"Week 7",'section':"CSCB09",'content':"Week 7 #  Programming in C (cont.) #  Compiler and Linker Stages #  myProgram.c $\\to$ Compiler $\\to$ Machine Code (myProgram.o) $\\to$ Libraries + Linker $\\to$ Executable\n myProgram.o is the object code file Libraries: where methods from stdio.h/stdlib.h come from Linker: Merges object files and libraries into one executable  gcc serves as a convenient linker frontend    C Compiler Stages #  The C compiler futher breaks down into:\n Pre-processor: For # directives, determines the actual C code seen by the compiler proper $ gcc -E ... # to see what the pre-processor actually does  Compiler proper: Translates C code into machine code $ gcc -c ... # creates the object file with the machine code   Pre-processor Directives #   #define macros  Textual substitution #define FINAL_COURSE_MARK 100 // to define a macro #undef FINAL_COURSE_MARK // to remove the macro    #include for header files  Header files usually contain  Macro defintions Types of exported functions and global variables   Implementation #include \u0026lt;foo.h\u0026gt; // looks for file in system-wide places (\u0026#39;/usr/include\u0026#39;)#include \u0026#34;foo.h\u0026#34; // looks for file among user source code   Conditional Compilation #ifdef DEBUG_FLAG  fprintf(stderr, \u0026#34;x=%d\\n\u0026#34;, x); #endif  Common technique for debugging code Also useful to check current OS (Windows/Linux)    Modularity and Seperate Compilation #   Keep closely-related code in the same files Key idea/principle for good software design Easier to modify and recompile one small file then one large file Example: // Rectangle Struct with area function typedef struct rect_struct { double width, height; } rect; double calcArea(const rect *r) { return ... //implementation goes here } // Linked-List Struct typedef struct ll_node_struct { rect r; ll_node_struct *next; } listNode; // Main Program int main() { rect r; listNode *newNode = (listNode *)calloc(1, sizeof(listNode)); printf(\u0026#34;%d\\n\u0026#34;, calcArea(\u0026amp;r)); ... }  This large file can be split into smaller more cohesive files  rect.h: includes type definition for rect_struct and calcArea() prototype rect.c: includes calcArea() implementation/definition llnode.h: includes ll_node_struct definition main.c: includes the main program     # only compile to machine code if it is necessary (new changes) $ gcc -c rect.c $ ... # takes the machine code and makes the executable $ gcc rect.o bb.o mainprog.o -o mainprog   Header Files #   A seperate file specifically for macro/type definitions and function prototypes Compiler wants to see the definition and prototype but you do not want to manually copy it to multiple files Note: It is illegal to see a type definition twice when compiling  Solution: Using Conditional Compilation to check if the header file was already included from another file, and including if it hasn\u0026rsquo;t #ifndef _FOO_H // if _FOO_H has been defined already, skip #define _FOO_H // if it has not been defined, then define it typedef struct node { int i; struct node *next; } node; #endif     Makefiles and make #  Most Basic Clause/Rule #    Form:\nTARGET : PREREQUISITES RECIPE   Example:\nbb.o : bb.c bb.h rect.h # if `bb.o` is missing or older than `bb.c`, `bb.h` and `rect.h` gcc -c bb.c # then run this command (compile to machine code)   If there are multiple rules in a Makefile:\n make triggers the first rule (which may trigger other subsequent rules) Order does not matter otherwise    Customary to write first rule as\nall : myexe1 myexe2 myexe3 # triggers other rules to build each myexe file .PHONY : all # means `all` is just a label, not an actual target file   File Clean Up #   Customary to add clean : # no prerequisites rm -f *.o myexe1 myexe2 myexe3 .PHONY : clean  Run make clean to invoke this target rule  Variables #   Defining variables from within a Makefile CFLAGS = -g  Setting variables outside of a Makefile make CFLAGS=\u0026#39;-g -DMY_DEBUG_FLAG\u0026#39; # overrides CFLAGS from within Makefile  Using a variable gcc $(CFLAGS) -c bb.c   Automatic Variables and Pattern Rules #    Non-example\nmainprog : mainprog.o bb.o rect.o gcc -g mainprog.o bb.o rect.o \\  -o mainprog mainprog.o : mainprog.c bb.h rect.h gcc -g -c mainprog.c bb.o : bb.c bb.h rect.h gcc -g -c bb.c rect.o : rect.c rect.h gcc -g -c rect.c   Using pattern rules\nmainprog : mainprog.o bb.o rect.o gcc -g $^ # all prereqs  -o $@ # target %.o : %.c # any `.o` target with `.c` prereq gcc -g -c $\u0026lt; # build the first prereq   Automatic prerequisite listing\n$ gcc -MM mainprog.c bb.c rect.c mainprog.o : mainprog.c rect.h bb.h bb.o : bb.c rect.h bb.h rect.o : rect.c rect.h # copy the output to your Makefile   "});index.add({'id':17,'href':'/notes/CSCC24/Week-7/','title':"Week 7",'section':"CSCC24",'content':"Week 7 #  Type Systems #    Type: Name of a set of values and operations which can be performed on the set\n Alternate: Collection of computational entities that share some common property What is or is not a type, is language dependent    A PL is Type Safe if it won\u0026rsquo;t execute a function if it\u0026rsquo;s not applicable to the arguments\n  Type Checking:\n Static: at compile-time Dynamic: at run-time    Motivation #   Catch all errors at compile-time (impossible, even in theory)  Solution: Guarantee to catch only a certain class of errors   Type safety without explicit declaration  Benefits of Type Systems #    Easier to debug\n  Static analysis - information obtained at compile-time\n  Can compile quicker/more optimized code (save computation, limit memory)\n  Can be used to prove correctness\n  Self documenting code\n  Type Notations (Haskell) #    Int: integers\n  Integer: unbounded integers\n  Float, Double: floating point numbers; single and double precision\n  Char: characters\n  Bool: boolean values\n  TypeA -\u0026gt; TypeB: function that takes in TypeA and returns TypeB\n Every function accepts exactly one argument (can be a tuple)    (): \u0026lsquo;unit\u0026rsquo; - empty tuple\n  (Type1, Type2, ..., TypeN): tuples of Types (heterogeneous)\n  [Type]: list whose elements are all Type\n  Parametric Polymorphism (Type Variables) #   When the type cannot be inferred\n Consider the Haskell function\nprompt\u0026gt; func (x, y, z) = if x then y else z prompt\u0026gt; :t func func :: (Bool, p, p) -\u0026gt; p   p is a Type Variable - any valid type, func is a Polymorphic function\n  $\\alpha \\to \\alpha$: for every valid type $\\alpha$\n i.e. when y, z is of type Int, $\\alpha$ is instantiated to Int    Example:\nprompt\u0026gt; swap (x, y) = (y, x) prompt\u0026gt; :t swap swap :: (t, t1) -\u0026gt; (t1, t)  $(\\alpha, \\beta) \\to (\\beta, \\alpha)$: for valid types $\\alpha, \\beta$  \nType Checking #   The process of verifying + enforcing type constraints\n Dynamic Type Checking #   Performed at run-time\n   Slower execution\n  More flexible/freedom: easier to re-factor\n  Static Type Checking #   Performed at compile-time\n   Faster execution\n  Arguably safer and more elegant/modular programs\n  More compiler optimization\n  Programmers may end up writing worse code to get around static type checkers\nconst o: Type = { foo: 42 }; (o as any).bar = baz;   Explicit Static Typing #   Declaring type annotations in the code\n // explicitly declaring main to be String[] -\u0026gt; void public static void main(String[] boostMyMark) { int x; // declaring x to be of primitive int } Type Inference #   Deduce types without explicitly declaring them\n (define (func x) (if (empty? x) 0 (length x))) ; can deduce that x is a pair, and return value is an int "});index.add({'id':18,'href':'/notes/CSCB09/Week-8/','title':"Week 8",'section':"CSCB09",'content':"Week 8 #  File System with C #  i-nodes #    The file system has an array of \u0026lsquo;i-nodes\u0026rsquo;\n  Every file and directory is identified using an i-node\n  An i-node stores:\n Type: Regular file, dir, link, device, socket, etc. Permissions The owning user and owning group (numerical ids) Size Timestamps (created, last modified) Which disk blocks are used Other metadata    You can get most metadata by using the stat command\nDesktop ~$ stat 2942805567 687 crw--w---- 1 home tty 268435456 0 \u0026#34;Jul 18 13:29:59 2020\u0026#34; \u0026#34;Jul 18 13:29:59 2020\u0026#34; \u0026#34;Jul 18 13:29:59 2020\u0026#34; \u0026#34;Dec 31 19:00:00 1969\u0026#34; 131072 0 0 (stdin)   Directories #   Stores the mapping of filenames to i-node numbers Data structure varies by system The C functions opendir, readdir, closedir can access directories portably  Linking #  Unlinking #   Also known as deleting a file by its filename When deleting a file, the kernel will:  Decrease the reference count of filenames referring to the i-node number If the reference count is now 0, the disk space and the i-node is freed up   System call for delete is unlink  Hard link #   Creates a literal link between 2 files Useful when you want to access a file in an inaccessible directory ln can create another filename that has the same i-node number as an existing file $ ln path/to/file1 path/to/file2 # this creates a \u0026#39;hard link\u0026#39;  The hard link between 2 files will not be broken if one of the file names change or even get deleted Hard linking dirs is disallowed unless implementing special dirs like . and ..  Symbolic Linking (Symlink) #   Special file that simply stores a path (sort of like a shortcut) Most system calls and C library functions/programs follows symlinks Create a symlink using ln -s  Bitwise Operators in C #   Bitwise AND (\u0026amp;), OR (|), NOT (~), XOR (^) Left Shift (\u0026lt;\u0026lt;) and Right Shift (\u0026gt;\u0026gt;) Example: unsigned char a = 10001001; // 8-bit binary unsigned char b = 00000011; a \u0026amp; b = 00000001 // logical AND on each bit a | b = 10001011 // logical OR on each bit a ^ b = 10001010 // XOR on each bit ~ a = 01110110 // flips all bits a \u0026lt;\u0026lt; 1 = 00010010 // shifts all bits 1 to the left b \u0026gt;\u0026gt; 2 = 00000000 // shifts all bits 2 to the right   File Mode Bits #    st_mode bitwise layout\n File Type Permissions ---------------- ------------------------------------------------ | - | - | - | - | U | G | T | R | W | X | R | W | X | R | W | X | ----------- ----------- ----------- User Group Other   Macros for checking individual permissions:\n S_IRUSR: Binary 0000 100 000 000 S_IWUSR: Binary 0000 010 000 000 S_IXUSR: Binary 0000 001 000 000    System Calls for File I/O #  int open(const char *path, int flags); int open(const char *path, int flags, int mode); flags: O_WRONLY, O_RDONLY, O_RDWR, O_EXCL, O_TRUNC, O_APPEND; // Combine flags with bitwise OR  size_t read(int fd, void *buf, size_t count); size_t write(int fd, void *buf, size_t count); off_t lseek(int fd, off_t offset, int origin); origin: SEEK_SET, SEEK_CUR, SEEK_END; // Takes another fdt entry to the same open file table entry int dup(int oldfd); // takes fdt entry to be `newfd` and duplicates `oldfd` to it int dup2(int oldfd, int newfd); int close(int fd); File Descriptor (fd) #   Every process has a finite \u0026lsquo;File descriptor table\u0026rsquo; for opened files The File Descriptor is an array index into it Example of file descriptors:  0: stdin 1: stdout 2: stderr   open() and dup() consumes the lowest-number free entry close() frees entries  "});index.add({'id':19,'href':'/notes/CSCC24/Week-8/','title':"Week 8",'section':"CSCC24",'content':"Week 8 #  Pattern Matching #   Input parameters for a function are matched from top down\n len :: [a] -\u0026gt; Integer len [] = 0 -- if the input is null, returns 0 len (_ : xs) = 1 + len xs The _ represents a \u0026lsquo;do not care\u0026rsquo; value, as its not bound to a variable\nthis.handle((_, event) =\u0026gt; ...); Value Matching in Haskell #  reverse xs = rev xs [] where rev [] rs = rs rev (y : ys) rs = rev ys (y : rs) abs x = if x \u0026gt;= 0 then x else =x abs x | x \u0026gt;= 0 = x | otherwise = -x Type Classes #   Offer a controlled approach to overloading\n   Type Classes basically have lots of types, where each type has implementations of those defined in the class\n  Predifined type classes in Haskell are Eq, Ord, Show, etc.\n  Consider the type for the number 69\n69 :: Num a -\u0026gt; a --- can be Int, Integer, Rational ... This means:\n  Num is the type class\n  Num a is a type class constraint\n  69 is of type a, where a is a type that belongs to the Num type class\n  Type Classes in a function #  member :: Eq t =\u0026gt; (t, [t]) -\u0026gt; Bool --- type t belongs to the Eq class --- instances of type t have the (==) function member (y, (x:xs)) = y == x || member (y, xs) Defining Type Classes #  class TypeClass a where classFunction :: a -\u0026gt; a --- could be any function --- optional: provide a default definition --- Example class Eq a where (==), (/=) :: a -\u0026gt; a -\u0026gt; Bool x == y = not x /= y x /= y = not x == y  If possible, default definitions should be circular  When making an instance of that class, only one needs to be implemented and the other is free    Currying #   Converting a multi-argument function into a sequence of evaluated functions, each with a single argument\n Alternative meaning: The action of cooking a traditional spicy dish of Indian and Oriental origin\n In Haskell, each function takes exactly one argument  Consider multiple ways of writing this function\nsum :: Num a =\u0026gt; (a, a) -\u0026gt; a sum (x, y) = x + y -- curried function sum\u0026#39; :: Num a =\u0026gt; a -\u0026gt; a -\u0026gt; a --- Num a =\u0026gt; a -\u0026gt; (a -\u0026gt; a) --- -\u0026gt; is right associative sum\u0026#39; x y = x + y sum\u0026#39; x = \\y -\u0026gt; x + y sum\u0026#39; = \\x -\u0026gt; \\y -\u0026gt; x + y :t (sum\u0026#39; x) (sum\u0026#39; x) :: Num a =\u0026gt; a -\u0026gt; a --- this is just a function "});index.add({'id':20,'href':'/notes/CSCB09/Week-9/','title':"Week 9",'section':"CSCB09",'content':"Week 9 #  Processes and Redirection #  Launching a New Process #   Clone the process pid_t fork(void); // child gets return value 0, parent gets child\u0026#39;s pid  Both processes (child and parent) run the same code   The child can switch to running another program execlp(path, arg0, arg1, ..., (char *)NULL); // \u0026#39;exec\u0026#39; family of system calls  Things such as environment variables, pid, fd, current dir, etc. are preserved File descriptors can be closed before exec by marking them as close on exec    Why seperate fork and exec? #   Some use cases do not require exec The child process can do some prep before exec (file redirection and pipelining)  The only \u0026lsquo;parent-less\u0026rsquo; process: init #   fork is the only way to launch new processes As the kernel boots, it launches init, with pid 1  Process Commands #   ps: List processes pgrep: Find processes by name, users, etc. top: Process list that periodically refreshes (think of it as a terminal task manager) htop: top, but better (more features) kill and pkill: Terminates a process if allowed (pkill finds like pgrep)  Waiting for a Child process #  pid_t wait(int *status); // status is for child\u0026#39;s exit code pid_t waitpid(pid_t pid, int *status, int options); // pid \u0026gt; 0 -\u0026gt; wait for the given child // pid == -1 -\u0026gt; wait for any child // options == WNOHANG -\u0026gt; don\u0026#39;t hang waiting Useful macros #   Normal Termination:  WIFEXITED, WEXITSTATUS   Killed by signal:  WIFSIGNALED, WTERMSIG, WCOREDUMP   Stopped and continued by signal:  WIFSTOPPED, WIFCONTINUED    Termination of Parent before Child #   If the child terminates first and the parent process is still running and does not call wait  A \u0026lsquo;zombie\u0026rsquo; process of the child retains the entry of the child, but is not actually running   If the parent terminates but the child is still running  The child is now an \u0026lsquo;orphan\u0026rsquo; process and gets the parent pid of init   If the child terminates and the parent calls wait  Just regular termination and no \u0026lsquo;zombie\u0026rsquo;    File Redirection #   Before exec and fork, open the file Duplicate the file descriptor with dup2(curr_fd, new_fd) Close the file descriptor or request close on exec Then call exec  Pipes #  int pipe(int pipefd[2]); // creates a unidirectional pipe // pipefd[0] is for read end // pipefd[1] is for write end  This is how shells do pipelining Usually, only one process at both ends For dup/dup2, stdout for write end, and stdin for read end. Close fds you do not need as soon as possible Kernel has a buffer for unread data if the write end is writing faster than the read end can handle  Signals #   How the kernel notifies processes of some events and severe errors\n Examples #    Interupt (CTRL+C): SIGINT\n  Suspend and Resume: SIGSTOP,SIGCONT\n  Child died/suspended/resumed:SIGCHLD\n  Broken pipe:SIGPIPE\n  Request for termination (shell ‘kill’ default):SIGTERM\n  Hard request for termination:SIGKILL\n  Illegal memory access (two types:SIGBUS,SIGSEGV)\n  Application-specific:SIGUSR1,SIGUSR2\n  Signal Life Cycle #   Some events generate a signal Kernel tries to deliver the signal, and is pending until delivered Normal exec resumes if signal ignored or handler returns normally Shell Command: $ kill -SIGKILL 31337 $ kill -9 31337  System Calls: int kill(pid_t pid, int sig); int raise(int sig); // to self   Signal Actions/Handlers #  int sigaction(int sig, const struct sigaction *act, struct sigaction *oldact)  sig: The signal type act: The new action you want oldact: The old action on fork: Signal actions cloned on exec: Handlers are replaced by default  struct sigaction #  struct sigaction { void *sa_handler(int sig); // pointer to handler function, SIG_IN, or SIG_DFL  sigset_t sa_mask; // mask these signals when running handler  int sa_flags; // options  void *sa_restorer(void); // not for application use } sigset_t Operations #  int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); // add all signals int sigaddset(sigset_t *set, int sig); int sigdelset(sigset_t *set, int sig); int sigismember(const sigset_t *set, int sig); sa_flags Flags #  // If you install handler SA_NODEFER // don\u0026#39;t mask signal when running handler SA_RESETHAND // reset action to default before running handler SA_RESTART // auto-restart most syscalls before running handler  // For SIGCHLD SA_NOCLDSTOP // don\u0026#39;t signal for child stop/cont. SA_NOCLDWAIT // don\u0026#39;t turn terminated child into zombie "});index.add({'id':21,'href':'/notes/CSCC24/Week-9/','title':"Week 9",'section':"CSCC24",'content':"Week 9 #  Infix Operators #   Any curried function that takes 2 parameters can be converted, and vice versa\n x = 3 + 2 -- infix x = (+) 3 2 -- function y = elem 3 [1,2,3] y = 3 `elem` [1,2,3] -- infix Type Synonyms #   Giving existing types an alias or new name\n type NewType = OldType  Useful for readability (String instead of [Char])  User Defined Data Types #  General Syntax:\ndata NewType = Constructor1 Type1 | ... | ConstructorN TypeN   |: represents union of the constructor and types\nexport Type NewType = Type1 | ... | TypeN   TypeI: previously defined types\n  ConstructorI: creates a value of NewType type\n  Type can be omitted if the constructor does not need any argument (constants)\n  Enumerated Types #  data NumberType = Odd | Even --- only constants --- pattern matching on constructors mod2 :: Num a =\u0026gt; NumberType -\u0026gt; a mod2 Odd = 1 mod2 Even = 2 Variant/Union Types #  data Text = Letter Char | Word [Char] --- either a single Letter or multiple letters (word) textLen :: Text -\u0026gt; Int textLen (Letter _) = 1 textLen (Word w) = length w Mutually Recursive Types #  --- parametric polymorphism here data Tree a = Leaf a | Node a (Tree a) (Tree a) --- Tree is a type constructor --- Node is a curried value constructor countNodes:: Tree a -\u0026gt; Int countNodes (Leaf _) = 1 countNodes (Node _ left right) = countNodes left + countNodes right + 1 --- the structure of the function is the same as the data type --- i.e the recursive pattern is the same on both "});index.add({'id':22,'href':'/notes/CSCB09/Week-10/','title':"Week 10",'section':"CSCB09",'content':"Week 10 #  Sockets #   Another way for two processes to communicate\n Characteristics of Sockets #   Has 2 sides: Server and Client  Server: has a publishable address Client: contacts Server by published address   Unrelated processes, even on different computers, can contact each other through sockets  Socket Varieties #  By Domain #   Unix Domain: Local to the computer, address is a filename IPv4: Over the network, 32-bit address + 16-bit port number IPv6: 128-bit address and over the network  By Abstraction Level #   Datagram:  Per packet Packet boundary preserved, packet order is not Unnoticed packet loss   Stream:  Network stack works hard to confirm, timeout, resend Preserves data order No packet boundary    Stream Socket Workflow #  Client #   Call socket, creates the socket fd Fill in the address struct and use connect to connect to the server at the address Use the socket fd to communicate with the server Close the fd when done  Server #   Call socket to create the server socket fd Fill in the address struct and use bind to bind the sfd to the address Call listen Loop  Call accept(sfd) to wait for client to connect, gets back a client fd Use the cfd to communicate with client, close when done   Close the server socket fd if no longer waiting for clients  Creating Sockets #  int socket(int family, int type, int protocol); // returns socket fd \u0026gt; 0, -1 if error  family: AF_UNIX, AF_INET (IPv4), AF_INET6 (IPv6) type: SOCK_DGRAM, SOCK_STREAM protocol: 0  IPv4 Addresses and Port struct #   Adresses are 32-bit, and identifies network interfaces (computers) Each byte is seperated by dots. (ex 142.1.96.164) dig can look up IP Addresses from domain names by asking Domain Name Servers (DNS) Port struct: struct sockaddr_in { sa_family_t sin_family; // AF_INET  in_port_t sin_port; // port, need to be in network byte order  struct in_addr sin_addr; // IPv4 address, also in NBO }; struct in_addr { uint32_t s_addr; }  Special addresses  127.0.0.1: Loopback (You can see this example when using localhost or any web server running on your computer) 0.0.0.0: Request binding to all network interfaces    Endians and Network Byte Order #   Big Endian (Network Byte Order): Left to right (ex. 772 in decimal = 03 04) Little Endian: Bytes are swapped (ex. 772 in decimal = 04 03) Use the library functions htonl (32-bit) and htons (16-bit) to convert from Little to Big Endian  bind, accept and connect #  int bind(int fd, const struct sockaddr *addr, socklen_t addrlen);  sockaddr: sockaddr_in (IPv4), sockaddr_in6 (IPv6), sockaddr_un (UNIX)  int accept(int fd, struct sockaddr *client_addr, socklen_t addrlen);  Returns new socket cfd for talking to client client_addr will recieve the address of client  int connect(int fd, const struct sockaddr *server_addr, socklen_t addrlen);  Returns 0 if success, -1 on error fd can now talk to the server  Broken Pipes #   If one end of the pipe is closed before the other one, the processes gets SIGPIPE The default action is the processes gets killed Eg. $ uniq longFile.txt | head -1 # \u0026#39;head\u0026#39; end of pipe closes after the first line # but \u0026#39;uniq\u0026#39; is still running, hence the process just ends  To override the default, set action to SIG_IGN (ignore)  "});index.add({'id':23,'href':'/notes/CSCC24/Week-10/','title':"Week 10",'section':"CSCC24",'content':"Week 10 #  Short Circuiting #   Defined in most if not all programing languages\n Consider the expression\nif x \u0026gt; 0 and 69 / x \u0026lt; 1: print(\u0026#39;hoe\u0026#39;)  If x happened to be 0, evaluating 69 / x only would result in a division by 0 error The second comparison would only be evaluated if the first was not false  i.e. if x was non-positive, then the rest wouldn\u0026rsquo;t be evaluated, acts as a \u0026lsquo;guard\u0026rsquo;    Laziness #   Only evaluate things when you need to\n Haskell is a lazy language, where everything is evaluated \u0026lsquo;at the very last second\u0026rsquo;.\nConsider this Java code\npublic void m(T x, T y) { // ... } // ... public static void main(String[] boostMyMark) { System.out.println(m(functionThatReturnsX(), functionThatReturnsY())); } When m is called, both functions that are the arguments are evaluated, this is Eager Evaluation.\nNow consider this Haskell code\nand\u0026#39; :: Bool -\u0026gt; Bool -\u0026gt; Bool and\u0026#39; False _ = False and _ x = x and\u0026#39; False (45 / 0 == -1) Due to the pattern matching in the definition of and', the second param will not be evaluated whatsoever, as in that pattern, its a do not care value.\nRecursive Values with Lazy Evaluation #  nats = 0 : map (+1) nats --- [1, 2, 3, 4, ...] GHCI\u0026gt; length nats --- This will never be evaluated, since this is infinite GHCI\u0026gt; take 10 nats [0,1,2,3,4,5,6,7,8,9] --- Works! Since 10 is finite --- fibonacci numbers with list comprehension --- infinite definition, linear complexity fib = 0 : 1 : [x + y | (x, y) \u0026lt;- zip fib (tail fib)] "});index.add({'id':24,'href':'/notes/CSCB09/Week-11/','title':"Week 11",'section':"CSCB09",'content':"Week 11 #  Multiplexing Input and Output #   Handling multiple input/output clients with select and epoll\n select #  int select(int n, fd_set *read_fds, fd_set *write_fds, NULL, struct timeval *wait_timeout);  Blocks until fds are ready Returns 0 if reaches the timeout, else returns positive count if some fds are ready Modifies the given fd_sets, set them again before the next call fd_set: holds a set of file descriptors n: The highest fd you specify, + 1  fd_set functions #  void FD_ZERO(fd_set *s); // empties the set  void FD_SET(int fd, fd_set *s); // adds an fd to the set  void FD_CLR(int fd, fd_set *s); // deletes an fd  int FD_ISSET(int fd, fd_set *s); // queries if fd is in the set Limitations #   Max size for fd_set usually 1024 Slow when using many file descriptors  epoll #   Only available on Linux\n int epoll_create1(int flags);  Creates a new epoll instance Returns the file descriptor of this instance (epfd) flags: 0 or FD_CLOEXEC Instance only useful for other epoll functions  int epol_ctl(int epfd, int op, int another_epfd, struct epoll_event *ev);  Sets what the epoll instance will wait for Returns 0 if successful op: EPOLL_CTL_ADD, EPOLL_CTL_DEL, EPOLL_CTL_MOD ev: Events to wait for  int epoll_wait(int epfd, struct epoll_event *evs, int n, int timeout);  evs: Array to recieve events n: Length of events array Returns count of ready file descriptors  struct epoll_event { uint32_t events; epoll_data_t data; };   You can combine events using bitwise operators\n  events:\n  EPOLLIN: Ready to read\n  EPOLLOUT: Ready to write\n  EPOLLONESHOT: Monitor once only\n  EPOLLET: Notify whenever changes from not-ready to ready\n  EPOLLHUP: Other end of pipe/socket has closed\n  EPOLLERR: Error condition\n    typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t;  You store to this data when calling epoll_ctl Stored data gets returned when you call epoll_wait Usually store the fd, or a pointer to some struct to keep track of history  "});index.add({'id':25,'href':'/notes/README/','title':"R E a D M E",'section':"Home",'content':"Notes \u0026lt;✏️/\u0026gt; #  \nTyped notes for my undergraduate classes at the University of Toronto, Canada.\nCourse Notes thus far:\n CSCA48H3: Intro to Computer Science II CSCB09H3: Software Tools and Systems Programming CSCC01H3: Intro to Software Engineering CSCC24H3: Principles of Programming Languages  src branch:\n Folders containing the actual notes, typed with Markdown starter.tex: Starter File used for LaTeX notes/assignments  master branch:\n Static site generated with Hugo with book theme Automated build from src and deployment using TravisCI and Github Pages  Made with ❤️ by Navinn Ravindaran\n"});index.add({'id':26,'href':'/notes/CSCA48/final-review/','title':"Final Review",'section':"CSCA48",'content':"CSCA48 - Final Review #  Winter 2020 #   If you think it won\u0026rsquo;t work in C, it probably will.\n Units 1 + 2: #    Variables and lockers: #   Uniquely numbered in increasing order, reserved only for the program using the box to store and access information in said box.\n Three ways to get a locker: #   Variable Declaration int boostMyMark = 420; // locker has been created  Return Values return boostMyMark; // new locker has been created, (copied value)  Input Parameters void killAverage(double currentAvg, double midtermMark) {...} // lockers created to store currentAvg, midtermMark     Arrays: #   Fixed length and data type, consecutive boxes allocated in memory and are Passed-By-Reference for function calls.\n Array Declaration: #  int crunchyArray[10]; // creates 10 consecutive boxes of memory Strings: #   Array of chars End-of-string delimiter: \u0026lsquo;\\0\u0026rsquo;    Pointers: #   Just a variable (own space in memory), and stores a memory address in its locker of the same data type.\n Example:\nint num = 69; // creates locker int *p = \u0026amp;num; // the contents of (*) p gets the address of (\u0026amp;) num *(p) ++; // increments the contents of (*) p Arrays and Pointers: #   Arrays get passed as a pointer in a function (index 0) int arr[3] = {1, 2, 3}; // 3 new consecutive lockers for arr int *p = NULL; // empty pointer // the following are equivalent p = \u0026amp;arr[0]; // p gets the address of the value of arr at index 0 p = arr; // p gets the start of arr  Arrays can be iterated using an offset pointer or the indicies int nums[5] = {1, 2, 3, 4, 5}; int *p = nums; // \u0026amp;nums[0] for(int i = 0; i \u0026lt; 3; i++) { // the following are equivalent  printf(\u0026#34;%d\\n\u0026#34;, nums[i]); // nums at index i  printf(\u0026#34;%d\\n\u0026#34;, *(p + i)); // the contents of memory address (p + i) }     Unit 3: #    Dynamic Memory Allocation #   Reserving space in memory so it doesn\u0026rsquo;t get released when your function exits\n Initializing on the stack versus the heap: #  int crunchyFunction() { int stackNum = 69420; // allocates memory on the stack  int *heapNum = (int *)calloc(1, sizeOf(int)); // allocates on the heap  return 0; } After the function exits, stackNum will be released from memory but heapNum must be freed by the user\nfree(heapNum); Malloc: #   Does not clean up, but is faster than calloc, just be careful. Type *type_name = (Type *)malloc(numOfElements, sizeOf(Type)); free(type_name); //same as calloc     Dynamic Arrays #   Taking the best parts of Arrays ($O(1)$ lookup, consecutive boxes in memory) but without fixed length constraint.\n Essentially, when an array of size $N$ is at capacity (check using a counter variable), create a new array of size $2N$, and copy existing elements over to the new array\nint *infiniteChocolateCopy(int someChocolate[n], int n) { int *moreChocolate = (int *)calloc(2 * n, sizeOf(int)); // allocates size 2n on the heap  for(int i = 0; i \u0026lt; n; i++) { //iterates through someChocolate  *(moreChcolate + i) = someChocolate[i]; //copies over  } return moreChocolate; }   Compound Data Types #   Storing multiple components of data types (primitive and/or compound), packaged into a single container. Used when storing information too complex for a single data type.\n Defining a CDT struct: #  typedef struct student_struct { // creates the struct  char name[1024]; int year; double gpa; Markbook *marks; // example of passing a CDT pointer (CDT-ception)  // as many as you want here } Student; Initializing a CDT: #  Student *sweaty_nerd = (Student *)calloc(1, sizeOf(Student)); // allocate memory strcpy(sweaty_nerd-\u0026gt;name, \u0026#34;TryHard on Piazza\u0026#34;); // for strings sweaty_nerd-\u0026gt;year = 2023; // arrow (-\u0026gt;) operator for pointers sweaty_nerd-\u0026gt;gpa = 2.718; sweaty_nerd-\u0026gt;marks = bad_marks; Memory Model: #   CDT\u0026rsquo;s get one locker for all of it\u0026rsquo;s contents (like a Bento Box) Passing a CDT into a function: myCDT randomCrunchyCDTFunction(myCDT crunch) { // makes a copy (not passed-by-ref)  ... return crunch //returns a copy } It is typical to pass and return CDTs as a pointer, instead of copying\n    Abstract Data Types #   Implementation independent! It is just the idea of a container that stores a collection of data.\n List ADT: #   Stores items sequentially in nodes not necessarily consecutive, containing a reference to the next node in the list Not fixed in length Head: 1st node in list Tail: last node in list Typical operations, $O(N)$ worst case:  Insert Remove Update Search   Queue ADT: FIFO (first-in-first-out) Stack ADT: FILO (first-in-last-out)  Linked List: #   Best used when data is added and queried in random order.\n   Basic dynamic implementation of List ADT\ntypedef struct linked_list_struct { int data // payload (can be any type)  struct linked_list_struct *next; // pointer to the next node in the list, NULL if tail node } ListNode;   Iterating through a Linked List\nfor(ListNode *n = head; n != NULL; n = n-\u0026gt;next);   Insert\n  At head - $O(1)$ complexity:\nListNode *wantToInsert = (ListNode *)calloc(1, sizeOf(ListNode)); wantToInsert-\u0026gt;data = 51 // coincidentally the course midterm average wantToInsert-\u0026gt;next = head; // where head is the head of the LL   At tail - $O(N)$ complexity:\n//same initialzation of wantToInsert as 1. ListNode *n = head; if(head != NULL) { // always check if head is not null to avoid errors  for(; n-\u0026gt;next != NULL; n = n-\u0026gt;next); // traverses until at the tail  n-\u0026gt;next = wantToInsert; // sets the tail as wantToInsert }   Somewhere in between\n//same initialzation of wantToInsert as 1. ListNode *n = head; if(head != NULL) { for(; n-\u0026gt;data != insertHereNum; n = n-\u0026gt;next); // traverses list  wantToInsert-\u0026gt;next = n-\u0026gt;next; // links wantToInsert to n-\u0026gt;next  n-\u0026gt;next = wantToInsert; // links n to wantToInsert } Note: When inserting inside the list, we would use a condition to compare unique identifiers so we know exactly where to insert. For this example we assumed all the numbers were distinct and we knew insertHereNum\u0026rsquo;s value was given and inside the Linked List.\n    Search - $O(N)$\n Traverse from head Check if current node is the desired node using a compare operation/function (see Note) Return  A pointer of the desired node, user can modify the node and list A copy of the data type (compound/primitive), user cannot modify the node and list      Delete - $O(N)$\nListNode *p1 = head; ListNode *p2 = NULL; // is always 1 node behind p1 if(head != NULL) { for(; p1 != NULL \u0026amp;\u0026amp; p1-\u0026gt;data != wantedNum; p2 = p1, p1 = p1-\u0026gt;next); //traverses through LL, one behind the other until wantedNode is found  if(p1-\u0026gt;data == head-\u0026gt;data) p2 = head-\u0026gt;next; // only if the wantedNode is the head  else p2-\u0026gt;next = p1-\u0026gt;next; // all other cases, links the node before wantedNode with the node after  free(p1); // releases the node from the list }     Unit 4: #    Computational Complexity: #   Measuring the amount of work done by an algorithm as a function of the number of data items the algorithm is working on, and thus predicting how algorithms will preform against each other without having to test on large $N$ values.\n The Big $O$ Notation #   Comparing algorithms in a machine and implementation dependent manner.\n   Mathematically put, $$ f(x) = O(g(x)) \\iff \\exists c \\in \\mathbb{R}_{\u0026gt;0} \\text{ such that for sufficiently large } x \\text{, } \\newline |f(x)| ≤ c \\text{ } \\cdotp{g(x)}, \\quad x \u0026gt; x_0 $$\n$O(g(x))$ is the smallest function of $N$ that puts an upper bound on $x$\n  Given a set of candidate algorithms, the fastest algorithm will have the slowest growing Big $O$ complexity.\n  In terms of efficiency, $$ O(1) \u0026lt; O(log (N)) \u0026lt; O(N) \u0026lt; O(Nlog(N)) \u0026lt; O(N^2) \u0026lt; O(N^3) \u0026lt; O(2^N) \u0026lt; O(N!) $$\n  Binary Search for Arrays #   Array must be sorted Complexity of $O(log_2(N))$ Procedure (Pseudocode): int binarySearch(int wantedNum, int Array[]) { int middleNum = Array[floor(length / 2.0)]; // finds middle index (floor if odd length)  if(wantedNum == middleNum) { return index(middleNum); // returns index of middleNum in Array  } else if (wantedNum \u0026gt; middleNum) { binarySearch(wantedNum, Lower Half of Array); // all values greater than middleNum  } else { binarySearch(wantedNum, Upper Half of Array); // all values less than middleNum  } }   Complexity of Linked Lists versus Arrays #   All basic operations on a Linked List have worst case $O(N)$ complexity. Unsorted Array:  Search:  Index lookup: $O(1)$ Linear search: $O(N)$ Sort: make a reasonable assumption :^)     Sorted Array:  Search:  Index lookup: $O(1)$ Binary Search: $O(log(N))$      The Consequence of Sorting #    Bubble Sort:\n Traverse the array and swap adjacent decreasing entries until the array is sorted.\n Worst-Case Complexity: $O(N^2)$\nvoid notSoCrunchyBubbleSort(int array[], int N) { for(int i = 0; i \u0026lt; N; i++) { // N iterations  for(int j = 0; j \u0026lt; N - 1; j++) { // N - 1 iterations  if(array[j] \u0026lt; array[j-1]) { // compares if the adj. entries are decreasing  swap(array[j], array[j+1]); } } } }   Quick Sort (qsort):\n Choose a random pivot, split elements into 2 arrays: values less than the pivot, and values greater than or equal to the pivot. Repeat until all sub-arrays have lengths ≤ 1. Reconstruct the now sorted array.\n  Average-Case Complexity: $O(Nlog(N))$ (not so crunchy) Worst-Case Complexity: $O(N^2)$ (first/last entry pivot $\\rightarrow$ insertion sort)    Insertion Sort:\n Build the sorted array in place (no splits), shifting elements as we traverse the array to sort.\n  Best-Case Complexity: $O(N)$ Worst-Case Complexity: $O(N^2)$ Procedure:  Choose first element to be \u0026ldquo;sorted\u0026rdquo; Look at next element in array, and insert it inside the \u0026ldquo;sorted\u0026rdquo; portion by comparing it to the values in said portion. Repeat 2. until the end of array        Trees #   A generalization of Linked Lists, linking one node in the Tree to sucessor (children) nodes. Recursive in nature, each sub-tree is also a Tree.\n Binary-Search Trees (BST) #   Variation of a Binary Tree (left and right children only) such that the BST property holds for each node and duplicate nodes are not allowed.\n   BST Property:\n Data in nodes on the left sub-tree are less than or equal to data in the root node Data in nodes on the right sub-tree are greater than data in the root node    Basic Implementation\ntypedef struct dollarStoreChocolate_BST_Struct { int data; struct dollarStoreChocolate_BST_Struct *left; // left child pointer  struct dollarStoreChocolate_BST_Struct *right; // right child pointer } BST_Node   Search - $O(log(N))$:\nif(root == NULL) return NULL; else if(givenData == root-\u0026gt;data) // check root  return root; else if(givenData \u0026lt;= root-\u0026gt;data) return search(root-\u0026gt;left, givenData); // search left sub-tree else return search(root-\u0026gt;right, givenData); // search right sub-tree   Insert - $O(log(N))$\n// assuming new_node was initialized and correctly allocated to the heap if (root == NULL) // empty tree  return new_node; // inserts at root else if (new_node-\u0026gt;data \u0026gt; root-\u0026gt;data) root-\u0026gt;right = insert(root-\u0026gt;right, new_node); // inserts in right sub-tree else root-\u0026gt;left = insert(root-\u0026gt;left, new_node); // inserts in left sub-tree return root; Note: Just like Linked Lists, we must use our own comparison function if the data in the node is a CDT.\n  Traversal - $O(N)$\n In Order - For listing a BST in sorted order: if (root != NULL) { inOrder(root-\u0026gt;left); // traverses left sub-tree  printf(\u0026#34;%d\\n\u0026#34;, root-\u0026gt;data); // any operation can be preformed  inOrder(root-\u0026gt;right); // traverses right sub-tree }  Pre Order - For Copying an entire BST: if (root != NULL) { printf(\u0026#34;%d\\n\u0026#34;, root-\u0026gt;data); // operation  preOrder(root-\u0026gt;left); // traverses left sub-tree  preOrder(root-\u0026gt;right); // traverses right sub-tree }  Post Order - For deleting an entire BST: if (root != NULL) { postOrder(root-\u0026gt;left); // traverses left sub-tree  postOrder(root-\u0026gt;right); // traverses right sub-tree  printf(\u0026#34;%d\\n\u0026#34;, root-\u0026gt;data); // operation }     Delete - $O(log(N))$\n Searching for node to delete is the same implementation as Insert and Search No children: free(root); // if only the final exam was as simple as this  One Child:  Left only BST_Node *temp = root-\u0026gt;left; // points to left child free(root); return temp;  Right only BST_Node *temp = root-\u0026gt;right; // points to right child free(root); return temp;    Two Children: BST_Node *temp = find_successor(root-\u0026gt;right); // smallest node in the right subtree copyNode(root, temp); // copies all the data from temp to the root root-\u0026gt;right = delete(temp); // deletes the successor recursively return root;     Complexity of Binary Search Trees versus Linked Lists and Arrays #    Building the data structure:\n LL: $O(N)$ BST: $O(Nlog(N))$ Array + Merge Sort: $O(Nlog(N))$    Search:\n LL / Unsorted Array: $O(N)$ BST: $O(Log(N))$ Sorted Array: $O(Log(N))$    Space Complexity:\n Array: Fixed size LL: $O(N)$ BST: $O(N)$      Unit 5: #    Graphs: #   A model to represent items and their relationships between them. Composed of Nodes (Verticies) and Edges, with optional direction and weight.\n $$ G=(V,E) $$\nGraph Representation #    Direction:\n Undirected: Two way relationship Directed: One way relationship    Neighbourhood:\n The neighbourhood of Node U is the set of all nodes that are neighbours of Node U.\n   Neighbour: 2 Nodes are considered neighbours if they are joined by an edge\nDirected Example: Node U $\\rightarrow$ Node V\n  In-neighbour: U of V\n  Out-neightbour: V of U\n  In-neighbourhood: Edges arriving at Node U\n  Out-neighbourhood: Edges leaving Node U\n      Degree:\n The size/dimension (number of nodes) in the neigbourhood of the Node.\n  In-degree: Degree of In-neighbourhood Out-degree: Degree of Out-neighbourhood    Traversals:\n Breadth First Search (BFS) - By path of neighbours Depth First Search (DFS) - Level by level    General Applications of Graphs #    Social Networks\n  Transportation (Maps services)\n  Genomics and Bioinformatics\n  Computer Networks and the Internet\n  Representing Graphs #    Adjacency List:\n An array with one entry per node. Each entry points to a linked list containing the neigbourhood for that node.\n   Adjacency Matrix:\n A 2D $N\\text{ x }N$ matrix, $N$ is the number of nodes in the graph. If Node $i$ and Node $j$ share an edge then AdjMat[$i$][$j$] \u0026gt; 0. For Undirected graphs, AdjMat[$i$][$j$] $=$ AdjMat[$j$][$i$]\n   Operation Complexity on Graphs #   $N = |\\text{Vertices}|$ is the number of nodes in the graph, and $M= |\\text{Edges}|$ is the number of edges in the graph\n     Operation Adjacency List Adjacency Matrix     Edge Query $O(N)$ $O(1)$   Inserting a Node $O(1)$ $O(N^2)$   Removing a Node $O(M)$ $O(N^2)$   Inserting an edge $O(1)$ $O(1)$   Removing an edge $O(N)$ $O(1)$       Principles of Recursion: #   The repeated application of a recursive procedure. Can make some problems super trivial to solve.\n Types of problems that benefit from recursion: #   Sudoku, N Queens (pretty c r u n c h y) BST Operations (duh) Graph Operations (every sub-graph is still a graph) Search and Path Finding (BFS and DFS)   Generally any problem that contains a smaller version of itself as a sub-problem.\n The process of designing a recursive solution #   Base Case(s):  Specific to the problem itself, multiple can exist The smallest problem with a trivial solution Any solution must always reach the base case   Recursive Case:  Multiple ways to split the problem at hand, some better than others After each recursive call, the sub-problem must be closer to the base case Always best to visually interpret/draw out the solution    Recursive Sort and their complexities #    DoofusSort/chewySort/notAProGamerSort:\n First Entry goes into one sub-array, the rest into another Recursively sort each sub-array Merge to form the sorted array  Complexity:\n Worst Case: $O(N^2)$ (Essentially Insertion Sort)    Merge Sort:\n Choose the middle entry as pivot Split into 2 sub-arrays, one less than, one greater than or equal Recursively sort each sub-array Combine to form the sorted array  Complexity:\n Worst Case: $O(Nlog(N))$ (Super Duper Crunchy)    qsort:\nSee: The Consequences of Sorting\n  The Memory Model #   Each time a recursive call has been made, part of the stack is reserved (stack frame) for variables, parameters and return type. Each stack frame will only be cleared until each recursive call is completed.\n  Stack Overflow (like the webpage):  Results when the stack has ran out of empty space Recursive solution must reach the base case in a reasonable number of steps Tail Recursion can prevent this  The recursive call would be the last thing the function does before returning Similar to an iterative solution, better for DEEP recursive solutions        Unit 6: #    Software Design: #   Developers are lazy, we need modular solutions to be as useful for others as possible.\n Properties of good software design #    Modularity\n Does one thing, ridonkulously well. Minimizes code replication Simplifies testing and debugging    Reusablity\n Any module can be reused by other applications requiring that specific task.    Extendibility\n Software that is easy to improve and extend its functionality and usability.    Maintainablity\n Organized, explicit and so well-commented that a noob would understand it.    Correctness\n Devs may be lazy, but they aren\u0026rsquo;t super lazy. Include detailed documentation and test cases.    Efficiency\n Gotta go fast, $O(1)$ or bust.    Openness\n You\u0026rsquo;re not a giant tech company, contribute to the open source software community.    Privacy and Security\n Secure data exchanges and reliable and safe solutions over personal/enterprise networks.      Application Programming Interfaces (APIs) #   Interacting with software modules, without having to understand how they work internally.\n  Use-case: Specific situation in which components of the API may be used Dependency: The relationship of one module requiring another module in order to function  Properties of a good API #   Easy to maintain Easy to extend and improve Easy to learn Difficult to use incorrectly Suitable for those who will be using it  Expanding an API #   Must consider required use-cases for each module Applications that rely on the API must not experience any significant impacts if expanded  Method overloading is a good workaround for any CRUNCHY use-cases after the initial rollout   If a bad API is expanded/modified, any software relying on said API will most likely stop functioning correctly  Limitations of C #   Basically C is !(OOP).\n  No Encapsulation and Information hiding No Polymorphism or Inheritance No Method overloading    Object Oriented Programming (OOP) #   Model for developing software components based on Encapsulation.\n  Encapsulation:  Wrapping required components together to implment the functionality of a data type. Hides data and functionality from the user using Access Control Modifiers to prevent misuse.   Access Control Modifiers:  Private: Accessed only by the class that its in  Protected: Gives inherited classes access to the parent class\u0026rsquo;s private data   Public: Can be accessed by any code outside of the class    Method Overloading #   Methods with the same name, but with different input parameters, return type and implementation.\n   Useful for multiple use-cases in which that particular solution is needed\nExample (Java):\npublic int addNumbers(int a, int b) { return a + b; } // same name but different return type and input parameters public double addNumbers(double a, double b, double c) { return a + b + c; } _\n  Classes and Objects #   The template/blueprint for building objects and their variables and methods.\n  Components of a class:  Private member variables  Used inside the class only   Constructor  Creates new instances/objects Assigns values to the input paramenters for the instance   Destructor  Called when finished with the class   Object Methods  Any functions declared in the class that an object can use      An example of an object class (Java):\nclass ComputerScienceNerd { // initialize the class  // initializes member variables for ComputerScienceNerd object  private String name; private double gpa; public ComputerScienceNerd(String name, double gpa) { // object constructor  // private variables (this.) get the parameter values  this.name = name; this.gpa = gpa; } /* * Object methods, public in nature * Call the method with (ComputerScienceNerdObject).method(); */ String getName() { return name; } double getGPA() { return gpa; } void screech() { System.out.println(\u0026#34;bY ThE WaY, dId yOu kNoW I\u0026#39;m iN CoMpUtEr sCiEnCe?\u0026#34;); } } Polymorphism and Inheritance #    Inheritance:\n The idea of passing methods and definitions to a hierarchy of Children classes.\n  A Child class inherits the same \u0026ldquo;traits\u0026rdquo; as the Parent class Example:  Parent Class: Instrument Child Class: WindInstrument inherits Instrument Child Class: Flute inherits WindInstrument   The \u0026ldquo;is a(n)\u0026rdquo; Test implies possible inheritance  \u0026ldquo;Flute is an instrument\u0026rdquo; $\\rightarrow$ Flute can inherit Instrument      Polymorphism:\n The idea that similar classes should be used the same way. Different objects belonging to the same inheritence hierarchy may posses the same functions, but the behaviour is characteristic to the object itself.\n Example (Pseudocode):\nClass Instrument { Instrument() { double duration; double freq; } playNote() { play(duration, freq); // generic implementation set by Parent class  } } Class Guitar extends Instrument { // child of Instrument  Guitar() { Instrument(); // uses the same constructor as parent class  } playNote() { // overrides the playNote() from the parent  // implementation here is specific to the Guitar class  } } Class Piano extends Instrument { // child of Instrument  Piano() { Instrument(); // uses parent constructor  } playNote() { // overrides the playNote() from the parent  // implementation here is specific to the Piano class  } } Obviously, a Guitar and a Piano do not sound the same (unless you\u0026rsquo;re deaf). As a result, playNote() should be modified for each different sounding instrument. The idea/functionality of playNote() must be the same, regardless of which Child is calling it.\n  Abstract Classes #   A class that only declares methods, and any subclass must provide implmentations for each method.\n  A Parent class that lets its children hold all implementations Example:  Parent Class: Instrument  Methods: playNote(), tunePitch(), smashOnSomeonesHead() No implementations   Children Classes: Piano, Guitar  Methods: Same as parent but each child has a different implementation  Piano: smashOnSomeonesHead() $\\rightarrow$ \u0026quot;Smash Head on Piano\u0026quot; Guitar: smashOnSomeonesHead() $\\rightarrow$ \u0026quot;Smash Guitar on Head\u0026quot;          "});index.add({'id':27,'href':'/notes/CSCC01/final-review/','title':"Final Review",'section':"CSCC01",'content':"CSCC01 - Final Review #  Fall 2020 #   The fix from StackOverflow isn\u0026rsquo;t working\n Software Development - The Agile Mindset #   Iterative approach to software development\n Values of the Agile Manifesto: #   Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan  User Stories #   Short, simple descriptions for features as told by the end-user\n Commonly follows the template:\nAs a \u0026lt;User\u0026gt;, I want (to) \u0026lt;Goal\u0026gt;, (so that)/(in order to) \u0026lt;Value\u0026gt;   Never more than 2 brief sentences, but usually one\n  Template should not mention any technical detail/requirement, only end-user related details\n  Often written on index cards, but can be referenced on a Sprint/Kanban board\n  All three attributes (User, Goal, Value) must be mentioned in a user story\n  To further add detail to a User Story, mention a clear Acceptance Criteria or if need be, break it down into smaller stories/sub-tasks\n  What makes a good user story? (INVEST)\n Independent Negotiable Valuable Estimatable Sized Appropriately Testable    Burn Down Chart #   Tool for collecting sprint/project data\nhttps://www.projectmanager.com/blog/burndown-chart-what-is-it\n   Used for viewing how much work is left w/r/t how much time is left\n  Usually, x-axis is measured in days/weeks, and y-axis is measured in story points\n  The \u0026lsquo;Ideal Work Remaining Line\u0026rsquo; is a straight line connecting the start of the sprint to the end linearly\n  The \u0026lsquo;Actual Work Remaining Line\u0026rsquo; is the actual work that has been done throughout the sprint, and hence deviates above or below from the ideal\n  Having a visual represenation of progressional data keeps the team more informed and on the same page\n  Doesn\u0026rsquo;t show whether the team is working on the right things\n  Depending on how well of an estimate user stories are story pointed, this chart may not accurately show if a team is on track or not\n  Critical Path #   The sequence of activities that will take the longest to complete, determining the overall length of the project\nhttps://www.mountaingoatsoftware.com/blog/the-critical-path-on-agile-projects\n   Can be answered 2 ways:\n What is the CP within an Iteration? What is the CP within a project?    CP can be quickly identified when certain user stories lead/build upon the next/previous one\n  Easy to spot due to a short iteration length\n  Must be considered by the team, but does not have to be very formal\n  Useful when you need to consider future dependencies along the line that may affect what is currently being developed\n  Agile Frameworks #    Scrum\n Set of meetings, tools, and roles that work in concert to help teams structure and manage their work.\nhttps://www.atlassian.com/agile/scrum\n   Centered around continuous improvement and adjustment\n  Structured to help teams natually respond and adapt to change in a timely manner\n  Scrum Master dedicated to co-ordinating the scrum and resolving blockers\n  Sprints:\n Short, time-boxed period of time where the scrum works to complete a set amount of work Common sprint length is 2 weeks, but can range from 1 week to 1 month    Scrum Meetings:\n  Sprint Planning Meeting:\n Determine the User and Technical Stories that will be worked on during the current sprint Sprint Estimates (Story Pointing) may or may not occur during this meeting    Daily Standup:\n Brief meeting involving the whole scrum, highlighting progress and identifying blockers Must be done at the same time every day, preferably at the same location Usually done standing up, but should reference the Scrum Board No \u0026lsquo;code-talk\u0026rsquo; during this meeting Participants must answer the following:  What have you done since yesterday? What are you planning on doing today? Any impediments or stumbling blocks?      Backlog Refinement:\n Story Point items found in the backlog Common pointing schema is Fibonacci (1, 3, 5, 8, 13,\u0026hellip;) Story Points represent the relative required amount of effort Must refer to Definition of Done (DoD) and collective effort (Dev + QA)    Sprint Retrospective:\n Meeting to reflect on the completed sprint Must ask what went well, and what did not Solutions to fix mistakes are proposed for the next sprint        Kanban\n Real time communication of capacity and full time transparency of work\nhttps://www.atlassian.com/agile/kanban\n  Work items are represented on a central Kanban Board Board should be seen as the \u0026lsquo;single source of truth\u0026rsquo; for the team\u0026rsquo;s work Entire team\u0026rsquo;s responsiblity to ensure work is moving smoothly through the board Each work item is represented by a single Kanban Card and is positioned in swimlanes based on the state of completion Example swimlanes include To Do, In Progress, In Review, Waiting on QA, Done    Test Driven Development (TDD)\n Develop tests before writing the code.\n   The tests become sort of like the \u0026lsquo;acceptance criteria\u0026rsquo; or specification for development\n  Traditionally, TDD means:\n Write failing test cases Write the minimum amount of code to pass the test(s) Repeat with occasional refactoring    Agile teams can adopt TDD with different types of testing:\n Unit Testing Integration Testing Product Acceptance Criteria (Customer Requirement) Testing Regression Tesing      Extreme Programming (XP)\n Iterative Incremental model incorperating TDD\n  Customer\u0026rsquo;s decisions drive the product Development team works directly with Product Owner or Domain Expert Focused on delivering working software rather than documentation    Software Design #   It\u0026rsquo;s a design choice\n Coupling #   How much a class is directly linked to another class\n   High coupling between classes means that changes to one class may lead to changes in the other coupled classes\n  Low coupling is desired\n  Cohesion #   How much the features of a class belong together\n   Low cohesion means that methods in a class operate on unrelated tasks. This means the class does jobs that are unrelated\n  High cohesion means that the methods have strongly-related functionaly.\n  Dependency Injection #   Seperate the responsibility of resolving object dependency from its behaviour\n   It is an Enterprise Design Pattern: used in enterprise applications\n  The Injector module is basically a container, and owns the life cycle of all objects (classes) defined/instantiated under its scope\n  Many different ways to implement dependency injection (ex. Dagger2, Angular)\n  Needs to be instructed/configured to signal that a class has certain dependencies and how to resolve them   Constructor Injection (Java)\npublic class MarkBooster { private CheatSystem cheater; @Inject // signals injector that MarkBooster has CheatSystem as dependency  public MarkBooster(CheatSystem cheater) { this.cheater = cheater; } } Setter Injection (Java)\npublic class MarkBooster { private CheatSystem cheater; // default constructor  public MarkBooster() {} @Inject // resolves CheatSystem dependency  public void setCheater(CheatSystem cheater) { this.cheater = cheater; } } SOLID principles of design #  Single responsiblilty principle: #    A class should have one and only one reason to change\n  The responsibility should be encapsulated by the class\n  All services for that class should be aligned with that responsibility\n  Open/closed principle: #    Open: Available for Extension\n  Closed: Available for use by other modules\n  Classes should be open for extension but closed for modification\n  Add new features by extending the class, which may or may not have the same interface(s) as the original class\n  Liskov substitution principle: #    Subclasses should add to a base class\u0026rsquo;s behavior, not replace it\n  If S is a subtype of T, then objects of type S may be subbed for objects of type T without altering any of the desired properties of the program\n  Interface segregation principle: #    No client should be forced to depend on methods it does not use\n  Many client-specific interfaces are better than one general-purpose interface\n  Easier to extend and modify the design\n  Dependency inversion principle: #    High-level code shouldn\u0026rsquo;t depend on low-level code. Both should depend on abstractions. It addition, abstractions shouldn\u0026rsquo;t depend on details\n  Develop high level classes first, then develop lower-level classes\n  Details depend on abstractions, not concretions\n  "});})();