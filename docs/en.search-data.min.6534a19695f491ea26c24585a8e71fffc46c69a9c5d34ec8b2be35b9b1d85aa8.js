'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/notes/CSCB09/Week-1/','title':"Week 1",'section':"CSCB09",'content':"Week 1 #  Processes #   What happens when you run a program.\n   Has Input and Output ends:\n stdin: Standard Input - eg. Keyboard input goes through stdin stdout: Standard Output - eg. Terminal output (printing to screen)  eg.\nNavinns-MacBook-Pro:~ home$ sort # OS connects keyboard to stdin Watermelon Apple Strawberry Mango ^D # \u0026#39;exit\u0026#39; keybind, OS connects screen to stdout Apple Mango Strawberry Watermelon   Pipelining and Redirection #   Routing outputs of one program to the input of another, and outputting to a file instead of the screen.\n eg.\nNavinns-MacBook-Pro:Desktop home$ cat myfile # screen is connected to stdout # starting text This this is is a file haha haha Navinns-MacBook-Pro:Desktop home$ cat myfile | sort | uniq \u0026gt; myNewFile \u0026amp;\u0026amp; cat myNewFile # myfile -\u0026gt; stdin of cat =\u0026gt; stdout -\u0026gt; stdin of sort =\u0026gt; stdout -\u0026gt; stdin of uniq =\u0026gt; stdout -\u0026gt; myNewFile This a file haha is this Scripting #   Combining shell commands, instead of being redundant.\n eg.\n  Redundant commands:\nNavinns-MacBook-Pro:Desktop home$ cat mywords | sort | uniq \u0026gt; mywords-unique Navinns-MacBook-Pro:Desktop home$ cat yourwords | sort | uniq \u0026gt; yourwords -unique Navinns-MacBook-Pro:Desktop home$ cat badwords | sort | uniq \u0026gt; badwords -unique   Simple For-Loop script:\nfor w in mywords yourwords badwords; do cat $w | sort | uniq \u0026gt; $w-unique done   Devices and Services #   Presented as files in Unix.\n  Unix kernal creates file names and emulates file operations, known as \u0026lsquo;Special Files\u0026rsquo;  eg.\n/dev/sda # Hard disk as a special file, restricted /dev/zero # Endless stream of 0\u0026#39;s as bytes # To wipe a hard disk clean: Navinns-MacBook-Pro:~ home$ dd bs=4K if=/dev/zero of=/dev/sda Terminology #    Kernel: Decides which processes may run, and what it can access\n  OS Processes: More services, features, and background monitoring not in the kernal\n  Shell: Command-line user interface\n  User Processes: Your processes\n  The Unix Philosophy #    Consisting of small programs, that do one thing really well\n  Scripting + Pipelining versus rewriting bigger programs for complex tasks\n  Recursive file-like structure\n  Short and Simple program names - eg. cp: copies files\n  "});index.add({'id':1,'href':'/notes/CSCA48/','title':"CSCA48",'section':"Home",'content':"CSCA48 - Intro to Computer Science II #  Semester Taken: Winter 2020\nProgramming Language: C\nCourse Description:\n  Abstract data types and data structures for implementing them Linked data structures Object Oriented Programming  Encapsulation and information-hiding Testing Specifications   Analyzing the efficiency of programs Recursion   Course Page\n"});index.add({'id':2,'href':'/notes/CSCB09/','title':"CSCB09",'section':"Home",'content':"CSCB09 - Software Tools and Systems Programming #  Semester Taken: Summer 2020\nProgramming Languages: Bash shell, C\nCourse Description:\n Software techniques in a Unix-style environment, using scripting languages and a machine-oriented programming language (typically C). What goes on in the system when programs are executed.\nCore topics:\n Creating and using software tools, pipes and filters File processing, shell programming, processes, system calls, signals, basic network programming.   Course Page\n"});index.add({'id':3,'href':'/notes/CSCB09/Week-2/','title':"Week 2",'section':"CSCB09",'content':"Week 2 #  File Management #   How we survived without File Explorer\n Directory Tree #  / ├── Applications ├── Library ├── System ├── *Users* ├── Volumes ├── bin ├── cores ├── *dev* ├── etc -\u0026gt; private/etc ├── *home* -\u0026gt; /System/Volumes/Data/home ├── opt ├── private ├── sbin ├── tmp -\u0026gt; private/tmp ├── *usr* └── var -\u0026gt; private/var Paths #    Absolute Path: from root dir\n eg. /Users/home/projects/course-notes/index.html    Relative Path: from current dir\n eg. course-notes/index.html (if current dir is /Users/home/projects/)    Parent Directory: ..\n  Directory Itself: .\n Some commands require the dir name, . simplifies this task    Commands #    pwd: print working directory\n  cd: change directory\n  ls: list\n -a || -A: include dotfiles (. for -a, .. \u0026amp;\u0026amp; . for -A) -l: include more information (size, modification time, etc.) -d: include only directories -t: sort by modification time -r: reverse order -R: recursive list, whole subtree    mkdir: make directory\n  cp: copy\n -R: recursive copy, can possibly overwrite    mv: move\n Can possibly replace existing files    rmdir: remove dir\n Precondition: the current dir is empty    rm: remove/delete file(s)\n -r: recursive delete, used for non-empty directories No \u0026ldquo;Recycle Bin\u0026rdquo;/Trash    Core Utilities #    cat: concatenation\n Copy files and/or stdin to stdout eg. $ cat file1 file2 ... # dumps file1 ... # dumps file2 $ cat file1 - file2 ... # dumps file1 ... # user input as stdin, use ctrl+D to exit and continue ... # dumps file2 $ sort myFile | uniq | cat file1 - file2 ... # dumps file1 ... # dumps myFile after sorting and uniq ... # dumps file2     head and tail:\n head starts from start of file, tail starts from last eg. $ head -3 # output first 3 lines $ head -n -3 # output all except last 3 lines $ tail -3 # output last 3 lines $ tail -n +3 # output starting from and including line 3     wc: word count\n Can count by words (-w), bytes (-c), lines (-l), characters (-m) eg. $ wc file1 2 6 27 file1 # 2 lines, 6 words, 27 bytes     sort:\n Sort, check if sorted, merge sorted Default sort by whole-line eg. # sample input Navinn CS 420 UofT Expensive 69 GiveJobPls iNeedJob 180 $ sort -b -k 3,3n # sort by key=3rd field, parse 3rd field as number UofT Expensive 69 # lowest number GiveJobPls iNeedJob 180 Navinn CS 420 # greatest number     tr: translate\n  Similar to a String.replace() method\n  eg.\n$ tr 12 ab # replace \u0026#39;1\u0026#39; with \u0026#39;a\u0026#39;, \u0026#39;2\u0026#39; with \u0026#39;b\u0026#39; $ tr 1234 \u0026#39;[a*]\u0026#39; # replace \u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39; with \u0026#39;a\u0026#39; $ tr A-Z a-z # replace Uppercase with lowercase   -c: compliment\n eg. $ tr -c 1234 \u0026#39;[a*]\u0026#39; # replace everything except \u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39; with \u0026#39;a\u0026#39;     -s: squeeze\n Replace consecutive occurences by a single occurrence eg. $ tr -s 12 # can convert \u0026#39;11122abc211\u0026#39; to \u0026#39;12abc21\u0026#39; $ tr -s 12 abc # replaces then squeezes $ tr -cs 0-9a-z ’[\\n*]’ # replace everything except digits and letters with line breaks # then squeezes multiple line breaks -\u0026gt; \u0026#39;one word per line\u0026#39;     -d: delete\n Remove occurence eg. $ tr -d 12 # removes \u0026#39;1\u0026#39; and 2\u0026#39; $ tr -ds 12 3 # deletes \u0026#39;1\u0026#39;,\u0026#39;2\u0026#39; then squeezes \u0026#39;3\u0026#39;       tee: T\n Branching out, extra pipe (T-shaped) Copy stdin to stdout, and also copy to file (extra branch) eg. sort | tee sortedfile | uniq # similar to sort | uniq # but stdout from sort is now copied to sorted file before pipelining into uniq stdin     yes:\n Unending lines of y Use case: if a program requires [y/N] a lot [expletive]: outputs expletive instead of y    "});index.add({'id':4,'href':'/notes/CSCB09/Week-3/','title':"Week 3",'section':"CSCB09",'content':"Week 3 #  Introduction to Shell #   More features available from man sh\n Simple Commands #  4 general cases of commands\n Built in commands: cd, ls etc. User defined functions Aliases eg. alias pls=\u0026quot;sudo\u0026quot; Commands that refer to the program name  eg. tr command runs the tr program    Sequential List #  Multi-line commands in a single line\n$ cd projects ; sort file1 | uniq # runs cd then runs sort with pipe # equivalent to $ cd projects projects$ sort file1 | uniq  Grouping:  Explicit: {grep foo file1 ; ls ; } \u0026gt; file2    Exit Codes #  0 for success, non-0 for failure\n$ sort file1 # assume this works $ echo $? # prints `?` command 0 $ cd asdgkj -bash: cd: asdgkj: No such file or directory $ echo $? 127 # non-zero -\u0026gt; fail Logical AND OR NOT #  $ mkdir foo \u0026amp;\u0026amp; cd foo # sequential unless one fails $ mkdir foo1 || mkdir foo2 || exit # runs sequential command if first one fails $ ! mkdir foo # trivial (true to false, v.v) Operator Precedence:\n | highest ! \u0026amp;\u0026amp; || - same precedence ; lowest  Boolean Conditions #   String comparisons: [ s1 = s2 ] # `!=`, `\u0026lt;`, `\u0026gt;` also work  Number comparisons: [ num1 -eq num2 ] # `-ne`,`-gt`,`-ge`,`-lt`,`-le` also work  Logical connectives  -a: and -o: or -e: not    Conditionals and Iteratives #   if statement: if list1 ; then list2 elif list 3 ; then list4 else list5 fi # end statement  while loop: while list1 ; do list2 done # end statement  for loop: for var in word1 word2 word3 ; do echo $var mkdir $var done # end statement   Filename Patters #   *: any string ?: matches one character [nav]: matches \u0026lsquo;n\u0026rsquo;, \u0026lsquo;a\u0026rsquo;, \u0026lsquo;v\u0026rsquo; [0-9]: matches digit [!0-9]: matches non-digit  eg.\nfor i in *.sh ; do # for all files in dir with ext .sh echo $i # echo its name done Escaping and Quoting #   \\: backslash '': single quotes \u0026quot;\u0026quot;: double quotes  Use Cases:\n Spaced files: cd \u0026quot;Onedrive - University of Toronto\u0026quot; Regex for grep: grep ’\u0026lt;[a-z]*\u0026gt;’ *.html Operators in test commands: [ ! ’(’ aaa ’\u0026lt;’ abc -o aaa ’\u0026gt;’ abc ’)’ ]  Variables #   Declaration: var=69 # no spaces # if uninit, `echo $var` returns empty string (`echo ${var}` also works) # uninitialized var is not neccessarily an empty string by default  Double Quotes $ f=`Stupid Example.js` $ ls $f # equiv to `ls Stupid ; ls Example.js` $ ls \u0026#34;$f\u0026#34; # equiv to `ls \u0026#34;Stupid Example.js\u0026#34;` # double quotes and variables($) are \u0026#39;special\u0026#39;   String Testing #   Non-Empty String: [ -n string ] Empty String: [ -z string ] Tricky: # suppose {V} is an empty string [ -n $V ] # doesnt work (interpreted as `[ -n ]`) [ -n \u0026#34;$V\u0026#34; ] # works!   Case Matching #  eg.\ncase \u0026#34;$var\u0026#34; in *.py) # Case python rm \u0026#34;$var\u0026#34; ;; *.c | *.sh | myscript) # Case C, Shell, myscript echo w00t \u0026#34;$var\u0026#34; ;; *) # else echo meh \u0026#34;$var\u0026#34; esac # end statement "});index.add({'id':5,'href':'/notes/CSCB09/Week-4/','title':"Week 4",'section':"CSCB09",'content':"Week 4 #  Shell Scripting #  Running Scripts #  $ sh myscript Alternatively, in your myscript.sh file, do the following\n#! /bin/sh chmod u+x myscript # sets \u0026#39;executable\u0026#39; flag on the file and run it with\u0026hellip;\n$ ./myscript Positional Parameters #  $ ./myscript foo bar baz # come after filename, spaced  $#: Number of arguments (3) $n: Parameter name (n is the number)  eg. $1 = \u0026quot;foo\u0026quot;   $*: One string with all parameter names  \u0026quot;foo bar baz\u0026quot;   $@: Comma seperated strings for each parameter name  \u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;baz\u0026quot;   shift: Shifts Positional Parameters by 1 $# = 2 $1 = \u0026#34;bar\u0026#34; $2 = \u0026#34;baz\u0026#34; $* = \u0026#34;bar baz\u0026#34; # good for looping over parameters   Example Script #  #! /bin/sh chmod u+x pydelete # sets exec flag on pydelete.sh dryrun= verbose= while [ $# -gt 0 ]; do # while the number of params \u0026gt; 0 case \u0026#34;$1\u0026#34; in # takes the first parameter/argument -n) # if the argument is -n dryrun=y # sets the program as a dryrun \u0026#34;doesnt actually delete files\u0026#34; ;; -v) verbose=y # sets the program as verbose \u0026#34;deletes verbosely\u0026#34; ;; *) # as soon as there is another different parameter, the while loop breaks break esac # end of case shift # basically $# -= 1 done # end of while for f in \u0026#34;$@\u0026#34; ; do # for each parameter (after remove the arguments) case \u0026#34;$f\u0026#34; in # begins case *.py) # if the file is .py extension [ -n \u0026#34;$verbose\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;deleting $f\u0026#34; # if user used `-v` [ -z \u0026#34;$dryrun\u0026#34; ] \u0026amp;\u0026amp; rm \u0026#34;$f\u0026#34; # if user did not use `-n`, then it will delete ;; *) # any other file extension [ -n \u0026#34;$verbose\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;not deleting $f\u0026#34; # if the user set verbose esac # end of case done # end of for exit #   Terminates script and/or shell process Useful for:  Early exit Non-zero exit codes: exit 1    Functions #   Example definition myfunc() { echo \u0026#34;Hot diggity dog\u0026#34; }  Example function call myfunc foo bar baz # positional parameters are now function arguments  Returning return # early return return 1 # with exit code  Variable Scopes  Local variables myfunc() { local x y z x=69 y=351 z=$(expr $x + $y) echo $z }  Dynamic Scoping $ cat myscript x=0 printnum() { local x echo $x } func1() { local x x=1 printnum } func2() { local x x=2 printnum } func1 ; func2 $ sh myscript 1 # from func1 2 # from func2     Feeding multi-line text into stdin #  $ cat \u0026lt;\u0026lt; EOF # could be any string ﹥Hi I\u0026#39;m Navinn ﹥Variables also work \\$x=$x ﹥EOF # tells shell its the end of file Hi I\u0026#39;m Navinn Variables also work $x=42069  if end-marker is declared in quotes, $ is no longer special.  Command Substitution #   Run a command and take its stdout in-place for i in $(cat myfile) ; do # if wrapped in double-quotes, `cat myfile` is just one string instead of multiple echo \u0026#34;$i\u0026#34; done   Environment Variables #   Every process has a collection of environment variables  eg. PATH, CLASSPATH, USER, PWD, PS1 etc. Convention is all caps Same syntax: eg. $PATH, PATH=...   printenv: prints current env. vars. $ printenv HOME=/Users/home PWD=/Users/home/desktop PATH=/usr/local/cms/jdk1.8.0_31/bin:/usr/bin:/bin # colon-seperated list of directories ANDROID_HOME=/Users/home/Library/Android/sdk SHELL=/bin/bash ...  Creating a new env. var. is different LOGNAME=navn # same init export LOGNAME # different export LOGNAME=navinn # alt   File Attributes #  General Attributes #   Size Type Last modified time Last access time Last change time Owning user Owning group \u0026hellip;  Unix Account Organization #  Two main accounts: user, groups\n user: the user (home, navinn etc.) groups: A user can be in multiple groups  groups command displays which groups the current user is in  $ groups staff everyone localaccounts _appserverusr admin # ...   Permission Flags #    Each file is assigned one owning user and one owning group. Default is the user who created it and their default group\n Permissions: take the form rwxrwxrwx  r: read w: write x: execute   File permission notation $ ls -l rwxr-x--x 1 home staff 73966 1 Jun 23:07 myscript.sh # perms. user group bytes date_created name # rwxr-x--x: user gets `rwx`, users in group get `x`, other users get `x`     For directories:\n r: list files in the dir ls w: add, delete, modify files in the dir x: cd into dir., use paths mentioning dir    To Check Perms on a file/dir:\n[ -r path ] # exists and readable by current user [ -w path ] # exists and writable [ -x path ] # exists and executable   Changing Ownership/Permission\n  chown user path1 path2 # changes the owning user for both paths chown user:group path1 path2 # changes owning user and owning group chown :group path1 path2 # changes group chmod u=rw,g=r,o= path1 path2 # changes specific perms (u=user, g=group, o=other) find #  Literally finds a path and operates on selected files with automatic recursion\n$ find path ...expression For each given path, recurse down and pick out a file based on the expression\neg. Find python files, print their path, then delete\n$ find . -name ’*.py’ -exec rm ’{}’ ’;’ -print "});index.add({'id':6,'href':'/notes/CSCB09/Week-5/','title':"Week 5",'section':"CSCB09",'content':"Week 5 #  Programming in C #  Memory Model #   Array of bytes, \u0026ldquo;Addresses\u0026rdquo; are indexes Variables may occupy several consecutive bytes, its address refers to the first occupied byte \u0026ldquo;Pointer\u0026rdquo;: Variable/parameter that stores an address  int i = 69; // Suppose i was occupying bytes 45 to 74 int *p = \u0026amp;i // 45 Memory Regions #   Text:  Stores code Pointers pointing to functions point here   Global:  Stores global variables   Stack:  Used for function calls Stores local variables Auto allocation and deallocation   Heap:  Manual allocation (malloc(), calloc()) and deallocation (free()) Used for dynamic data outside of functions    Global Variables #   Two types of varaibles int pubVar = 10; // top-level public global variable int f() { static int privVar = 1010; // function private global variable  pubVar++; privVar++; ... }   Integer Types #   All possible combinations: {signed, unsigned $\\times$ char, short, int, long, long long} Byte size depends on platform  eg. x86-64    Type Size (bytes)     char (default signed) 1   short 2   int 4   long 8   long long 8        Integer Literal Notation #     Literal Type     3 int   c char   3U unsigned int   3L long   3UL unsigned long   3LL long long   3ULL unsigned long long    printf(\u0026#34;%lu\\n\u0026#34;, 3UL) // Good usage printf(\u0026#34;%lu\\n\u0026#34;, 3) // Bad since 3 is `int` Type Casting with Numbers #   Larger size type to smaller:  Automatic conversion Lose some information in a natural way (double to int removes decimal place) Better to explicitly typecast: double d = 420.69; int i = (int)d;    Smaller size type to larger:  Automatic conversion Completely lossless    Implicit Number Promotion #   The smaller operand type gets promoted to the larger operand type  Note: char and short are always promoted to int   eg. // Suppose the following double d = 65.0; int i = 65; char c = \u0026#39;A\u0026#39;; /** i / c -\u0026gt; promotes c to `int` and preforms integer division d / j -\u0026gt; promotes j to `double` and preforms floating-point division **/   Enumeration Types #   New \u0026ldquo;types\u0026rdquo; and integer constant names enum rps { ROCK, // ROCK = 0  PAPER, // PAPER = 1  SCISSORS // SCISSORS = 2 }; enum coin { HEAD, // HEAD = 0  TAIL // TAIL = 1 }; enum rps a = PAPER; // a = 1 enum coin c = HEAD; // c = 0  \u0026ldquo;Types\u0026rdquo; are simply int, are mixable and not checked Practically useful for meaningful names only  Union Types #   Overlapping \u0026ldquo;fields\u0026rdquo; that share the same space union myUnion { // sizeof(myUnion) = \u0026#34;largest field size\u0026#34; = 4 (for this example)  unsigned short s; unsigned int i; unsigned char b[4]; }; union myUnion u; // can use u.s, u.i, u.b[j] etc.  Use Cases:  High-level: Data has multiple mutually exclusive cases Low-level:  Store an int in i Read b[0] to b[3] to discover how i splits      Tagged Union Idiom #   Example: Suppose you wanted an array that holds both int and double Idiom: Make an outer struct struct int_or_double { enum { INT, DOUBLE } tag; // remembers which case you are in  union { // shares the same space in memory regardless of int or double  int i; // case value is an int  double d; // case value is a double  } data; }; struct int_or_double a[10]; // as wanted   Type Alias with typedef #   Very general, i.e can use with struct, enum, int, double etc. typedef struct node { int i; struct node *next; } nodetype; // use `nodetype` instead of `struct node`  Cannot use the same typedef name for more than one thing typedef coin { HEAD, TAIL } coin; typedef int coin; // illegal since `typedef coin` is already defined     \\(\\)  "});index.add({'id':7,'href':'/notes/CSCB09/Week-6/','title':"Week 6",'section':"CSCB09",'content':"Week 6 #  Programming in C (cont.) #  File I/O in C #   Content can be accessed as a steam (seq. read/write) File functions work with FILE *  FILE: Type rep. stream state, definition varies by platform, most likely a struct    Open #  FILE *fopen(const char *filename, const char *mode)  Modes: \u0026quot;r\u0026quot;, \u0026quot;w\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;r+\u0026quot;, \u0026quot;w+\u0026quot;, \u0026quot;a+\u0026quot;  Read, Write, Append, Read \u0026amp; Write, Write \u0026amp; Read, Append \u0026amp; Read Appending and Writing to a file will create a new one if the file does not exist Reading to a non-existent file will cause an error (returns NULL)    Close #  int fclose(FILE *stream)  Close stream when finished with the file Returns 0 if success, EOF if error Why should you close the file as soon as you\u0026rsquo;re finished:  There is a limit on how many streams are open per process Writing may be buffered until closing No two process can open the same file (Windows only)    Formatted I/O #  // printf and scanf but for a given stream int fprintf(FILE *stream, const char *format, ...) int fscanf(FILE *stream, const char *format, ...)  printf is just fprintf but stdout is specified scanf(format, args) == fscanf(stdin, format, args) //same for scanf  You do not need to manually close stdin, stdout, stderr streams  Character and String I/O #   One single character: returns EOF if error or not found int putchar(int c) /* stdout */ int putc(int c, FILE *stream) int getchar(void) /* stdin */ int getc(FILE *stream)  String: int fputs(const char *string, FILE *stream) // does not put a newline at the end char *fgets(char *dest, int n, FILE *stream) // Reads at most (n-1) chars or until (and including) newline   Arbitrary Data I/O #  size_t fread(void *dest, size_t s, size_t n, FILE *stream) size_t fwrite(const void *data, size_t s, size_t n,FILE *stream)  Reads/Writes n items, each of s bytes Returns how many items have been read/written Potential Use Cases:  A whole array struct Raw bytes (array of unsigned char)    Error versus End-of-Stream Disambiguation #   getc, scanf return EOF on error fgets returns NULL fread returns \u0026lt; n  int feof(FILE *stream) // returns true if end-of-stream int ferror(FILE *stream) // returns true if error void clearerr(FILE *stream) // clears end-of-stream and error status Error Information #  #include \u0026lt;errno.h\u0026gt; Global variable stores error reason of most recent error int errno;  Many possible values: ENOENT // File does not exist EACCESS // No permission EDOM // sqrt(-3.0)  Usually, we just use perror to print the error message to stderr: void perror(const char *prefix)   Buffering #   C delays file writing  Accumulates data in a buffer until it is large, then requests the kernel to write that chunk   Also hastens reading  Requests kernel to read a large chunk into the buffer, then serves read requests from said buffer    Buffer Operations #  int fflush(FILE *stream) // Returns 0 if success, EOF if error  Writes the buffer for the output stream Clears the buffer for the input stream  int setvbuf(FILE *stream, char *buf, int mode, size_t n)    mode meaning     _IOFBF full buffering   _IOLBF line buffering   _IONBF no buffering    Default Buffering of stdin, stdout, stderr #    If Terminal:\n stdin: line buffer stdout: no buffer stderr: complicated    If in a file or pipelined:\n stdin: full buffer stdout: no buffer stderr: full buffer    Seeking #   Ask current position: long int ftell(FILE *stream) // returns -1L if error  Seek: int fseek(FILE *stream, long i, int origin) // non-zero return if error    origin go to i bytes from     SEEK_SET beginning   SEEK_END end   SEEK_CUR current position      "});index.add({'id':8,'href':'/notes/CSCB09/Week-7/','title':"Week 7",'section':"CSCB09",'content':"Week 7 #  Programming in C (cont.) #  Compiler and Linker Stages #  myProgram.c $\\to$ Compiler $\\to$ Machine Code (myProgram.o) $\\to$ Libraries + Linker $\\to$ Executable\n myProgram.o is the object code file Libraries: where methods from stdio.h/stdlib.h come from Linker: Merges object files and libraries into one executable  gcc serves as a convenient linker frontend    C Compiler Stages #  The C compiler futher breaks down into:\n Pre-processor: For # directives, determines the actual C code seen by the compiler proper $ gcc -E ... # to see what the pre-processor actually does  Compiler proper: Translates C code into machine code $ gcc -c ... # creates the object file with the machine code   Pre-processor Directives #   #define macros  Textual substitution #define FINAL_COURSE_MARK 100 // to define a macro #undef FINAL_COURSE_MARK // to remove the macro    #include for header files  Header files usually contain  Macro defintions Types of exported functions and global variables   Implementation #include \u0026lt;foo.h\u0026gt; // looks for file in system-wide places (\u0026#39;/usr/include\u0026#39;)#include \u0026#34;foo.h\u0026#34; // looks for file among user source code   Conditional Compilation #ifdef DEBUG_FLAG  fprintf(stderr, \u0026#34;x=%d\\n\u0026#34;, x); #endif  Common technique for debugging code Also useful to check current OS (Windows/Linux)    Modularity and Seperate Compilation #   Keep closely-related code in the same files Key idea/principle for good software design Easier to modify and recompile one small file then one large file Example: // Rectangle Struct with area function typedef struct rect_struct { double width, height; } rect; double calcArea(const rect *r) { return ... //implementation goes here } // Linked-List Struct typedef struct ll_node_struct { rect r; ll_node_struct *next; } listNode; // Main Program int main() { rect r; listNode *newNode = (listNode *)calloc(1, sizeof(listNode)); printf(\u0026#34;%d\\n\u0026#34;, calcArea(\u0026amp;r)); ... }  This large file can be split into smaller more cohesive files  rect.h: includes type definition for rect_struct and calcArea() prototype rect.c: includes calcArea() implementation/definition llnode.h: includes ll_node_struct definition main.c: includes the main program     # only compile to machine code if it is necessary (new changes) $ gcc -c rect.c $ ... # takes the machine code and makes the executable $ gcc rect.o bb.o mainprog.o -o mainprog   Header Files #   A seperate file specifically for macro/type definitions and function prototypes Compiler wants to see the definition and prototype but you do not want to manually copy it to multiple files Note: It is illegal to see a type definition twice when compiling  Solution: Using Conditional Compilation to check if the header file was already included from another file, and including if it hasn\u0026rsquo;t #ifndef _FOO_H // if _FOO_H has been defined already, skip #define _FOO_H // if it has not been defined, then define it typedef struct node { int i; struct node *next; } node; #endif     Makefiles and make #  Most Basic Clause/Rule #    Form:\nTARGET : PREREQUISITES RECIPE   Example:\nbb.o : bb.c bb.h rect.h # if `bb.o` is missing or older than `bb.c`, `bb.h` and `rect.h` gcc -c bb.c # then run this command (compile to machine code)   If there are multiple rules in a Makefile:\n make triggers the first rule (which may trigger other subsequent rules) Order does not matter otherwise    Customary to write first rule as\nall : myexe1 myexe2 myexe3 # triggers other rules to build each myexe file .PHONY : all # means `all` is just a label, not an actual target file   File Clean Up #   Customary to add clean : # no prerequisites rm -f *.o myexe1 myexe2 myexe3 .PHONY : clean  Run make clean to invoke this target rule  Variables #   Defining variables from within a Makefile CFLAGS = -g  Setting variables outside of a Makefile make CFLAGS=\u0026#39;-g -DMY_DEBUG_FLAG\u0026#39; # overrides CFLAGS from within Makefile  Using a variable gcc $(CFLAGS) -c bb.c   Automatic Variables and Pattern Rules #    Non-example\nmainprog : mainprog.o bb.o rect.o gcc -g mainprog.o bb.o rect.o \\  -o mainprog mainprog.o : mainprog.c bb.h rect.h gcc -g -c mainprog.c bb.o : bb.c bb.h rect.h gcc -g -c bb.c rect.o : rect.c rect.h gcc -g -c rect.c   Using pattern rules\nmainprog : mainprog.o bb.o rect.o gcc -g $^ # all prereqs -o $@ # target %.o : %.c # any `.o` target with `.c` prereq gcc -g -c $\u0026lt; # build the first prereq   Automatic prerequisite listing\n$ gcc -MM mainprog.c bb.c rect.c mainprog.o : mainprog.c rect.h bb.h bb.o : bb.c rect.h bb.h rect.o : rect.c rect.h # copy the output to your Makefile     \\(\\)  "});index.add({'id':9,'href':'/notes/CSCB09/Week-8/','title':"Week 8",'section':"CSCB09",'content':"Week 8 #  File System with C #  i-nodes #    The file system has an array of \u0026lsquo;i-nodes\u0026rsquo;\n  Every file and directory is identified using an i-node\n  An i-node stores:\n Type: Regular file, dir, link, device, socket, etc. Permissions The owning user and owning group (numerical ids) Size Timestamps (created, last modified) Which disk blocks are used Other metadata    You can get most metadata by using the stat command\nDesktop ~$ stat 2942805567 687 crw--w---- 1 home tty 268435456 0 \u0026#34;Jul 18 13:29:59 2020\u0026#34; \u0026#34;Jul 18 13:29:59 2020\u0026#34; \u0026#34;Jul 18 13:29:59 2020\u0026#34; \u0026#34;Dec 31 19:00:00 1969\u0026#34; 131072 0 0 (stdin)   Directories #   Stores the mapping of filenames to i-node numbers Data structure varies by system The C functions opendir, readdir, closedir can access directories portably  Linking #  Unlinking #   Also known as deleting a file by its filename When deleting a file, the kernel will:  Decrease the reference count of filenames referring to the i-node number If the reference count is now 0, the disk space and the i-node is freed up   System call for delete is unlink  Hard link #   Creates a literal link between 2 files Useful when you want to access a file in an inaccessible directory ln can create another filename that has the same i-node number as an existing file $ ln path/to/file1 path/to/file2 # this creates a \u0026#39;hard link\u0026#39;  The hard link between 2 files will not be broken if one of the file names change or even get deleted Hard linking dirs is disallowed unless implementing special dirs like . and ..  Symbolic Linking (Symlink) #   Special file that simply stores a path (sort of like a shortcut) Most system calls and C library functions/programs follows symlinks Create a symlink using ln -s  Bitwise Operators in C #   Bitwise AND (\u0026amp;), OR (|), NOT (~), XOR (^) Left Shift (\u0026lt;\u0026lt;) and Right Shift (\u0026gt;\u0026gt;) Example: unsigned char a = 10001001; // 8-bit binary unsigned char b = 00000011; a \u0026amp; b = 00000001 // logical AND on each bit a | b = 10001011 // logical OR on each bit a ^ b = 10001010 // XOR on each bit ~ a = 01110110 // flips all bits a \u0026lt;\u0026lt; 1 = 00010010 // shifts all bits 1 to the left b \u0026gt;\u0026gt; 2 = 00000000 // shifts all bits 2 to the right   File Mode Bits #    st_mode bitwise layout\n File Type Permissions ---------------- ------------------------------------------------ | - | - | - | - | U | G | T | R | W | X | R | W | X | R | W | X | ----------- ----------- ----------- User Group Other   Macros for checking individual permissions:\n S_IRUSR: Binary 0000 100 000 000 S_IWUSR: Binary 0000 010 000 000 S_IXUSR: Binary 0000 001 000 000    System Calls for File I/O #  int open(const char *path, int flags); int open(const char *path, int flags, int mode); flags: O_WRONLY, O_RDONLY, O_RDWR, O_EXCL, O_TRUNC, O_APPEND; // Combine flags with bitwise OR  size_t read(int fd, void *buf, size_t count); size_t write(int fd, void *buf, size_t count); off_t lseek(int fd, off_t offset, int origin); origin: SEEK_SET, SEEK_CUR, SEEK_END; // Takes another fdt entry to the same open file table entry int dup(int oldfd); // takes fdt entry to be `newfd` and duplicates `oldfd` to it int dup2(int oldfd, int newfd); int close(int fd); File Descriptor (fd) #   Every process has a finite \u0026lsquo;File descriptor table\u0026rsquo; for opened files The File Descriptor is an array index into it Example of file descriptors:  0: stdin 1: stdout 2: stderr   open() and dup() consumes the lowest-number free entry close() frees entries  "});index.add({'id':10,'href':'/notes/CSCB09/Week-9/','title':"Week 9",'section':"CSCB09",'content':"Week 9 #  Processes and Redirection #  Launching a New Process #   Clone the process pid_t fork(void); // child gets return value 0, parent gets child\u0026#39;s pid  Both processes (child and parent) run the same code   The child can switch to running another program execlp(path, arg0, arg1, ..., (char *)NULL); // \u0026#39;exec\u0026#39; family of system calls  Things such as environment variables, pid, fd, current dir, etc. are preserved File descriptors can be closed before exec by marking them as close on exec    Why seperate fork and exec? #   Some use cases do not require exec The child process can do some prep before exec (file redirection and pipelining)  The only \u0026lsquo;parent-less\u0026rsquo; process: init #   fork is the only way to launch new processes As the kernel boots, it launches init, with pid 1  Process Commands #   ps: List processes pgrep: Find processes by name, users, etc. top: Process list that periodically refreshes (think of it as a terminal task manager) htop: top, but better (more features) kill and pkill: Terminates a process if allowed (pkill finds like pgrep)  Waiting for a Child process #  pid_t wait(int *status); // status is for child\u0026#39;s exit code pid_t waitpid(pid_t pid, int *status, int options); // pid \u0026gt; 0 -\u0026gt; wait for the given child // pid == -1 -\u0026gt; wait for any child // options == WNOHANG -\u0026gt; don\u0026#39;t hang waiting Useful macros #   Normal Termination:  WIFEXITED, WEXITSTATUS   Killed by signal:  WIFSIGNALED, WTERMSIG, WCOREDUMP   Stopped and continued by signal:  WIFSTOPPED, WIFCONTINUED    Termination of Parent before Child #   If the child terminates first and the parent process is still running and does not call wait  A \u0026lsquo;zombie\u0026rsquo; process of the child retains the entry of the child, but is not actually running   If the parent terminates but the child is still running  The child is now an \u0026lsquo;orphan\u0026rsquo; process and gets the parent pid of init   If the child terminates and the parent calls wait  Just regular termination and no \u0026lsquo;zombie\u0026rsquo;    File Redirection #   Before exec and fork, open the file Duplicate the file descriptor with dup2(curr_fd, new_fd) Close the file descriptor or request close on exec Then call exec  Pipes #  int pipe(int pipefd[2]); // creates a unidirectional pipe // pipefd[0] is for read end // pipefd[1] is for write end  This is how shells do pipelining Usually, only one process at both ends For dup/dup2, stdout for write end, and stdin for read end. Close fds you do not need as soon as possible Kernel has a buffer for unread data if the write end is writing faster than the read end can handle  Signals #   How the kernel notifies processes of some events and severe errors\n Examples #    Interupt (CTRL+C): SIGINT\n  Suspend and Resume: SIGSTOP,SIGCONT\n  Child died/suspended/resumed:SIGCHLD\n  Broken pipe:SIGPIPE\n  Request for termination (shell ‘kill’ default):SIGTERM\n  Hard request for termination:SIGKILL\n  Illegal memory access (two types:SIGBUS,SIGSEGV)\n  Application-specific:SIGUSR1,SIGUSR2\n  Signal Life Cycle #   Some events generate a signal Kernel tries to deliver the signal, and is pending until delivered Normal exec resumes if signal ignored or handler returns normally Shell Command: $ kill -SIGKILL 31337 $ kill -9 31337  System Calls: int kill(pid_t pid, int sig); int raise(int sig); // to self   Signal Actions/Handlers #  int sigaction(int sig, const struct sigaction *act, struct sigaction *oldact)  sig: The signal type act: The new action you want oldact: The old action on fork: Signal actions cloned on exec: Handlers are replaced by default  struct sigaction #  struct sigaction { void *sa_handler(int sig); // pointer to handler function, SIG_IN, or SIG_DFL  sigset_t sa_mask; // mask these signals when running handler  int sa_flags; // options  void *sa_restorer(void); // not for application use } sigset_t Operations #  int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); // add all signals int sigaddset(sigset_t *set, int sig); int sigdelset(sigset_t *set, int sig); int sigismember(const sigset_t *set, int sig); sa_flags Flags #  // If you install handler SA_NODEFER // don\u0026#39;t mask signal when running handler SA_RESETHAND // reset action to default before running handler SA_RESTART // auto-restart most syscalls before running handler  // For SIGCHLD SA_NOCLDSTOP // don\u0026#39;t signal for child stop/cont. SA_NOCLDWAIT // don\u0026#39;t turn terminated child into zombie "});index.add({'id':11,'href':'/notes/CSCB09/Week-10/','title':"Week 10",'section':"CSCB09",'content':"Week 10 #  Sockets #   Another way for two processes to communicate\n Characteristics of Sockets #    Has 2 sides: Server and Client\n Server: has a publishable address Client: contacts Server by published address    Unrelated processes, even on different computers, can contact each other through sockets\n  Socket Varieties #  By Domain #   Unix Domain: Local to the computer, address is a filename IPv4: Over the network, 32-bit address + 16-bit port number IPv6: 128-bit address and over the network  By Abstraction Level #   Datagram:  Per packet Packet boundary preserved, packet order is not Unnoticed packet loss   Stream:  Network stack works hard to confirm, timeout, resend Preserves data order No packet boundary    Stream Socket Workflow #  Client #   Call socket, creates the socket fd Fill in the address struct and use connect to connect to the server at the address Use the socket fd to communicate with the server Close the fd when done  Server #   Call socket to create the server socket fd Fill in the address struct and use bind to bind the sfd to the address Call listen Loop i. Call accept(sfd) to wait for client to connect, gets back a client fd ii. Use the cfd to communicate with client, close when done Close the server socket fd if no longer waiting for clients  Creating Sockets #  int socket(int family, int type, int protocol); // returns socket fd \u0026gt; 0, -1 if error  family: AF_UNIX, AF_INET (IPv4), AF_INET6 (IPv6) type: SOCK_DGRAM, SOCK_STREAM protocol: 0  IPv4 Addresses and Port struct #   Adresses are 32-bit, and identifies network interfaces (computers) Each byte is seperated by dots. (ex 142.1.96.164) dig can look up IP Addresses from domain names by asking Domain Name Servers (DNS) Port struct: struct sockaddr_in { sa_family_t sin_family; // AF_INET  in_port_t sin_port; // port, need to be in network byte order  struct in_addr sin_addr; // IPv4 address, also in NBO }; struct in_addr { uint32_t s_addr; }  Special addresses  127.0.0.1: Loopback (You can see this example when using localhost or any web server running on your computer) 0.0.0.0: Request binding to all network interfaces    Endians and Network Byte Order #   Big Endian (Network Byte Order): Left to right (ex. 772 in decimal = 03 04) Little Endian: Bytes are swapped (ex. 772 in decimal = 04 03) Use the library functions htonl (32-bit) and htons (16-bit) to convert from Little to Big Endian  bind, accept and connect #  int bind(int fd, const struct sockaddr *addr, socklen_t addrlen);  sockaddr: sockaddr_in (IPv4), sockaddr_in6 (IPv6), sockaddr_un (UNIX)  int accept(int fd, struct sockaddr *client_addr, socklen_t addrlen);  Returns new socket cfd for talking to client client_addr will recieve the address of client  int connect(int fd, const struct sockaddr *server_addr, socklen_t addrlen);  Returns 0 if success, -1 on error fd can now talk to the server  Broken Pipes #   If one end of the pipe is closed before the other one, the processes gets SIGPIPE The default action is the processes gets killed Eg. $ uniq longFile.txt | head -1 # \u0026#39;head\u0026#39; end of pipe closes after the first line # but \u0026#39;uniq\u0026#39; is still running, hence the process just ends  To override the default, set action to SIG_IGN (ignore)  "});index.add({'id':12,'href':'/notes/README/','title':"R E a D M E",'section':"Home",'content':"Notes #  \nTyped notes for my undergraduate classes at the University of Toronto, Canada.\nCourse Notes thus far:\n CSCA48H3: Intro to Computer Science II CSCB09H3: Software Tools and Systems Programming  src branch:\n Folders containing the actual notes Typed with Markdown  master branch:\n Static site generated with Hugo with book theme Automated build from src and deployment using TravisCI and Github Pages  Made with ❤️ by Navinn Ravindaran\n"});index.add({'id':13,'href':'/notes/CSCA48/final-review/','title':"Final Review",'section':"CSCA48",'content':"CSCA48 - Final Review #  Winter 2020 #   If you think it won\u0026rsquo;t work in C, it probably will.\n Units 1 + 2: #    Variables and lockers: #   Uniquely numbered in increasing order, reserved only for the program using the box to store and access information in said box.\n Three ways to get a locker: #   Variable Declaration int boostMyMark = 420; // locker has been created  Return Values return boostMyMark; // new locker has been created, (copied value)  Input Parameters void killAverage(double currentAvg, double midtermMark) {...} // lockers created to store currentAvg, midtermMark     Arrays: #   Fixed length and data type, consecutive boxes allocated in memory and are Passed-By-Reference for function calls.\n Array Declaration: #  int crunchyArray[10]; // creates 10 consecutive boxes of memory Strings: #   Array of chars End-of-string delimiter: \u0026lsquo;\\0\u0026rsquo;    Pointers: #   Just a variable (own space in memory), and stores a memory address in its locker of the same data type.\n Example:\nint num = 69; // creates locker int *p = \u0026amp;num; // the contents of (*) p gets the address of (\u0026amp;) num *(p) ++; // increments the contents of (*) p Arrays and Pointers: #   Arrays get passed as a pointer in a function (index 0) int arr[3] = {1, 2, 3}; // 3 new consecutive lockers for arr int *p = NULL; // empty pointer // the following are equivalent p = \u0026amp;arr[0]; // p gets the address of the value of arr at index 0 p = arr; // p gets the start of arr  Arrays can be iterated using an offset pointer or the indicies int nums[5] = {1, 2, 3, 4, 5}; int *p = nums; // \u0026amp;nums[0] for(int i = 0; i \u0026lt; 3; i++) { // the following are equivalent  printf(\u0026#34;%d\\n\u0026#34;, nums[i]); // nums at index i  printf(\u0026#34;%d\\n\u0026#34;, *(p + i)); // the contents of memory address (p + i) }     Unit 3: #    Dynamic Memory Allocation #   Reserving space in memory so it doesn\u0026rsquo;t get released when your function exits\n Initializing on the stack versus the heap: #  int crunchyFunction() { int stackNum = 69420; // allocates memory on the stack  int *heapNum = (int *)calloc(1, sizeOf(int)); // allocates on the heap  return 0; } After the function exits, stackNum will be released from memory but heapNum must be freed by the user\nfree(heapNum); Malloc: #   Does not clean up, but is faster than calloc, just be careful. Type *type_name = (Type *)malloc(numOfElements, sizeOf(Type)); free(type_name); //same as calloc     Dynamic Arrays #   Taking the best parts of Arrays ($O(1)$ lookup, consecutive boxes in memory) but without fixed length constraint.\n Essentially, when an array of size $N$ is at capacity (check using a counter variable), create a new array of size $2N$, and copy existing elements over to the new array\nint *infiniteChocolateCopy(int someChocolate[n], int n) { int *moreChocolate = (int *)calloc(2 * n, sizeOf(int)); // allocates size 2n on the heap  for(int i = 0; i \u0026lt; n; i++) { //iterates through someChocolate  *(moreChcolate + i) = someChocolate[i]; //copies over  } return moreChocolate; }   Compound Data Types #   Storing multiple components of data types (primitive and/or compound), packaged into a single container. Used when storing information too complex for a single data type.\n Defining a CDT struct: #  typedef struct student_struct { // creates the struct  char name[1024]; int year; double gpa; Markbook *marks; // example of passing a CDT pointer (CDT-ception)  // as many as you want here } Student; Initializing a CDT: #  Student *sweaty_nerd = (Student *)calloc(1, sizeOf(Student)); // allocate memory strcpy(sweaty_nerd-\u0026gt;name, \u0026#34;TryHard on Piazza\u0026#34;); // for strings sweaty_nerd-\u0026gt;year = 2023; // arrow (-\u0026gt;) operator for pointers sweaty_nerd-\u0026gt;gpa = 2.718; sweaty_nerd-\u0026gt;marks = bad_marks; Memory Model: #   CDT\u0026rsquo;s get one locker for all of it\u0026rsquo;s contents (like a Bento Box) Passing a CDT into a function: myCDT randomCrunchyCDTFunction(myCDT crunch) { // makes a copy (not passed-by-ref)  ... return crunch //returns a copy } It is typical to pass and return CDTs as a pointer, instead of copying\n    Abstract Data Types #   Implementation independent! It is just the idea of a container that stores a collection of data.\n List ADT: #   Stores items sequentially in nodes not necessarily consecutive, containing a reference to the next node in the list Not fixed in length Head: 1st node in list Tail: last node in list Typical operations, $O(N)$ worst case:  Insert Remove Update Search   Queue ADT: FIFO (first-in-first-out) Stack ADT: FILO (first-in-last-out)  Linked List: #   Best used when data is added and queried in random order.\n   Basic dynamic implementation of List ADT\ntypedef struct linked_list_struct { int data // payload (can be any type)  struct linked_list_struct *next; // pointer to the next node in the list, NULL if tail node } ListNode;   Iterating through a Linked List\nfor(ListNode *n = head; n != NULL; n = n-\u0026gt;next);   Insert\n  At head - $O(1)$ complexity:\nListNode *wantToInsert = (ListNode *)calloc(1, sizeOf(ListNode)); wantToInsert-\u0026gt;data = 51 // coincidentally the course midterm average wantToInsert-\u0026gt;next = head; // where head is the head of the LL   At tail - $O(N)$ complexity:\n//same initialzation of wantToInsert as 1. ListNode *n = head; if(head != NULL) { // always check if head is not null to avoid errors  for(; n-\u0026gt;next != NULL; n = n-\u0026gt;next); // traverses until at the tail  n-\u0026gt;next = wantToInsert; // sets the tail as wantToInsert }   Somewhere in between\n//same initialzation of wantToInsert as 1. ListNode *n = head; if(head != NULL) { for(; n-\u0026gt;data != insertHereNum; n = n-\u0026gt;next); // traverses list  wantToInsert-\u0026gt;next = n-\u0026gt;next; // links wantToInsert to n-\u0026gt;next  n-\u0026gt;next = wantToInsert; // links n to wantToInsert } Note: When inserting inside the list, we would use a condition to compare unique identifiers so we know exactly where to insert. For this example we assumed all the numbers were distinct and we knew insertHereNum's value was given and inside the Linked List.\n    Search - $O(N)$\n Traverse from head Check if current node is the desired node using a compare operation/function (see Note) Return  A pointer of the desired node, user can modify the node and list A copy of the data type (compound/primitive), user cannot modify the node and list      Delete - $O(N)$\nListNode *p1 = head; ListNode *p2 = NULL; // is always 1 node behind p1 if(head != NULL) { for(; p1 != NULL \u0026amp;\u0026amp; p1-\u0026gt;data != wantedNum; p2 = p1, p1 = p1-\u0026gt;next); //traverses through LL, one behind the other until wantedNode is found  if(p1-\u0026gt;data == head-\u0026gt;data) p2 = head-\u0026gt;next; // only if the wantedNode is the head  else p2-\u0026gt;next = p1-\u0026gt;next; // all other cases, links the node before wantedNode with the node after  free(p1); // releases the node from the list }     Unit 4: #    Computational Complexity: #   Measuring the amount of work done by an algorithm as a function of the number of data items the algorithm is working on, and thus predicting how algorithms will preform against each other without having to test on large $N$ values.\n The Big $O$ Notation #   Comparing algorithms in a machine and implementation dependent manner.\n   Mathematically put, $$ f(x) = O(g(x)) \\iff \\exists c \\in \\mathbb{R}_{\u0026gt;0} \\text{ such that for sufficiently large } x \\text{, } \\newline |f(x)| ≤ c \\text{ } \\cdotp{g(x)}, \\quad x \u0026gt; x_0 $$\n$O(g(x))$ is the smallest function of $N$ that puts an upper bound on $x$\n  Given a set of candidate algorithms, the fastest algorithm will have the slowest growing Big $O$ complexity.\n  In terms of efficiency, $$ O(1) \u0026lt; O(log (N)) \u0026lt; O(N) \u0026lt; O(Nlog(N)) \u0026lt; O(N^2) \u0026lt; O(N^3) \u0026lt; O(2^N) \u0026lt; O(N!) $$\n  Binary Search for Arrays #   Array must be sorted Complexity of $O(log_2(N))$ Procedure (Pseudocode): int binarySearch(int wantedNum, int Array[]) { int middleNum = Array[floor(length / 2.0)]; // finds middle index (floor if odd length)  if(wantedNum == middleNum) { return index(middleNum); // returns index of middleNum in Array  } else if (wantedNum \u0026gt; middleNum) { binarySearch(wantedNum, Lower Half of Array); // all values greater than middleNum  } else { binarySearch(wantedNum, Upper Half of Array); // all values less than middleNum  } }   Complexity of Linked Lists versus Arrays #   All basic operations on a Linked List have worst case $O(N)$ complexity. Unsorted Array:  Search:  Index lookup: $O(1)$ Linear search: $O(N)$ Sort: make a reasonable assumption :^)     Sorted Array:  Search:  Index lookup: $O(1)$ Binary Search: $O(log(N))$      The Consequence of Sorting #    Bubble Sort:\n Traverse the array and swap adjacent decreasing entries until the array is sorted.\n Worst-Case Complexity: $O(N^2)$\nvoid notSoCrunchyBubbleSort(int array[], int N) { for(int i = 0; i \u0026lt; N; i++) { // N iterations  for(int j = 0; j \u0026lt; N - 1; j++) { // N - 1 iterations  if(array[j] \u0026lt; array[j-1]) { // compares if the adj. entries are decreasing  swap(array[j], array[j+1]); } } } }   Quick Sort (qsort):\n Choose a random pivot, split elements into 2 arrays: values less than the pivot, and values greater than or equal to the pivot. Repeat until all sub-arrays have lengths ≤ 1. Reconstruct the now sorted array.\n  Average-Case Complexity: $O(Nlog(N))$ (not so crunchy) Worst-Case Complexity: $O(N^2)$ (first/last entry pivot $\\rightarrow$ insertion sort)    Insertion Sort:\n Build the sorted array in place (no splits), shifting elements as we traverse the array to sort.\n  Best-Case Complexity: $O(N)$ Worst-Case Complexity: $O(N^2)$ Procedure:  Choose first element to be \u0026ldquo;sorted\u0026rdquo; Look at next element in array, and insert it inside the \u0026ldquo;sorted\u0026rdquo; portion by comparing it to the values in said portion. Repeat 2. until the end of array        Trees #   A generalization of Linked Lists, linking one node in the Tree to sucessor (children) nodes. Recursive in nature, each sub-tree is also a Tree.\n Binary-Search Trees (BST) #   Variation of a Binary Tree (left and right children only) such that the BST property holds for each node and duplicate nodes are not allowed.\n   BST Property:\n Data in nodes on the left sub-tree are less than or equal to data in the root node Data in nodes on the right sub-tree are greater than data in the root node    Basic Implementation\ntypedef struct dollarStoreChocolate_BST_Struct { int data; struct dollarStoreChocolate_BST_Struct *left; // left child pointer  struct dollarStoreChocolate_BST_Struct *right; // right child pointer } BST_Node   Search - $O(log(N))$:\nif(root == NULL) return NULL; else if(givenData == root-\u0026gt;data) // check root  return root; else if(givenData \u0026lt;= root-\u0026gt;data) return search(root-\u0026gt;left, givenData); // search left sub-tree else return search(root-\u0026gt;right, givenData); // search right sub-tree   Insert - $O(log(N))$\n// assuming new_node was initialized and correctly allocated to the heap if (root == NULL) // empty tree  return new_node; // inserts at root else if (new_node-\u0026gt;data \u0026gt; root-\u0026gt;data) root-\u0026gt;right = insert(root-\u0026gt;right, new_node); // inserts in right sub-tree else root-\u0026gt;left = insert(root-\u0026gt;left, new_node); // inserts in left sub-tree return root; Note: Just like Linked Lists, we must use our own comparison function if the data in the node is a CDT.\n  Traversal - $O(N)$\n In Order - For listing a BST in sorted order: if (root != NULL) { inOrder(root-\u0026gt;left); // traverses left sub-tree  printf(\u0026#34;%d\\n\u0026#34;, root-\u0026gt;data); // any operation can be preformed  inOrder(root-\u0026gt;right); // traverses right sub-tree }  Pre Order - For Copying an entire BST: if (root != NULL) { printf(\u0026#34;%d\\n\u0026#34;, root-\u0026gt;data); // operation  preOrder(root-\u0026gt;left); // traverses left sub-tree  preOrder(root-\u0026gt;right); // traverses right sub-tree }  Post Order - For deleting an entire BST: if (root != NULL) { inOrder(root-\u0026gt;left); // traverses left sub-tree  inOrder(root-\u0026gt;right); // traverses right sub-tree  printf(\u0026#34;%d\\n\u0026#34;, root-\u0026gt;data); // operation }     Delete - $O(log(N))$\n Searching for node to delete is the same implementation as Insert and Search No children: free(root); // if only the final exam was as simple as this  One Child:  Left only BST_Node *temp = root-\u0026gt;left; // points to left child free(root); return temp;  Right only BST_Node *temp = root-\u0026gt;right; // points to right child free(root); return temp;    Two Children: BST_Node *temp = find_successor(root-\u0026gt;right); // smallest node in the right subtree copyNode(root, temp); // copies all the data from temp to the root root-\u0026gt;right = delete(temp); // deletes the successor recursively return root;     Complexity of Binary Search Trees versus Linked Lists and Arrays #    Building the data structure:\n LL: $O(N)$ BST: $O(Nlog(N))$ Array + Merge Sort: $O(Nlog(N))$    Search:\n LL / Unsorted Array: $O(N)$ BST: $O(Log(N))$ Sorted Array: $O(Log(N))$    Space Complexity:\n Array: Fixed size LL: $O(N)$ BST: $O(N)$      Unit 5: #    Graphs: #   A model to represent items and their relationships between them. Composed of Nodes (Verticies) and Edges, with optional direction and weight.\n $$ G=(V,E) $$\nGraph Representation #    Direction:\n Undirected: Two way relationship Directed: One way relationship    Neighbourhood:\n The neighbourhood of Node U is the set of all nodes that are neighbours of Node U.\n   Neighbour: 2 Nodes are considered neighbours if they are joined by an edge\nDirected Example: Node U $\\rightarrow$ Node V\n  In-neighbour: U of V\n  Out-neightbour: V of U\n  In-neighbourhood: Edges arriving at Node U\n  Out-neighbourhood: Edges leaving Node U\n      Degree:\n The size/dimension (number of nodes) in the neigbourhood of the Node.\n  In-degree: Degree of In-neighbourhood Out-degree: Degree of Out-neighbourhood    Traversals:\n Breadth First Search (BFS) - By path of neighbours Depth First Search (DFS) - Level by level    General Applications of Graphs #    Social Networks\n  Transportation (Maps services)\n  Genomics and Bioinformatics\n  Computer Networks and the Internet\n  Representing Graphs #    Adjacency List:\n An array with one entry per node. Each entry points to a linked list containing the neigbourhood for that node.\n   Adjacency Matrix:\n A 2D $N\\text{ x }N$ matrix, $N$ is the number of nodes in the graph. If Node $i$ and Node $j$ share an edge then AdjMat[$i$][$j$] \u0026gt; 0. For Undirected graphs, AdjMat[$i$][$j$] $=$ AdjMat[$j$][$i$]\n   Operation Complexity on Graphs #   $N = |\\text{Vertices}|$ is the number of nodes in the graph, and $M= |\\text{Edges}|$ is the number of edges in the graph\n     Operation Adjacency List Adjacency Matrix     Edge Query $O(N)$ $O(1)$   Inserting a Node $O(1)$ $O(N^2)$   Removing a Node $O(M)$ $O(N^2)$   Inserting an edge $O(1)$ $O(1)$   Removing an edge $O(N)$ $O(1)$       Principles of Recursion: #   The repeated application of a recursive procedure. Can make some problems super trivial to solve.\n Types of problems that benefit from recursion: #   Sudoku, N Queens (pretty c r u n c h y) BST Operations (duh) Graph Operations (every sub-graph is still a graph) Search and Path Finding (BFS and DFS)   Generally any problem that contains a smaller version of itself as a sub-problem.\n The process of designing a recursive solution #   Base Case(s):  Specific to the problem itself, multiple can exist The smallest problem with a trivial solution Any solution must always reach the base case   Recursive Case:  Multiple ways to split the problem at hand, some better than others After each recursive call, the sub-problem must be closer to the base case Always best to visually interpret/draw out the solution    Recursive Sort and their complexities #    DoofusSort/chewySort/notAProGamerSort:\n First Entry goes into one sub-array, the rest into another Recursively sort each sub-array Merge to form the sorted array  Complexity:\n Worst Case: $O(N^2)$ (Essentially Insertion Sort)    Merge Sort:\n Choose the middle entry as pivot Split into 2 sub-arrays, one less than, one greater than or equal Recursively sort each sub-array Combine to form the sorted array  Complexity:\n Worst Case: $O(Nlog(N))$ (Super Duper Crunchy)    qsort:\nSee: The Consequences of Sorting\n  The Memory Model #   Each time a recursive call has been made, part of the stack is reserved (stack frame) for variables, parameters and return type. Each stack frame will only be cleared until each recursive call is completed.\n  Stack Overflow (like the webpage):  Results when the stack has ran out of empty space Recursive solution must reach the base case in a reasonable number of steps Tail Recursion can prevent this  The recursive call would be the last thing the function does before returning Similar to an iterative solution, better for DEEP recursive solutions        Unit 6: #    Software Design: #   Developers are lazy, we need modular solutions to be as useful for others as possible.\n Properties of good software design #    Modularity\n Does one thing, ridonkulously well. Minimizes code replication Simplifies testing and debugging    Reusablity\n Any module can be reused by other applications requiring that specific task.    Extendibility\n Software that is easy to improve and extend its functionality and usability.    Maintainablity\n Organized, explicit and so well-commented that a noob would understand it.    Correctness\n Devs may be lazy, but they aren\u0026rsquo;t super lazy. Include detailed documentation and test cases.    Efficiency\n Gotta go fast, $O(1)$ or bust.    Openness\n You\u0026rsquo;re not a giant tech company, contribute to the open source software community.    Privacy and Security\n Secure data exchanges and reliable and safe solutions over personal/enterprise networks.      Application Programming Interfaces (APIs) #   Interacting with software modules, without having to understand how they work internally.\n  Use-case: Specific situation in which components of the API may be used Dependency: The relationship of one module requiring another module in order to function  Properties of a good API #   Easy to maintain Easy to extend and improve Easy to learn Difficult to use incorrectly Suitable for those who will be using it  Expanding an API #   Must consider required use-cases for each module Applications that rely on the API must not experience any significant impacts if expanded  Method overloading is a good workaround for any CRUNCHY use-cases after the initial rollout   If a bad API is expanded/modified, any software relying on said API will most likely stop functioning correctly  Limitations of C #   Basically C is !(OOP).\n  No Encapsulation and Information hiding No Polymorphism or Inheritance No Method overloading    Object Oriented Programming (OOP) #   Model for developing software components based on Encapsulation.\n  Encapsulation:  Wrapping required components together to implment the functionality of a data type. Hides data and functionality from the user using Access Control Modifiers to prevent misuse.   Access Control Modifiers:  Private: Accessed only by the class that its in  Protected: Gives inherited classes access to the parent class\u0026rsquo;s private data   Public: Can be accessed by any code outside of the class    Method Overloading #   Methods with the same name, but with different input parameters, return type and implementation.\n   Useful for multiple use-cases in which that particular solution is needed\nExample (Java):\npublic int addNumbers(int a, int b) { return a + b; } // same name but different return type and input parameters public double addNumbers(double a, double b, double c) { return a + b + c; } _\n  Classes and Objects #   The template/blueprint for building objects and their variables and methods.\n  Components of a class:  Private member variables  Used inside the class only   Constructor  Creates new instances/objects Assigns values to the input paramenters for the instance   Destructor  Called when finished with the class   Object Methods  Any functions declared in the class that an object can use      An example of an object class (Java):\nclass ComputerScienceNerd { // initialize the class  // initializes member variables for ComputerScienceNerd object  private String name; private double gpa; public ComputerScienceNerd(String name, double gpa) { // object constructor  // private variables (this.) get the parameter values  this.name = name; this.gpa = gpa; } /* * Object methods, public in nature * Call the method with (ComputerScienceNerdObject).method(); */ String getName() { return name; } double getGPA() { return gpa; } void screech() { System.out.println(\u0026#34;bY ThE WaY, dId yOu kNoW I\u0026#39;m iN CoMpUtEr sCiEnCe?\u0026#34;); } } Polymorphism and Inheritance #    Inheritance:\n The idea of passing methods and definitions to a hierarchy of Children classes.\n  A Child class inherits the same \u0026ldquo;traits\u0026rdquo; as the Parent class Example:  Parent Class: Instrument Child Class: WindInstrument inherits Instrument Child Class: Flute inherits WindInstrument   The \u0026ldquo;is a(n)\u0026rdquo; Test implies possible inheritance  \u0026ldquo;Flute is an instrument\u0026rdquo; $\\rightarrow$ Flute can inherit Instrument      Polymorphism:\n The idea that similar classes should be used the same way. Different objects belonging to the same inheritence hierarchy may posses the same functions, but the behaviour is characteristic to the object itself.\n Example (Pseudocode):\nClass Instrument { Instrument() { double duration; double freq; } playNote() { play(duration, freq); // generic implementation set by Parent class  } } Class Guitar extends Instrument { // child of Instrument  Guitar() { Instrument(); // uses the same constructor as parent class  } playNote() { // overrides the playNote() from the parent  // implementation here is specific to the Guitar class  } } Class Piano extends Instrument { // child of Instrument  Piano() { Instrument(); // uses parent constructor  } playNote() { // overrides the playNote() from the parent  // implementation here is specific to the Piano class  } } Obviously, a Guitar and a Piano do not sound the same (unless you\u0026rsquo;re deaf). As a result, playNote() should be modified for each different sounding instrument. The idea/functionality of playNote() must be the same, regardless of which Child is calling it.\n  Abstract Classes #   A class that only declares methods, and any subclass must provide implmentations for each method.\n  A Parent class that lets its children hold all implementations Example:  Parent Class: Instrument  Methods: playNote(), tunePitch(), smashOnSomeonesHead() No implementations   Children Classes: Piano, Guitar  Methods: Same as parent but each child has a different implementation  Piano: smashOnSomeonesHead() $\\rightarrow$ \u0026quot;Smash Head on Piano\u0026quot; Guitar: smashOnSomeonesHead() $\\rightarrow$ \u0026quot;Smash Guitar on Head\u0026quot;            \\(\\)  "});})();