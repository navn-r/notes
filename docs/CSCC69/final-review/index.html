<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="CSCC69 - Final Review # Winter 2023 # We both know I shouldn&rsquo;t be writing a review for this course.
Threads and Processes # Concurrency # Running multiple processes at the same time
Able to run more processes than the number of cores Serial execution results in more CPU idle time waiting for I/O User threads are 1:1 mapped to kernel threads (struct thread), can also be many:1 The OS also has its own kernel threads Interrupts # CPU stops running current process, saves its state, and runs interrupt handler (threads/interrupt."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Final Review"><meta property="og:description" content="CSCC69 - Final Review # Winter 2023 # We both know I shouldn&rsquo;t be writing a review for this course.
Threads and Processes # Concurrency # Running multiple processes at the same time
Able to run more processes than the number of cores Serial execution results in more CPU idle time waiting for I/O User threads are 1:1 mapped to kernel threads (struct thread), can also be many:1 The OS also has its own kernel threads Interrupts # CPU stops running current process, saves its state, and runs interrupt handler (threads/interrupt."><meta property="og:type" content="article"><meta property="og:url" content="https://navn.me/notes/CSCC69/final-review/"><meta property="article:section" content="cscc69"><title>Final Review - cscc69</title>
<link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@420&family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&display=swap" rel=stylesheet><link rel=manifest href=/notes/manifest.json><link rel=icon href=/notes/favicon.png type=image/x-icon><link rel=stylesheet href=/notes/book.min.5b161a410a07e8edac1f3ac3960626c8f0526b5c27cd5e3521db29c8d38dcb70.css integrity="sha256-WxYaQQoH6O2sHzrDlgYmyPBSa1wnzV41IdspyNONy3A="><script defer src=/notes/flexsearch.min.js></script><script defer src=/notes/en.search.min.209631fd3be946f278ff8f3cad77b0ea831d01730439d10609f7fbb90c4813fc.js integrity="sha256-IJYx/TvpRvJ4/488rXew6oMdAXMEOdEGCff7uQxIE/w=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a href=/notes/><img src=/notes/logo.svg alt=Logo><span>Notes</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-4bb681271db05f0940ee1acb09b0f8a8 class=toggle>
<label for=section-4bb681271db05f0940ee1acb09b0f8a8 class="flex justify-between"><a href=https://navn.me/notes/CSCA48/>CSCA48</a></label><ul><li><a href=https://navn.me/notes/CSCA48/final-review/>Final Review</a></li></ul></li><li><input type=checkbox id=section-2debca29f5b04840be17adb7f423a898 class=toggle>
<label for=section-2debca29f5b04840be17adb7f423a898 class="flex justify-between"><a href=https://navn.me/notes/CSCB09/>CSCB09</a></label><ul><li><a href=https://navn.me/notes/CSCB09/Week-1/>Week 1</a></li><li><a href=https://navn.me/notes/CSCB09/Week-2/>Week 2</a></li><li><a href=https://navn.me/notes/CSCB09/Week-3/>Week 3</a></li><li><a href=https://navn.me/notes/CSCB09/Week-4/>Week 4</a></li><li><a href=https://navn.me/notes/CSCB09/Week-5/>Week 5</a></li><li><a href=https://navn.me/notes/CSCB09/Week-6/>Week 6</a></li><li><a href=https://navn.me/notes/CSCB09/Week-7/>Week 7</a></li><li><a href=https://navn.me/notes/CSCB09/Week-8/>Week 8</a></li><li><a href=https://navn.me/notes/CSCB09/Week-9/>Week 9</a></li><li><a href=https://navn.me/notes/CSCB09/Week-10/>Week 10</a></li><li><a href=https://navn.me/notes/CSCB09/Week-11/>Week 11</a></li></ul></li><li><input type=checkbox id=section-77986a30d0bafa2006c4244549bdb530 class=toggle>
<label for=section-77986a30d0bafa2006c4244549bdb530 class="flex justify-between"><a href=https://navn.me/notes/CSCC01/>CSCC01</a></label><ul><li><a href=https://navn.me/notes/CSCC01/final-review/>Final Review</a></li></ul></li><li><input type=checkbox id=section-e600dcd392656875928f11f720f2035e class=toggle>
<label for=section-e600dcd392656875928f11f720f2035e class="flex justify-between"><a href=https://navn.me/notes/CSCC24/>CSCC24</a></label><ul><li><a href=https://navn.me/notes/CSCC24/Week-1/>Week 1</a></li><li><a href=https://navn.me/notes/CSCC24/Week-2/>Week 2</a></li><li><a href=https://navn.me/notes/CSCC24/Week-3/>Week 3</a></li><li><a href=https://navn.me/notes/CSCC24/Week-4/>Week 4</a></li><li><a href=https://navn.me/notes/CSCC24/Week-5/>Week 5</a></li><li><a href=https://navn.me/notes/CSCC24/Week-6/>Week 6</a></li><li><a href=https://navn.me/notes/CSCC24/Week-7/>Week 7</a></li><li><a href=https://navn.me/notes/CSCC24/Week-8/>Week 8</a></li><li><a href=https://navn.me/notes/CSCC24/Week-9/>Week 9</a></li><li><a href=https://navn.me/notes/CSCC24/Week-10/>Week 10</a></li></ul></li><li><input type=checkbox id=section-541477ac4ab0917da5319e88a4774c31 class=toggle>
<label for=section-541477ac4ab0917da5319e88a4774c31 class="flex justify-between"><a href=https://navn.me/notes/CSCC43/>CSCC43</a></label><ul><li><a href=https://navn.me/notes/CSCC43/final-review/>Final Review</a></li></ul></li><li><input type=checkbox id=section-b5358fad36614aebec833658cee7af14 class=toggle checked>
<label for=section-b5358fad36614aebec833658cee7af14 class="flex justify-between"><a href=https://navn.me/notes/CSCC69/>CSCC69</a></label><ul><li><a href=https://navn.me/notes/CSCC69/final-review/ class=active>Final Review</a></li></ul></li></ul><ul><li><a href=https://github.com/navn-r/notes target=_blank rel=noopener>Github Repo</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/notes/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Final Review</strong>
<label for=toc-control><img src=/notes/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#threads-and-processes>Threads and Processes</a><ul><li><a href=#concurrency>Concurrency</a></li><li><a href=#synchronization>Synchronization</a></li><li><a href=#scheduling>Scheduling</a></li></ul></li><li><a href=#virtual-memory>Virtual Memory</a><ul><li><a href=#attempts-to-solve-virtual-memory>Attempts to Solve Virtual Memory</a></li><li><a href=#page-replacement>Page Replacement</a></li><li><a href=#memory-allocation>Memory Allocation</a></li></ul></li><li><a href=#storage-devices>Storage Devices</a><ul><li><a href=#purpose>Purpose</a></li><li><a href=#hard-disk-drives>Hard Disk Drives</a></li><li><a href=#solid-state-drives>Solid State Drives</a></li></ul></li><li><a href=#file-systems>File Systems</a><ul><li><a href=#goals>Goals</a></li><li><a href=#disk-layout>Disk Layout</a></li><li><a href=#unix-file-system>UNIX File System</a></li><li><a href=#access-paths-unix>Access Paths (UNIX)</a></li><li><a href=#placement-problems-in-unix-fs>Placement Problems in UNIX FS</a></li><li><a href=#file-interfaces>File Interfaces</a></li><li><a href=#bsd-fast-file-system-ffs>BSD Fast File System (FFS)</a></li><li><a href=#links>Links</a></li><li><a href=#buffer-cache>Buffer Cache</a></li><li><a href=#protecting-files>Protecting Files</a></li><li><a href=#crash-consistency>Crash Consistency</a></li><li><a href=#journaling>Journaling</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=cscc69---final-review>CSCC69 - Final Review
<a class=anchor href=#cscc69---final-review>#</a></h1><h4 id=winter-2023>Winter 2023
<a class=anchor href=#winter-2023>#</a></h4><blockquote><p>We both know I shouldn&rsquo;t be writing a review for this course.</p></blockquote><h2 id=threads-and-processes>Threads and Processes
<a class=anchor href=#threads-and-processes>#</a></h2><h3 id=concurrency>Concurrency
<a class=anchor href=#concurrency>#</a></h3><blockquote><p>Running multiple processes at the same time</p></blockquote><ul><li>Able to run more processes than the number of cores</li><li>Serial execution results in more CPU idle time waiting for I/O</li><li>User threads are 1:1 mapped to kernel threads (<code>struct thread</code>), can also be many:1</li><li>The OS also has its own kernel threads</li></ul><p><img src=../images/kernel_threads.png alt="kernel threads"></p><p><img src=../images/process_vs_threads.png alt="process vs threads"></p><h4 id=interrupts>Interrupts
<a class=anchor href=#interrupts>#</a></h4><ul><li>CPU stops running current process, saves its state, and runs interrupt handler (<code>threads/interrupt.c</code>)</li><li><strong>External</strong>: Programmable Interrupt Controller (PIC) handles hardware interrupts</li><li><strong>Internal</strong>: Timer interrupts, Syscalls, Faults (page, segmentation, division by zero)</li></ul><h3 id=synchronization>Synchronization
<a class=anchor href=#synchronization>#</a></h3><ul><li>Incrementing and Decrementing are not atomic, may cause race conditions</li></ul><h4 id=critical-section>Critical Section
<a class=anchor href=#critical-section>#</a></h4><ul><li>Code that accesses shared data and must be executed atomically</li></ul><table><thead><tr><th>Requirement</th><th>Definition</th></tr></thead><tbody><tr><td>Mutual Exclusion</td><td>Only one thread can be in critical section at a time</td></tr><tr><td>Progress</td><td>A thread in the critical section will eventually exit</td></tr><tr><td>Bounded Waiting</td><td>If a thread is waiting to enter critical section, eventually it will</td></tr><tr><td>Performance</td><td>No thread should wait too long to enter critical section</td></tr></tbody></table><ul><li><p><strong>Disable Interrupts</strong>: Technically works, but can cause deadlock (thread hangs forever)</p></li><li><p><strong>Semaphores</strong>: Accessed by multiple threads</p><ul><li>Contains a counter (> 0) and a list of waiting threads</li><li>Before entering critical section, down the semaphore</li><li>After, up the semaphore, waking up another thread</li></ul></li><li><p><strong>Locks</strong>: Acquired and released by a single thread (binary semaphore)</p></li><li><p><strong>Condition Variables</strong>: Waits for a condition to be true</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#a6e22e>cond_init</span> (<span style=color:#f92672>&amp;</span>cond);
</span></span><span style=display:flex><span><span style=color:#a6e22e>cond_wait</span> (<span style=color:#f92672>&amp;</span>cond, <span style=color:#f92672>&amp;</span>lock); <span style=color:#75715e>// thread calls this to wait for condition
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>cond_signal</span> (<span style=color:#f92672>&amp;</span>cond);      <span style=color:#75715e>// wakes up one waiter 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>cond_broadcast</span> (<span style=color:#f92672>&amp;</span>cond);   <span style=color:#75715e>// wakes all threads
</span></span></span></code></pre></div></li></ul><h4 id=deadlock>Deadlock
<a class=anchor href=#deadlock>#</a></h4><ul><li>No process can make progress because each is waiting for an event that only another process can cause</li><li>Avoided by acquiring resources in a fixed order (no circular wait)</li><li>Note: Any three conditions can (likely) result in deadlock, doesn&rsquo;t have to be all four</li></ul><table><thead><tr><th>Condition</th><th>Definition</th></tr></thead><tbody><tr><td>Mutual Exclusion</td><td>One process at a time can use the resource</td></tr><tr><td>Hold and Wait</td><td>A process is holding at least one resource and waiting for additional resources</td></tr><tr><td>No Preemption</td><td>A resource can be released only voluntarily by the process holding it</td></tr><tr><td>Circular Wait</td><td>P1 waiting on P2 waiting on &mldr; PN waiting on P1</td></tr></tbody></table><h3 id=scheduling>Scheduling
<a class=anchor href=#scheduling>#</a></h3><h4 id=thread-lifecycle>Thread Lifecycle
<a class=anchor href=#thread-lifecycle>#</a></h4><p><img src=../images/thread_lifecycle.png alt="thread lifecycle diagram"></p><ul><li><strong>Scheduling Problem</strong>: Given a set of processes, decide which process to run next, and for how long</li><li><strong>Starvation</strong>: Thread is prevented from making progress because some other thread has the resources it needs<ul><li>i.e. a higher priority thread is preventing the lower priority thread from running</li></ul></li></ul><h4 id=scheduling-metrics>Scheduling Metrics
<a class=anchor href=#scheduling-metrics>#</a></h4><table><thead><tr><th>Metric</th><th>Definition</th></tr></thead><tbody><tr><td>Throughput</td><td>Number of processes that complete per unit time (maximize)</td></tr><tr><td>Turnaround</td><td><code>time_finished</code> $-$ <code>time_started</code> (minimize)</td></tr><tr><td>Response</td><td><code>time_responded</code> $-$ <code>time_requested</code> (minimize)</td></tr></tbody></table><h4 id=scheduling-algorithms>Scheduling Algorithms
<a class=anchor href=#scheduling-algorithms>#</a></h4><table><thead><tr><th>Kind</th><th>Definition</th></tr></thead><tbody><tr><td>Preemptive</td><td>OS can switch to another thread at any time</td></tr><tr><td>Non-Preemptive</td><td>OS can only switch to another thread after the running thread terminates</td></tr></tbody></table><ul><li><p><strong>First-Come, First-Served (FCFS)</strong>: Can cause head-of-line blocking (long processes block short processes)</p></li><li><p><strong>Shortest Job First (SJF)</strong>: Must know processing time, can cause starvation (short processes starve long processes)</p><ul><li>SRTF: Can consider remaining time instead of total time (preemptive), still leads to starvation</li></ul></li><li><p><strong>Round Robin (RR)</strong>: Preempt current thread after time quantum (1-100ms), and continue in FIFO order</p><ul><li>Doesn&rsquo;t consider a thread&rsquo;s priority, can cause starvation</li></ul></li><li><p><strong>Multilevel Feedback Queue Scheduling (MLFQS)</strong>: Preemptive, priority-based scheduling</p><ol><li>Assigned high priority initially, and priority is decreased after each time quantum</li><li>A Lower priority runs only when the higher priority queue is empty</li><li>If same priority, round robin is used</li><li>After a job uses up its time quantum, it moves to the lower priority queue</li><li>After some time, all jobs are moved back to higher priority</li></ol></li></ul><h4 id=priority-donation>Priority Donation
<a class=anchor href=#priority-donation>#</a></h4><ul><li>A thread can donate to a lower priority thread</li><li>Eg. Thread H waiting for a lock held by a thread L<ul><li>H donates to L, allowing L to schedule and release the lock</li><li>L returns the donation back to H to continue running</li></ul></li></ul><pre tabindex=0><code>NESTED DONATION: &#34;H is waiting on A held by M and M is waiting on B held by L&#34;

|-------------------|                               |-------------------|                               |--------------------|
| thread H          |       |-------------|         | thread M          |       |-------------|         | thread L           |
|   priority: HIGH  |       | lock A      |         |   priority: MED   |       | lock B      |         |   priority: LOW    |
|   waiting_on: A   |------&gt;|   holder: M |--------&gt;|   waiting_on: B   |------&gt;|  holder: L  |--------&gt;|   waiting_on: NULL |
|___________________|       |_____________|         |___________________|       |_____________|         |____________________|
</code></pre><h2 id=virtual-memory>Virtual Memory
<a class=anchor href=#virtual-memory>#</a></h2><ul><li>Abstraction of physical memory</li><li>Each process has its own virtual address space</li><li>OS maps virtual addresses to physical addresses without the process knowing other processes&rsquo; addresses</li><li><strong>Fragmentation</strong>: Inability to use memory over time, avoiding this is impossible<ul><li><strong>Internal</strong>: Fixed size pieces, internal waste of space</li><li><strong>External</strong>: Free space is not contiguous, can&rsquo;t allocate a large block (many small holes)</li><li>Factors required for Fragmentation:<ul><li>Different lifetimes: no fragmentation if all processes have same lifetime</li><li>Different sizes: no fragmentation if all processes have same size</li></ul></li></ul></li></ul><table><thead><tr><th>Goal</th><th>Definition</th></tr></thead><tbody><tr><td>Protection</td><td>Each process has its own virtual address space</td></tr><tr><td>Efficiency</td><td>Reduce memory usage and improve performance</td></tr><tr><td>Convenience</td><td>Allow processes to use memory without worrying about physical memory</td></tr><tr><td>Extensibility</td><td>Allow processes to use more memory than physical memory</td></tr></tbody></table><h3 id=attempts-to-solve-virtual-memory>Attempts to Solve Virtual Memory
<a class=anchor href=#attempts-to-solve-virtual-memory>#</a></h3><ol><li><p><strong>Base and Bound Registers</strong></p><ul><li>MMU translates (and verifies) address at runtime</li><li><code>physical_address = virtual_address - base</code></li><li>If <code>base &lt;= address &lt;= bound</code>, then address is valid, else trap to OS</li><li>Causes internal fragmentation, growing process is expensive</li></ul></li><li><p><strong>Segmentation</strong></p><ul><li>Divide process into segments, each with its own base and bound</li><li>Address is built from segmentation table</li><li>Causes external fragmentation</li></ul></li><li><p><strong>Simple Paging</strong></p><ul><li>Divide virtual memory into fixed-size pages, physical memory into paged-sized frames</li><li>Each page has a page table entry (PTE) that maps virtual page to physical page</li><li>Eliminates external fragmentation, internal fragmentation is small</li><li>Each memory lookup requires two memory accesses (page table and PTE)</li></ul></li></ol><p><img src=../images/address_lookup.png alt="address lookup"></p><ol><li><strong>Multi-Level Paging</strong><ul><li>Page directory contains one entry per page table (<code>pagedir</code>)</li><li>Lookup process: (happy path)<ol><li>Fetch PTE from PDE</li><li>Fetch page frame from PTE</li><li>Compute physical address from page frame and offset</li></ol></li><li>If any of the above steps fail, a page fault occurs (<code>userprog/exception.c:page_fault()</code>)</li><li>Allows for page growth, but now requires 3 memory accesses (time-space trade-off)</li><li><strong>Translation Lookaside Buffer (TLB)</strong>: Cache of recently used PTEs, reduces memory accesses to 2<ul><li>High hit rate, maintained by the MMU (hardware is always faster than software)</li></ul></li></ul></li></ol><h3 id=page-replacement>Page Replacement
<a class=anchor href=#page-replacement>#</a></h3><ul><li><strong>Swap</strong>: Move a page from physical memory to disk</li><li>When a page fault occurs, the OS must choose a page to evict from physical memory into swap</li><li>Page replacement algorithms strive to minimize page fault rate</li><li><strong>Belady&rsquo;s Anomaly</strong>: Having more physical memory does not automatically mean fewer page faults</li></ul><p><img src=../images/page_replacement.png alt="page replacement"></p><h4 id=page-replacement-algorithms>Page Replacement Algorithms
<a class=anchor href=#page-replacement-algorithms>#</a></h4><ol><li><strong>Basic algorithms</strong>: FIFO, LRU, LFU, MFU</li></ol><ul><li>Combinations also exist</li></ul><ol start=2><li><strong>Clock Algorithm</strong>: Approximation of LRU</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#a6e22e>list_init</span> (frame_list); <span style=color:#75715e>// circular
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>clock_hand <span style=color:#f92672>=</span> frame_list.head; <span style=color:#75715e>// some page frame
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>for</span> (each page access request)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (page in memory) <span style=color:#75715e>// hit 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  {
</span></span><span style=display:flex><span>    page.accessed <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>else</span> <span style=color:#75715e>// miss (eviction)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> (clock_hand.accessed <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      clock_hand.accessed <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>      clock_hand <span style=color:#f92672>=</span> clock_hand.next;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>swap</span> (clock_hand, page);
</span></span><span style=display:flex><span>    clock_hand <span style=color:#f92672>=</span> clock_hand.next;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><ol start=3><li><strong>Second Chance</strong>: Similar to clock algorithm, head of list after is ready to be evicted</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#66d9ef>void</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>second_chance</span> (<span style=color:#66d9ef>void</span>)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>struct</span> <span style=color:#66d9ef>thread</span> <span style=color:#f92672>*</span>cur <span style=color:#f92672>=</span> <span style=color:#a6e22e>thread_current</span> ();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>struct</span> frame_table_entry <span style=color:#f92672>*</span>frame <span style=color:#f92672>=</span> <span style=color:#a6e22e>get_head_frame</span> ();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>struct</span> sup_page_entry <span style=color:#f92672>*</span>spe <span style=color:#f92672>=</span> frame<span style=color:#f92672>-&gt;</span>spe;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>while</span> (<span style=color:#a6e22e>pagedir_is_accessed</span> (frame<span style=color:#f92672>-&gt;</span>owner<span style=color:#f92672>-&gt;</span>pagedir, spe<span style=color:#f92672>-&gt;</span>uaddr))
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>pagedir_set_accessed</span> (frame<span style=color:#f92672>-&gt;</span>owner<span style=color:#f92672>-&gt;</span>pagedir, spe<span style=color:#f92672>-&gt;</span>uaddr, false);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// &#39;rotate&#39; frame to the back of the list
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#a6e22e>list_remove</span> (<span style=color:#f92672>&amp;</span>frame<span style=color:#f92672>-&gt;</span>elem);
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>list_push_back</span> (<span style=color:#f92672>&amp;</span>frame_table, <span style=color:#f92672>&amp;</span>frame<span style=color:#f92672>-&gt;</span>elem);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    frame <span style=color:#f92672>=</span> <span style=color:#a6e22e>get_head_frame</span> ();
</span></span><span style=display:flex><span>    spe <span style=color:#f92672>=</span> frame<span style=color:#f92672>-&gt;</span>spe;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=memory-allocation>Memory Allocation
<a class=anchor href=#memory-allocation>#</a></h3><ul><li><strong>Static</strong>: Memory is allocated at compile time (fixed size, stack)<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#66d9ef>int</span> a[<span style=color:#ae81ff>100</span>]; <span style=color:#75715e>// simple, but restricted
</span></span></span></code></pre></div></li><li><strong>Dynamic</strong>: Memory is allocated at runtime (variable size, heap)<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#66d9ef>char</span> <span style=color:#f92672>*</span>a <span style=color:#f92672>=</span> (<span style=color:#66d9ef>char</span> <span style=color:#f92672>*</span>) <span style=color:#a6e22e>malloc</span> (<span style=color:#ae81ff>100</span>); <span style=color:#75715e>// contiguous block of memory
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>free</span> (a); <span style=color:#75715e>// creates fragmentation (need to coalesce)
</span></span></span></code></pre></div></li></ul><p><img src=../images/heap_memory_allocator.png alt="heap memory allocator"></p><h4 id=allocator-data-structures>Allocator Data Structures
<a class=anchor href=#allocator-data-structures>#</a></h4><ol><li><p><strong>Bitmap</strong>: Array of bits, each bit represents a page</p><ul><li>0 means free, 1 means allocated</li><li>Allocation is slow, requires linear scan to find sequence of zeros</li><li>No need to coalesce</li></ul></li><li><p><strong>Free List</strong>: List of free pages</p><ul><li>Coalescing is required to prevent fragmentation, merge adjacent blocks</li></ul></li></ol><p><img src=../images/free_list.png alt="free list"></p><h4 id=placement-algorithms>Placement Algorithms
<a class=anchor href=#placement-algorithms>#</a></h4><ol><li><p><strong>First Fit</strong>: Find first free block that is large enough</p><ul><li>Linear scan of free list sorted LIFO/FIFO/address, pick first one that is large enough</li><li>Simple, (often) fastest and most efficient</li><li>May cause fragmentation near start of memory that must be searched repeatedly</li></ul></li><li><p><strong>Best Fit</strong>: Find smallest free block that is large enough</p><ul><li>Minimize fragmentation by allocating space from block that leaves smallest fragment</li><li>Requires linear scan of free list</li><li><strong>Worst Fit</strong>: Find largest free block that is large enough (opposite of best fit)</li></ul></li><li><p><strong>Buddy Allocation</strong>: Round up allocations to power of 2 to make management faster</p><ul><li>Fast search and merge (alloc and free)</li><li>Avoids iterating through free list</li><li>Avoids external fragmentation</li><li>Physical pages are kept contiguous</li></ul></li></ol><p><img src=../images/buddy_allocation.png alt="buddy allocation"></p><h2 id=storage-devices>Storage Devices
<a class=anchor href=#storage-devices>#</a></h2><h3 id=purpose>Purpose
<a class=anchor href=#purpose>#</a></h3><ul><li><p>It is the OS&rsquo;s responsibility to abstract storage details</p><ul><li>HDD only knows about platters and sectors, SSD only knows about pages and blocks</li><li>Neither know about files, directories, or processes, but user programs do</li></ul></li><li><p><strong>Memory/Storage Hierarchy</strong>:</p><ul><li>Balance between cost, performance, and capacity</li><li>CPU registers and cache are fastest, but small and expensive</li><li>Hard disk is slow, but large and cheap</li><li>Exploit locality of reference to minimize cost</li></ul></li><li><p><strong>Persistence</strong>:</p><ul><li>&lsquo;Permanent&rsquo; storage of data</li><li>Organization, consistency, and management issues are important</li></ul></li></ul><h3 id=hard-disk-drives>Hard Disk Drives
<a class=anchor href=#hard-disk-drives>#</a></h3><p><img src=../images/hdd_insides.png alt=insides></p><ul><li><p>Slow for random access</p></li><li><p>HDD workloads favor high locality and large request sizes</p><ul><li>Should design FS to generate workloads that have this</li></ul></li><li><p>Disk service time components:</p><ul><li>Seeking (expensive)</li><li>Rotational Latency (spinning)</li><li>Data transfer (reading/writing)</li></ul></li><li><p>Disks expose storage as a linear array of blocks</p><ul><li>Blocks are 512 bytes</li><li>Can read/write whole blocks (nothing partial)</li><li>Actual location of block is unknown to the OS</li></ul></li></ul><p><strong>Preventing Failures</strong></p><p><img src=../images/storage_redundancy.png alt=redundancy></p><h3 id=solid-state-drives>Solid State Drives
<a class=anchor href=#solid-state-drives>#</a></h3><ul><li><p>Based on NAND flash cells, and have no moving parts</p><ul><li><strong>SLC</strong>: Single Level Cell (1 bit per cell)</li><li><strong>QLC</strong>: Quad Level Cell (4 bits per cell)</li></ul></li><li><p>Faster, reliable, and more power efficient than HDD</p><ul><li>But can only be written/erased to a limited number of times</li></ul></li><li><p>Cells are organized into <strong>pages</strong></p></li><li><p>Pages are organized into <strong>Erase Blocks</strong> (not the same as disk blocks)</p><ul><li>Writes are only possible to erased pages</li></ul></li><li><p>Writes are 10x slower than reads, Erases are 10x slower than writes</p></li><li><p>Erase Blocks are the smallest unit that can be erased</p><ul><li>Causes fragmentation, requires garbage collection, usually done in the background</li><li>GC copies over an entire block to a new block, then erases the old (fragmented) block</li><li>SSDs overprovision to account for this (240GB SSD has 256GB of storage)</li></ul></li><li><p>GC and Wear levelling (solution to fixed number of writes) case <strong>Write Amplification</strong>:</p><ul><li>The number of writes to the SSD is greater than the number of writes to the file system</li></ul></li></ul><p><img src=../images/ssd_firmware.png alt="ssd firmware"></p><h2 id=file-systems>File Systems
<a class=anchor href=#file-systems>#</a></h2><h3 id=goals>Goals
<a class=anchor href=#goals>#</a></h3><ol><li><strong>Abstraction</strong>: Hide details of storage devices from user programs (files)<ul><li>Developed using a generic block layer (does not matter if HDD or SSD)</li></ul></li><li><strong>Organization</strong>: Organize files into directories (logically)</li><li><strong>Sharing</strong>: Allow processes, users, and machines to share files</li><li><strong>Security</strong>: Protect files from unauthorized access</li></ol><h3 id=disk-layout>Disk Layout
<a class=anchor href=#disk-layout>#</a></h3><ul><li><strong>inode</strong>: Data structure to represent a file (<code>struct inode</code>)<ul><li>Metadata: File size, permissions, owner, etc.</li><li>Tracks which blocks (on disk) contains the data stored in the file (<code>struct inode_disk</code>)</li></ul></li></ul><h4 id=layout-strategies>Layout Strategies
<a class=anchor href=#layout-strategies>#</a></h4><ol><li><p><strong>Contiguous Allocation</strong>: Allocate blocks in a contiguous sequence</p><ul><li>Simple, only need to keep track of offset and length of file</li><li>Causes external fragmentation, gaps when a file is deleted</li></ul></li><li><p><strong>Linked Allocation</strong>: Allocate blocks in a linked list</p><ul><li>Each block points to the next block in the file</li><li>Doesn&rsquo;t have to be contiguous, need to keep track of first and last block pointer</li><li>Good for sequential access, bad for all others</li></ul></li><li><p><strong>Indexed Allocation</strong>: Multi-level indirect blocks</p><ul><li>&lsquo;Index&rsquo; block (indirect, double indirect, triple indirect) points to other blocks</li><li>Need to store the index blocks on disk as well</li><li>Allows for very large and extendable files</li><li><strong>Freemap</strong>: Bitmap of free blocks, used to allocate new blocks<ul><li>Only need to allocate bit by bit, not contiguously</li></ul></li></ul></li></ol><h3 id=unix-file-system>UNIX File System
<a class=anchor href=#unix-file-system>#</a></h3><blockquote><p>Simple, easy to use, but terrible performance due to lack of locality</p></blockquote><p><img src=../images/unix_fs.png alt=unix></p><h3 id=access-paths-unix>Access Paths (UNIX)
<a class=anchor href=#access-paths-unix>#</a></h3><h4 id=reading-a-file-from-disk>Reading a file from disk
<a class=anchor href=#reading-a-file-from-disk>#</a></h4><ol><li><p><code>open ("/foo/bar")</code> &ldquo;Find the inode for the file (using the path)&rdquo;</p><ol><li>Start at <code>/</code>, find the inode for the directory</li><li>Read block that contains the inode</li><li>Traverse the data in the block to find the inode for <code>foo</code></li><li>Repeat for <code>bar</code></li><li>Allocate a file descriptor for the file, and return, checking file permissions</li></ol></li><li><p><code>read ()</code> &ldquo;Actually read the file, given the inode&rdquo;</p><ol><li>Read in the first block, use inode to find block location<ul><li>If the offset is past EOF, do nothing</li></ul></li><li>Update inode accessed time</li><li>Update file offset</li></ol></li><li><p>When closing the file, deallocate the file descriptor only</p></li></ol><h4 id=writing-a-file-to-disk>Writing a file to disk
<a class=anchor href=#writing-a-file-to-disk>#</a></h4><ol><li><p>Same <code>open ()</code> as above</p></li><li><p><code>write ()</code> &ldquo;Actually write the file, given the inode&rdquo;</p><ol><li>If the offset is past EOF, need to extend the file<ul><li>May need to allocate new blocks, update inode, and freemap</li></ul></li><li>Read the inode from disk</li><li>Write the data to existing/new blocks<ul><li>Depending on indexing strategy, may need to write new indirect blocks</li></ul></li><li>Update inode with new length, and write serialized inode to disk</li></ol></li></ol><h3 id=placement-problems-in-unix-fs>Placement Problems in UNIX FS
<a class=anchor href=#placement-problems-in-unix-fs>#</a></h3><blockquote><p>Generates long seeks</p></blockquote><ol><li><p>Data blocks allocated randomly in aging file system</p><ul><li>Initial blocks are allocated contiguously, but later blocks are allocated randomly (fragmentation from deletion)</li></ul></li><li><p>Inodes allocated far from blocks</p><ul><li>Access paths operations requires going back and forth between inode and data blocks</li></ul></li></ol><h3 id=file-interfaces>File Interfaces
<a class=anchor href=#file-interfaces>#</a></h3><ul><li><p><strong>File Descriptors</strong>: Managed by the OS</p><ul><li><code>STDIN</code> is 0, <code>STDOUT</code> is 1 (reserved)</li><li>All other open files are identified by a unique integer</li><li>System calls use the file descriptor to identify the file</li><li>Can also be used for pipes, and sockets</li></ul></li><li><p><strong>File Pointers</strong>: Managed by the C library</p><ul><li><code>FILE *</code> is a pointer to a <code>struct FILE</code> (defined in <code>stdio.h</code>)</li><li>Contains the file descriptor, and a buffer for reading/writing</li><li>Use <code>fopen ()</code>, <code>fclose ()</code>, <code>fread ()</code>, <code>fwrite ()</code>, &mldr; to manipulate</li><li>Used for regular files</li></ul></li></ul><h4 id=questions>Questions
<a class=anchor href=#questions>#</a></h4><ol><li><p>Why do we need to open files before reading/writing them?</p><ul><li>Need to load the file into memory, and allocate a file descriptor, in order to manipulate it<ul><li><code>open ()</code> calls <code>filesys_open ()</code>, which calls <code>inode_open ()</code>, which loads the serialized inode into memory</li></ul></li><li>Files occupy multiple blocks, need to load the inode to find the blocks<ul><li>We don&rsquo;t need to load all the blocks at once, just where they are located</li></ul></li><li>To check permissions of the file, if the user is allowed to read/write to the file</li></ul></li><li><p>Why do we need to close files when done with them?</p><ul><li>Resource management: FDs are a limited resource, need to free them up</li><li>File operations may be under a lock, so threads/processes may be blocked</li><li>Security vulnerability, if the file is still open, it can be manipulated by other processes</li><li>Write operations may be written to a buffer, closing the file flushes the buffer</li></ul></li><li><p>Why did we not have to open STDOUT before using <code>printf ()</code>?
<img src=../images/std_file_desc.png alt="std file desc"></p></li></ol><h3 id=bsd-fast-file-system-ffs>BSD Fast File System (FFS)
<a class=anchor href=#bsd-fast-file-system-ffs>#</a></h3><blockquote><p>Improves performance by exploiting locality</p></blockquote><p><img src=../images/cylinder_groups.png alt="Cylinder Group"></p><h4 id=clustering-in-ffs>Clustering in FFS
<a class=anchor href=#clustering-in-ffs>#</a></h4><ol><li>Put sequential blocks in adjacent sectors</li><li>Place inode near file data in the same cylinder</li><li>Try to keep all inodes in a directory in the same cylinder group (allocation group)</li></ol><h4 id=solutions-in-ffs>Solutions in FFS
<a class=anchor href=#solutions-in-ffs>#</a></h4><ol><li><p>The Large File Exception</p><ul><li>Problem: Putting all blocks for a large file in the same cylinder group hurts locality</li><li>Use a multi-level index block to store the file&rsquo;s blocks, store blocks in different cylinder groups<ul><li><strong>Indirect blocks</strong>: 1 indirect pointer to a block of direct pointers</li><li><strong>Double indirect blocks</strong>: 1 indirect pointer to a block of indirect pointers</li></ul></li></ul></li><li><p>Problem: Small block size in UNIX (1K)</p><ul><li>Low bandwidth and small max file size</li><li>Use a larger block (4k)</li></ul></li><li><p>Added Symbolic Links</p></li><li><p>Problem: Media failures</p><ul><li>Duplicate master block (superblock)</li></ul></li><li><p>Problem: Device Obliviousness</p><ul><li>Use a generic block layer, so that it doesn&rsquo;t matter if HDD or SSD</li><li>Modern systems hide device details from the file system</li></ul></li></ol><p><img src=../images/amortization.png alt=amoritization></p><h3 id=links>Links
<a class=anchor href=#links>#</a></h3><h4 id=hard-links>Hard Links
<a class=anchor href=#hard-links>#</a></h4><ul><li>Several dir entires point to the same inode</li><li>UNIX counts number of hard links to an inode</li><li>inode is free&rsquo;d only when all links are removed (rm)</li><li>If the original file is deleted/moved, the link is not broken</li></ul><h4 id=symbolic-soft-links>Symbolic (Soft) Links
<a class=anchor href=#symbolic-soft-links>#</a></h4><ul><li>Just a special file (symlink) with a path to another file</li><li>Type of symlink is stored in the inode</li><li>If the original file is deleted/moved, the link is broken, but the file still exists</li></ul><h3 id=buffer-cache>Buffer Cache
<a class=anchor href=#buffer-cache>#</a></h3><p><img src=../images/buffer_cache.png alt="buffer cache"></p><h4 id=read-ahead>Read Ahead
<a class=anchor href=#read-ahead>#</a></h4><ul><li>FS preloads the next block into the buffer cache, predicting that it will be needed soon</li><li>Great for sequential accessed files, unless blocks are scattered across the disk<ul><li>FS tries to prevent this during allocation</li></ul></li></ul><h3 id=protecting-files>Protecting Files
<a class=anchor href=#protecting-files>#</a></h3><ul><li><p><strong>Protection System</strong>: Access control mechanism for files</p><ul><li>Owner</li><li>Group (UNIX)</li><li>Permissions<ul><li>Read</li><li>Write</li><li>Execute</li></ul></li></ul></li><li><p><strong>Access Control List (ACL)</strong>: List of users and permissions for a file</p><ul><li>For each file, a list of users and their permissions</li><li>For each user, a list of files and their permissions</li></ul></li></ul><p><img src=../images/acl.png alt=ACL></p><h3 id=crash-consistency>Crash Consistency
<a class=anchor href=#crash-consistency>#</a></h3><ul><li>File system data structures must persist, retain data on disk even if the system shuts down<ul><li>Either unexpectedly (crash, power loss) or planned (graceful shutdown)</li></ul></li></ul><p><img src=../images/crash_consistency.png alt="crash consistency"></p><ul><li>Consider appending to an already open file, this is not atomic and a crash can happen at any of these steps:<ol><li>Write to the inode</li><li>Write to the freemap (if allocating a new block)</li><li>Write to the data block</li></ol></li></ul><h4 id=crash-scenarios>Crash Scenarios
<a class=anchor href=#crash-scenarios>#</a></h4><ol><li><p>Only one of the steps succeeds</p><ol><li><p>Only the inode is updated (<strong>File Inconsistency</strong>)</p><ul><li>Inode points to some data block, thinking that the file has data there</li><li>But it doesn&rsquo;t, so that data block contains garbage</li></ul></li><li><p>Only the freemap is updated (<strong>Space leak</strong>)</p><ul><li>Bitmap claims that the block is allocated, but it is not</li><li>Wasting an entire block that could actually be used</li></ul></li><li><p>Only the data block is updated</p><ul><li>Not a problem, since the inode is not updated</li><li>OS will not know that the data block is allocated, so it will be overwritten later</li></ul></li></ol></li><li><p>Only 2 (out of the 3) steps succeed</p><ol><li><p>Inode and freemap are updated, but data block is not</p><ul><li>The block that the inode claims has data in, contains garbage</li><li>FS metadata is consistent</li></ul></li><li><p>Inode and data block are updated, but freemap is not</p><ul><li>Block is inconsistent with the freemap, thinking that it is free</li><li>Freemap will (eventually) overwrite the data block, so the data will be lost</li></ul></li><li><p>Freemap and data block are updated, but inode is not</p><ul><li>Similar to just the data block being updated</li><li>No clue which file the data block is allocated for</li><li>Would not get overwritten, since the freemap knows its allocated</li><li>Inconsistent with the inode, so really just wasting space</li></ul></li></ol></li></ol><h3 id=journaling>Journaling
<a class=anchor href=#journaling>#</a></h3><blockquote><p>A solution to crash consistency</p></blockquote><ul><li><p>Allows the file system to recover from a crash, by keeping a log of all file system operations</p></li><li><p>Before performing an operation, write it to the log</p></li><li><p>If a crash happens, the file system can replay the log to recover</p></li><li><p>Small section of disk is partitioned just for the journal</p><ul><li>Journal is a circular buffer, so it will eventually overwrite itself (due to finite partition size)</li></ul></li></ul><h4 id=writing-to-the-log>Writing to the log:
<a class=anchor href=#writing-to-the-log>#</a></h4><ol><li><strong>TxB</strong>: Transaction Begin marker<ul><li>Contains transaction identifier (TID)</li></ul></li><li><strong>Physical Loggings</strong>: Write the (exact block content) data to the log</li><li><strong>TxE</strong>: Transaction End marker<ul><li>Contains same TID</li></ul></li></ol><h4 id=checkpoint>Checkpoint
<a class=anchor href=#checkpoint>#</a></h4><ul><li>Once journal is safely updated, ready to update the actual FS</li><li>Issue the three writes to the FS<ol><li>Write the inode</li><li>Write the freemap</li><li>Write the data block</li></ol></li></ul><h4 id=recovery-during-checkpoint-crash-successful-journal-log>Recovery during checkpoint crash (successful journal log)
<a class=anchor href=#recovery-during-checkpoint-crash-successful-journal-log>#</a></h4><blockquote><p>Scan the log for completed transactions</p></blockquote><ul><li>Find the last TxB and TxE</li><li>All operations between these two markers are part of the same transaction</li><li>Just replay the transaction, since the data was physically logged in the journal</li><li>If TxE is missing, then the transaction is incomplete<ul><li>The data was not written to the log, so the update is lost</li><li>The FS is still consistent, since the checkpoint was not reached</li></ul></li></ul><h4 id=recovery-during-journal-write-crash>Recovery during Journal write crash
<a class=anchor href=#recovery-during-journal-write-crash>#</a></h4><ul><li>Internally, the disk may write the journal data in any order (abstraction of sectors to linear blocks)</li><li>TxB and TxE might be written before physical loggings,<ul><li>If disk lost power before writing the data blocks, then the transaction is incomplete but may appear complete</li></ul></li></ul><ol><li><p>Split transaction into two (atomic) transactions: TxB + Phys, and TxE</p><ul><li>If disk loses power during first transaction, no big deal, as if nothing was logged</li><li>If lost during the second transaction, TxE never gets written, so the entire transaction is lost/skipped anyway</li></ul></li><li><p>One single transaction, but include a <strong>Journal Checksum</strong> (commit)</p><ul><li>TxB, Phys, Checksum, then TxE</li><li>Checksum is computed from all the data in the transaction (including TxB and TxE)</li><li>When replayed, the entire transaction is valid if the checksum is correct (recompute and compare)</li></ul></li></ol><p><img src=../images/batch_journaling.png alt="batch journaling"></p><h4 id=metadata-journaling>Metadata Journaling
<a class=anchor href=#metadata-journaling>#</a></h4><ul><li>Log only the metadata (inode + bitmap) changes</li><li>Data blocks are written to the filesystem directly, not the journal</li></ul><ol><li>Write the data block to the FS</li><li>Journal TxB and Metadata</li><li>Journal Checksum commit</li><li>Journal TxE</li><li>Checkpoint metadata (inode, bitmap)<ul><li>FS is consistent if it crashes before this step</li></ul></li><li>Free: Update the journal superblock (this journal log can be overwritten)</li></ol><hr><p><strong>Credits</strong>: Professor <a href=https://www.cs.toronto.edu/~bianca/>Bianca Schroeder</a>, University of Toronto</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#threads-and-processes>Threads and Processes</a><ul><li><a href=#concurrency>Concurrency</a></li><li><a href=#synchronization>Synchronization</a></li><li><a href=#scheduling>Scheduling</a></li></ul></li><li><a href=#virtual-memory>Virtual Memory</a><ul><li><a href=#attempts-to-solve-virtual-memory>Attempts to Solve Virtual Memory</a></li><li><a href=#page-replacement>Page Replacement</a></li><li><a href=#memory-allocation>Memory Allocation</a></li></ul></li><li><a href=#storage-devices>Storage Devices</a><ul><li><a href=#purpose>Purpose</a></li><li><a href=#hard-disk-drives>Hard Disk Drives</a></li><li><a href=#solid-state-drives>Solid State Drives</a></li></ul></li><li><a href=#file-systems>File Systems</a><ul><li><a href=#goals>Goals</a></li><li><a href=#disk-layout>Disk Layout</a></li><li><a href=#unix-file-system>UNIX File System</a></li><li><a href=#access-paths-unix>Access Paths (UNIX)</a></li><li><a href=#placement-problems-in-unix-fs>Placement Problems in UNIX FS</a></li><li><a href=#file-interfaces>File Interfaces</a></li><li><a href=#bsd-fast-file-system-ffs>BSD Fast File System (FFS)</a></li><li><a href=#links>Links</a></li><li><a href=#buffer-cache>Buffer Cache</a></li><li><a href=#protecting-files>Protecting Files</a></li><li><a href=#crash-consistency>Crash Consistency</a></li><li><a href=#journaling>Journaling</a></li></ul></li></ul></nav></div></aside></main><link rel=stylesheet href=/notes/katex/katex.min.css><script defer src=/notes/katex/katex.min.js></script><script defer src=/notes/katex/auto-render.min.js onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script></body></html>